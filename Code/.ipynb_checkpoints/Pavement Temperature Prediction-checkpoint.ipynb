{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xlwt \n",
    "from xlwt import Workbook \n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print('Libraries Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    '''\n",
    "    Returns the dataframe which is read from the excel file present in the path specified. \n",
    "    \n",
    "    Parameters:\n",
    "        path (str) : The path of the file\n",
    "    \n",
    "    Returns:\n",
    "        df (float) : The dataframe which is created after reading the file.\n",
    "    '''\n",
    "    df= pd.read_excel(path)\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "def create_dataset(X, y, time_steps, ts_range):\n",
    "    '''\n",
    "    Returns the prepared data based on the lag and look ahead\n",
    "    \n",
    "    Parameters:\n",
    "        X          (float): The independent variables of the data\n",
    "        y          (float): The dependent variables of the data\n",
    "        time_steps (int)  : The lag that is being used to lookback\n",
    "        ts_range   (int)  : The lookahead for the data\n",
    "    \n",
    "    Returns:\n",
    "        Xs (float) : The numpy array of the input variable\n",
    "        ys (float) : The numpy array of the output variable \n",
    "    '''\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps - ts_range):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.values[(i + time_steps):(i + time_steps + ts_range),0])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def splitter(df,output,lag,duration,ts):\n",
    "    '''\n",
    "    Returns the training and testing data\n",
    "    \n",
    "    Parameters:\n",
    "        df (float): The whole dataframe containing the independent and dependent variables\n",
    "        output(str): The output variable \n",
    "        lag (int): The lag that needs to be applied for the data\n",
    "        duration (int): The duration that is being considered as output\n",
    "        ts (float): The percentage of training data\n",
    "    \n",
    "    Returns:\n",
    "        x_train (float): The training data of independent variable \n",
    "        x_test (float): The testing data of independent variable\n",
    "        y_train (float): The training data of the depenedent variable \n",
    "        y_test (float): The testing data of the dependent variable \n",
    "    '''\n",
    "    assert (0. <= ts <= 1.)\n",
    "    train_size = int(len(df) * ts)\n",
    "    test_size = len(df) - train_size\n",
    "    train, test = df.iloc[0:train_size], df[train_size:]\n",
    "    print(train.shape, test.shape)\n",
    "    scaler,scaler_single = MinMaxScaler(feature_range=(0, 1)),MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaler.fit(train)\n",
    "    scaler_single.fit(train[output])\n",
    "\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=[df.columns])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=[df.columns])\n",
    "\n",
    "    df_train = train_scaled.copy(deep=True)\n",
    "    df_test = test_scaled.copy(deep=True)\n",
    "\n",
    "    x_train,y_train = create_dataset(df_train,df_train[[output]],lag,duration)\n",
    "    x_test, y_test = create_dataset(df_test, df_test[[output]], lag, duration)\n",
    "\n",
    "    return x_train,x_test,y_train,y_test,scaler_single\n",
    "\n",
    "class attention(keras.layers.Layer):\n",
    "    '''\n",
    "    Attention layer for the neural networks.\n",
    "    \n",
    "    if return_sequences=True, it will give 3D vector and if false it will give 2D vector. It is same as LSTMs.\n",
    "\n",
    "    https://stackoverflow.com/questions/62948332/how-to-add-attention-layer-to-a-bi-lstm/62949137#62949137\n",
    "    the  following code is being inspired from the above link.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, return_sequences=True, **kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention, self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "\n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10896, 7)\n",
      "   Year  Month  Day  Hour  Temp  Solar  Pavement\n",
      "0  2009     11    1     1   8.4    0.0  9.333333\n",
      "1  2009     11    1     2   8.3    0.0  8.933333\n",
      "2  2009     11    1     3   7.9    0.0  8.700000\n",
      "3  2009     11    1     4   7.6    0.0  8.533333\n",
      "4  2009     11    1     5   6.9    0.0  8.533333\n"
     ]
    }
   ],
   "source": [
    "## Specifying the source path\n",
    "src = r'C:\\Users\\Saad.LAKES\\Desktop\\Pavement-Temperature-Prediction\\Data'\n",
    "filename = r'Pave_data_cleaned.xlsx'\n",
    "\n",
    "## Specifying the destination path\n",
    "dest = r'C:\\Users\\Saad.LAKES\\Desktop\\Pavement-Temperature-Prediction\\Solutions\\Six Hours Lag'\n",
    "\n",
    "## Reading the file\n",
    "df = read_file(os.path.join(src,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8716, 2) (2180, 2)\n",
      "The shape of x_train is (8704, 6, 2) and x_test is (2168, 6, 2)\n",
      "The shape of y_train is (8704, 6) and y_test is (2168, 6)\n"
     ]
    }
   ],
   "source": [
    "## Creating the training and testing data\n",
    "x_train,x_test,y_train,y_test,scaler = splitter(df[['Temp','Pavement']],['Pavement'],6,6,0.8)\n",
    "print(f'The shape of x_train is {x_train.shape} and x_test is {x_test.shape}')\n",
    "print(f'The shape of y_train is {y_train.shape} and y_test is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_lstm.hdf5'\n",
    "filepath_attention = 'attention_lstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple LSTM\n",
    "K.clear_session()\n",
    "simple_lstm = keras.Sequential()\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.Dropout(0.3))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.Flatten())\n",
    "simple_lstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dropout(0.3))\n",
    "simple_lstm.add(keras.layers.Dense(32))\n",
    "simple_lstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_lstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new directory......\n",
      "New Directory Created\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0146 - mae: 0.0852 - val_loss: 0.0023 - val_mae: 0.0370\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0069 - mae: 0.0611 - val_loss: 0.0022 - val_mae: 0.0365\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0056 - mae: 0.0552 - val_loss: 0.0022 - val_mae: 0.0367\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0046 - mae: 0.0497 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0272\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0015 - val_mae: 0.0295\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0035 - mae: 0.0426 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0032 - mae: 0.0407 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0030 - mae: 0.0402 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0281\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0373 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 9.7834e-04 - val_mae: 0.0230\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0010 - val_mae: 0.0250\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0365 - val_loss: 9.7266e-04 - val_mae: 0.0236\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0025 - mae: 0.0355 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0351 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0352 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0348 - val_loss: 9.2194e-04 - val_mae: 0.0231\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 8.6621e-04 - val_mae: 0.0220\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 9.2318e-04 - val_mae: 0.0226\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0335 - val_loss: 8.9590e-04 - val_mae: 0.0223\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 8.9534e-04 - val_mae: 0.0221\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 8.1338e-04 - val_mae: 0.0207\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0333 - val_loss: 8.4413e-04 - val_mae: 0.0209\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 8.8885e-04 - val_mae: 0.0226\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 9.0732e-04 - val_mae: 0.0230\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0325 - val_loss: 8.5654e-04 - val_mae: 0.0220\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0321 - val_loss: 9.1475e-04 - val_mae: 0.0233\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0324 - val_loss: 7.9062e-04 - val_mae: 0.0209\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 7.4094e-04 - val_mae: 0.0195\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 0.0013 - val_mae: 0.0293\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 7.8354e-04 - val_mae: 0.0205\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 8.3236e-04 - val_mae: 0.0206\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 8.0783e-04 - val_mae: 0.0211\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0313 - val_loss: 8.2644e-04 - val_mae: 0.0207\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 8.4793e-04 - val_mae: 0.0216\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0319 - val_loss: 8.2382e-04 - val_mae: 0.0197\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 7.4777e-04 - val_mae: 0.0199\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0317 - val_loss: 7.4088e-04 - val_mae: 0.0198\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0314 - val_loss: 8.7723e-04 - val_mae: 0.0217\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0304 - val_loss: 8.6330e-04 - val_mae: 0.0223\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0314 - val_loss: 7.7653e-04 - val_mae: 0.0201\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 7.3451e-04 - val_mae: 0.0196\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 7.7454e-04 - val_mae: 0.0192\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0312 - val_loss: 8.3103e-04 - val_mae: 0.0209\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 8.3696e-04 - val_mae: 0.0208\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 7.2785e-04 - val_mae: 0.0195\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 9.0795e-04 - val_mae: 0.0209\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 8.6529e-04 - val_mae: 0.0220\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 8.4696e-04 - val_mae: 0.0216\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 7.0835e-04 - val_mae: 0.0194\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 7.3532e-04 - val_mae: 0.0192\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 8.3972e-04 - val_mae: 0.0221\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 7.6693e-04 - val_mae: 0.0206\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 7.2297e-04 - val_mae: 0.0200\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 7.7074e-04 - val_mae: 0.0206\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 9.6617e-04 - val_mae: 0.0243\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 8.5748e-04 - val_mae: 0.0224\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 7.1669e-04 - val_mae: 0.0200\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 7.6433e-04 - val_mae: 0.0207\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 7.6293e-04 - val_mae: 0.0203\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 6.8059e-04 - val_mae: 0.0185\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 7.8179e-04 - val_mae: 0.0203\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 6.9912e-04 - val_mae: 0.0194\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 7.3879e-04 - val_mae: 0.0192\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 7.4835e-04 - val_mae: 0.0196\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 9.2646e-04 - val_mae: 0.0221\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0296 - val_loss: 7.2881e-04 - val_mae: 0.0201\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 8.3453e-04 - val_mae: 0.0222\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 8.6633e-04 - val_mae: 0.0222\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 7.5719e-04 - val_mae: 0.0194\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 8.8940e-04 - val_mae: 0.0218\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 6.6091e-04 - val_mae: 0.0188\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 8.2296e-04 - val_mae: 0.0215\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 8.4799e-04 - val_mae: 0.0221\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0297 - val_loss: 6.9173e-04 - val_mae: 0.0190\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 8.0499e-04 - val_mae: 0.0212\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 9.0890e-04 - val_mae: 0.0233\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 8.9849e-04 - val_mae: 0.0230\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 7.9315e-04 - val_mae: 0.0201\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 6.7464e-04 - val_mae: 0.0188\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 8.4237e-04 - val_mae: 0.0220\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 7.9438e-04 - val_mae: 0.0202\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 8.7215e-04 - val_mae: 0.0220\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 7.8217e-04 - val_mae: 0.0211\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0288 - val_loss: 7.5208e-04 - val_mae: 0.0202\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 7.7745e-04 - val_mae: 0.0204\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 7.6917e-04 - val_mae: 0.0205\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 8.5075e-04 - val_mae: 0.0223\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.8915e-04 - val_mae: 0.0203\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 8.1809e-04 - val_mae: 0.0216\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.1980e-04 - val_mae: 0.0191\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 7.7559e-04 - val_mae: 0.0195\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 9.1498e-04 - val_mae: 0.0216\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 7.6044e-04 - val_mae: 0.0196\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 8.5384e-04 - val_mae: 0.0205\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 8.5643e-04 - val_mae: 0.0210\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.3890e-04 - val_mae: 0.0192\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.3880e-04 - val_mae: 0.0193\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 7.9752e-04 - val_mae: 0.0204\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.1612e-04 - val_mae: 0.0193\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 9.0503e-04 - val_mae: 0.0218\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 7.8252e-04 - val_mae: 0.0206\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 8.5672e-04 - val_mae: 0.0217\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 8.5172e-04 - val_mae: 0.0206\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 7.6126e-04 - val_mae: 0.0202\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 7.0811e-04 - val_mae: 0.0190\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.4392e-04 - val_mae: 0.0192\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.2853e-04 - val_mae: 0.0196\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 9.5897e-04 - val_mae: 0.0234\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 8.0539e-04 - val_mae: 0.0210\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 8.6833e-04 - val_mae: 0.0213\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 9.8666e-04 - val_mae: 0.0240\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.7944e-04 - val_mae: 0.0201\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.9892e-04 - val_mae: 0.0199\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.6120e-04 - val_mae: 0.0196\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 8.0362e-04 - val_mae: 0.0205\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 7.6504e-04 - val_mae: 0.0193\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 8.2691e-04 - val_mae: 0.0207\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.9200e-04 - val_mae: 0.0202\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 8.6818e-04 - val_mae: 0.0207\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 9.3438e-04 - val_mae: 0.0225\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 7.5784e-04 - val_mae: 0.0202\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.0414e-04 - val_mae: 0.0202\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.6841e-04 - val_mae: 0.0202\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.8575e-04 - val_mae: 0.0211\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.9197e-04 - val_mae: 0.0202\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.5646e-04 - val_mae: 0.0210\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 7.9322e-04 - val_mae: 0.0204\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 7.7534e-04 - val_mae: 0.0202\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.9249e-04 - val_mae: 0.0207\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 8.3167e-04 - val_mae: 0.0206\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 7.3123e-04 - val_mae: 0.0193\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.0289e-04 - val_mae: 0.0198\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 8.0347e-04 - val_mae: 0.0199\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.4373e-04 - val_mae: 0.0191\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.2872e-04 - val_mae: 0.0209\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 7.5154e-04 - val_mae: 0.0197\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 8.7847e-04 - val_mae: 0.0219\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 7.6216e-04 - val_mae: 0.0202\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 8.8959e-04 - val_mae: 0.0227\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.4885e-04 - val_mae: 0.0214\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.5135e-04 - val_mae: 0.0214\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.1426e-04 - val_mae: 0.0206\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.9252e-04 - val_mae: 0.0204\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.6319e-04 - val_mae: 0.0200\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.6093e-04 - val_mae: 0.0212\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 7.4374e-04 - val_mae: 0.0193\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 9.2227e-04 - val_mae: 0.0219\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.5011e-04 - val_mae: 0.0223\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.9101e-04 - val_mae: 0.0204\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 7.8269e-04 - val_mae: 0.0198\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 7.7988e-04 - val_mae: 0.0204\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.1635e-04 - val_mae: 0.0203\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.0689e-04 - val_mae: 0.0207\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0273 - val_loss: 8.6265e-04 - val_mae: 0.0206\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.1575e-04 - val_mae: 0.0211\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0263 - val_loss: 7.8355e-04 - val_mae: 0.0192\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.3257e-04 - val_mae: 0.0191\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.6884e-04 - val_mae: 0.0196\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 7.5175e-04 - val_mae: 0.0197\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.7034e-04 - val_mae: 0.0192\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 7.4060e-04 - val_mae: 0.0190\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.5415e-04 - val_mae: 0.0196\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 7.6827e-04 - val_mae: 0.0198\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 8.2486e-04 - val_mae: 0.0200\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.3326e-04 - val_mae: 0.0221\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 7.8020e-04 - val_mae: 0.0203\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 7.9389e-04 - val_mae: 0.0210\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 8.1494e-04 - val_mae: 0.0208\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 8.3797e-04 - val_mae: 0.0209\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 8.0297e-04 - val_mae: 0.0202\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.0414e-04 - val_mae: 0.0214\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 7.8015e-04 - val_mae: 0.0199\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.7391e-04 - val_mae: 0.0194\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 9.6838e-04 - val_mae: 0.0226\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 8.2800e-04 - val_mae: 0.0212\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 8.4145e-04 - val_mae: 0.0207\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 7.4491e-04 - val_mae: 0.0190\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 7.7399e-04 - val_mae: 0.0197\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 7.9242e-04 - val_mae: 0.0201\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 7.4055e-04 - val_mae: 0.0194\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 8.1176e-04 - val_mae: 0.0194\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 9.1598e-04 - val_mae: 0.0212\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 12.577021916561455\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('LSTM')\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_lstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_lstm.load_weights(filepath_simple)\n",
    "preds = simple_lstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention model\n",
    "K.clear_session()\n",
    "atten_lstm = keras.Sequential()\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_lstm.add(keras.layers.Dropout(0.3))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_lstm.add(attention(return_sequences=True))\n",
    "atten_lstm.add(keras.layers.Flatten())\n",
    "atten_lstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dropout(0.3))\n",
    "atten_lstm.add(keras.layers.Dense(32))\n",
    "atten_lstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_lstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0169 - mae: 0.0914 - val_loss: 0.0028 - val_mae: 0.0430\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0071 - mae: 0.0621 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0063 - mae: 0.0581 - val_loss: 0.0021 - val_mae: 0.0366\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0053 - mae: 0.0531 - val_loss: 0.0016 - val_mae: 0.0307\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0044 - mae: 0.0484 - val_loss: 0.0015 - val_mae: 0.0302\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0447 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0037 - mae: 0.0439 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0034 - mae: 0.0421 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - ETA: 0s - loss: 0.0031 - mae: 0.040 - 1s 5ms/step - loss: 0.0031 - mae: 0.0406 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0030 - mae: 0.0394 - val_loss: 0.0011 - val_mae: 0.0256\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0028 - mae: 0.0376 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0027 - mae: 0.0376 - val_loss: 8.9347e-04 - val_mae: 0.0215\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 9.2033e-04 - val_mae: 0.0228\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0013 - val_mae: 0.0284\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 8.9940e-04 - val_mae: 0.0220\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0026 - mae: 0.0362 - val_loss: 9.6491e-04 - val_mae: 0.0232\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0025 - mae: 0.0357 - val_loss: 8.8832e-04 - val_mae: 0.0217\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0348 - val_loss: 9.4178e-04 - val_mae: 0.0229\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0349 - val_loss: 9.2025e-04 - val_mae: 0.0226\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 8.2059e-04 - val_mae: 0.0211\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0344 - val_loss: 9.9881e-04 - val_mae: 0.0244\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0024 - mae: 0.0346 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 8.4872e-04 - val_mae: 0.0214\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 7.9549e-04 - val_mae: 0.0205\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0022 - mae: 0.0335 - val_loss: 0.0015 - val_mae: 0.0295\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0325 - val_loss: 8.7829e-04 - val_mae: 0.0209\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0323 - val_loss: 8.9556e-04 - val_mae: 0.0227\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 7.8043e-04 - val_mae: 0.0207\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0021 - mae: 0.0325 - val_loss: 7.5122e-04 - val_mae: 0.0197\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 9.4840e-04 - val_mae: 0.0225\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 8.1564e-04 - val_mae: 0.0209\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 8.6964e-04 - val_mae: 0.0225\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 9.5667e-04 - val_mae: 0.0242\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0314 - val_loss: 7.5720e-04 - val_mae: 0.0203\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 7.6363e-04 - val_mae: 0.0203\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 8.6772e-04 - val_mae: 0.0225\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 7.5282e-04 - val_mae: 0.0194\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 8.6436e-04 - val_mae: 0.0214\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 7.5114e-04 - val_mae: 0.0194\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 9.7814e-04 - val_mae: 0.0239\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 7.2606e-04 - val_mae: 0.0185\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0320 - val_loss: 8.0594e-04 - val_mae: 0.0210\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 8.0358e-04 - val_mae: 0.0196\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 7.4059e-04 - val_mae: 0.0194\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 7.5571e-04 - val_mae: 0.0207\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 8.0491e-04 - val_mae: 0.0203\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 8.6829e-04 - val_mae: 0.0224\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 6.9629e-04 - val_mae: 0.0185\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 8.7870e-04 - val_mae: 0.0215\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 8.6077e-04 - val_mae: 0.0216\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 7.3772e-04 - val_mae: 0.0192\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 6.9988e-04 - val_mae: 0.0185\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 8.6720e-04 - val_mae: 0.0218\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 7.2425e-04 - val_mae: 0.0190\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 8.0739e-04 - val_mae: 0.0209\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0309 - val_loss: 8.0182e-04 - val_mae: 0.0209\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 7.8321e-04 - val_mae: 0.0204\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 8.3131e-04 - val_mae: 0.0213\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 8.1192e-04 - val_mae: 0.0209\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 6.9679e-04 - val_mae: 0.0190\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 7.1078e-04 - val_mae: 0.0188\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 7.7962e-04 - val_mae: 0.0208\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 7.4561e-04 - val_mae: 0.0195\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0295 - val_loss: 7.7086e-04 - val_mae: 0.0203\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0299 - val_loss: 6.6565e-04 - val_mae: 0.0186\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 8.2684e-04 - val_mae: 0.0220\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 9.3685e-04 - val_mae: 0.0237\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 7.1773e-04 - val_mae: 0.0199\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 8.9911e-04 - val_mae: 0.0214\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 7.6854e-04 - val_mae: 0.0209\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 8.5287e-04 - val_mae: 0.0214\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 8.4699e-04 - val_mae: 0.0222\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 7.1390e-04 - val_mae: 0.0198\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 7.5513e-04 - val_mae: 0.0202\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0296 - val_loss: 7.9904e-04 - val_mae: 0.0205\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 8.5854e-04 - val_mae: 0.0205\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 7.4370e-04 - val_mae: 0.0196\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 7.4370e-04 - val_mae: 0.0193\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 7.2264e-04 - val_mae: 0.0191\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 9.8388e-04 - val_mae: 0.0235\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 7.8953e-04 - val_mae: 0.0198\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 8.0544e-04 - val_mae: 0.0204\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 7.9083e-04 - val_mae: 0.0202\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 7.6312e-04 - val_mae: 0.0202\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 7.5814e-04 - val_mae: 0.0201\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 8.5744e-04 - val_mae: 0.0214\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 7.3611e-04 - val_mae: 0.0198\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 8.7179e-04 - val_mae: 0.0229\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.9605e-04 - val_mae: 0.0206\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 8.6844e-04 - val_mae: 0.0222\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 7.6976e-04 - val_mae: 0.0196\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 7.5846e-04 - val_mae: 0.0195\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 7.6989e-04 - val_mae: 0.0201\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.1824e-04 - val_mae: 0.0186\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.5634e-04 - val_mae: 0.0196\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 7.2341e-04 - val_mae: 0.0197\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0287 - val_loss: 8.0563e-04 - val_mae: 0.0204\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 8.4059e-04 - val_mae: 0.0209\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0285 - val_loss: 7.2786e-04 - val_mae: 0.0196\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 7.1600e-04 - val_mae: 0.0195\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 8.2106e-04 - val_mae: 0.0205\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.6741e-04 - val_mae: 0.0202\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 7.8090e-04 - val_mae: 0.0206\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.0475e-04 - val_mae: 0.0187\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0250\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 7.0807e-04 - val_mae: 0.0190\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 7.3636e-04 - val_mae: 0.0195\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.0542e-04 - val_mae: 0.0187\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.7008e-04 - val_mae: 0.0195\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.9860e-04 - val_mae: 0.0202\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.9580e-04 - val_mae: 0.0205\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 7.7175e-04 - val_mae: 0.0203\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 7.6365e-04 - val_mae: 0.0198\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 8.8329e-04 - val_mae: 0.0218\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.3877e-04 - val_mae: 0.0194\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 8.1677e-04 - val_mae: 0.0204\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 8.8620e-04 - val_mae: 0.0230\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.8148e-04 - val_mae: 0.0212\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 8.1870e-04 - val_mae: 0.0215\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 7.5653e-04 - val_mae: 0.0193\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 7.5188e-04 - val_mae: 0.0193\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 7.6331e-04 - val_mae: 0.0203\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 8.8493e-04 - val_mae: 0.0215\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 8.9763e-04 - val_mae: 0.0210\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 8.2356e-04 - val_mae: 0.0199\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 6.8807e-04 - val_mae: 0.0187\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.9138e-04 - val_mae: 0.0200\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 7.8524e-04 - val_mae: 0.0193\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.1196e-04 - val_mae: 0.0212\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 7.8225e-04 - val_mae: 0.0207\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 7.3939e-04 - val_mae: 0.0198\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 7.8387e-04 - val_mae: 0.0201\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 8.7912e-04 - val_mae: 0.0213\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 7.5780e-04 - val_mae: 0.0198\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.9792e-04 - val_mae: 0.0204\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.2278e-04 - val_mae: 0.0202\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 7.6322e-04 - val_mae: 0.0194\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.8231e-04 - val_mae: 0.0205\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.6386e-04 - val_mae: 0.0194\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 8.0544e-04 - val_mae: 0.0200\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 7.0468e-04 - val_mae: 0.0183\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 9.3577e-04 - val_mae: 0.0227\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 9.2337e-04 - val_mae: 0.0214\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 9.5924e-04 - val_mae: 0.0234\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 0.0014 - val_mae: 0.0293\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 7.5074e-04 - val_mae: 0.0193\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 6.9919e-04 - val_mae: 0.0183\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 7.0424e-04 - val_mae: 0.0189\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 8.2517e-04 - val_mae: 0.0204\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 8.0714e-04 - val_mae: 0.0205\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 7.2420e-04 - val_mae: 0.0186\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 8.0537e-04 - val_mae: 0.0206\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 8.5042e-04 - val_mae: 0.0217\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.4208e-04 - val_mae: 0.0201\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.1223e-04 - val_mae: 0.0192\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.6394e-04 - val_mae: 0.0194\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0271 - val_loss: 7.6218e-04 - val_mae: 0.0189\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 7.6643e-04 - val_mae: 0.0198\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 7.2839e-04 - val_mae: 0.0190\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.7493e-04 - val_mae: 0.0205\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0268 - val_loss: 7.6375e-04 - val_mae: 0.0189\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 7.3289e-04 - val_mae: 0.0196\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.7810e-04 - val_mae: 0.0195\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.3367e-04 - val_mae: 0.0208\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.5072e-04 - val_mae: 0.0221\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.6632e-04 - val_mae: 0.0199\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.1473e-04 - val_mae: 0.0205\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.7365e-04 - val_mae: 0.0237\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 7.8817e-04 - val_mae: 0.0200\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 8.1443e-04 - val_mae: 0.0210\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 8.0422e-04 - val_mae: 0.0199\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 8.3764e-04 - val_mae: 0.0212\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.2208e-04 - val_mae: 0.0189\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 8.6961e-04 - val_mae: 0.0212\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.8018e-04 - val_mae: 0.0203\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 7.4548e-04 - val_mae: 0.0201\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 7.7088e-04 - val_mae: 0.0207\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.8265e-04 - val_mae: 0.0201\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0014 - mae: 0.0270 - val_loss: 7.5644e-04 - val_mae: 0.0192\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 7.7397e-04 - val_mae: 0.0193\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 9.3574e-04 - val_mae: 0.0228\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 7.8691e-04 - val_mae: 0.0199\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 7.9892e-04 - val_mae: 0.0202\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 8.2565e-04 - val_mae: 0.0209\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0261 - val_loss: 7.5711e-04 - val_mae: 0.0193\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 8.1702e-04 - val_mae: 0.0200\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0262 - val_loss: 7.8006e-04 - val_mae: 0.0201\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 9.0326e-04 - val_mae: 0.0222\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 8.3971e-04 - val_mae: 0.0213\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 8.0593e-04 - val_mae: 0.0204\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 1s 5ms/step - loss: 0.0013 - mae: 0.0260 - val_loss: 7.7159e-04 - val_mae: 0.0198\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 12.074794783720996\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('LSTM')\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_lstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_lstm.load_weights(filepath_attention)\n",
    "preds = atten_lstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "\n",
    "wk.save(f'LSTM Result.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_cnnlstm.hdf5'\n",
    "filepath_attention = 'attention_cnnlstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple CNN-LSTM model\n",
    "K.clear_session()\n",
    "simple_cnnlstm = keras.Sequential()\n",
    "simple_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "simple_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3))\n",
    "simple_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_cnnlstm.add(keras.layers.Flatten())\n",
    "simple_cnnlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(32))\n",
    "simple_cnnlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_cnnlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0290 - mae: 0.1144 - val_loss: 0.0026 - val_mae: 0.0431\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0050 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0327\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0043 - mae: 0.0472 - val_loss: 0.0015 - val_mae: 0.0293\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0040 - mae: 0.0450 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0036 - mae: 0.0425 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0032 - mae: 0.0401 - val_loss: 0.0013 - val_mae: 0.0267\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0383 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0359 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0342 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0318 - val_loss: 9.3729e-04 - val_mae: 0.0222\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 9.5543e-04 - val_mae: 0.0225\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 8.9605e-04 - val_mae: 0.0217\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0299 - val_loss: 9.3509e-04 - val_mae: 0.0227\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 8.9650e-04 - val_mae: 0.0222\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 8.6948e-04 - val_mae: 0.0216\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 8.4570e-04 - val_mae: 0.0210\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 8.2495e-04 - val_mae: 0.0211\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 8.2581e-04 - val_mae: 0.0213\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0272 - val_loss: 8.6144e-04 - val_mae: 0.0220\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.8174e-04 - val_mae: 0.0213\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 9.1643e-04 - val_mae: 0.0218\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 7.4636e-04 - val_mae: 0.0195\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 7.6162e-04 - val_mae: 0.0198\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 7.5151e-04 - val_mae: 0.0199\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 7.7743e-04 - val_mae: 0.0199\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 8.0337e-04 - val_mae: 0.0201\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.4538e-04 - val_mae: 0.0199\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.1038e-04 - val_mae: 0.0190\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 7.1519e-04 - val_mae: 0.0193\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.5964e-04 - val_mae: 0.0208\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 7.7995e-04 - val_mae: 0.0207\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 7.1891e-04 - val_mae: 0.0192\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.3507e-04 - val_mae: 0.0195\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 8.4812e-04 - val_mae: 0.0215\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.7600e-04 - val_mae: 0.0197\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 7.4934e-04 - val_mae: 0.0193\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 7.2135e-04 - val_mae: 0.0195\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.4160e-04 - val_mae: 0.0199\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 7.9849e-04 - val_mae: 0.0203\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 7.2718e-04 - val_mae: 0.0191\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.2685e-04 - val_mae: 0.0191\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.0194e-04 - val_mae: 0.0189\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 7.3679e-04 - val_mae: 0.0195\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.5157e-04 - val_mae: 0.0193\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.6160e-04 - val_mae: 0.0194\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 6.7660e-04 - val_mae: 0.0184\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 8.0986e-04 - val_mae: 0.0213\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 8.0170e-04 - val_mae: 0.0202\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.9425e-04 - val_mae: 0.0209\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.1466e-04 - val_mae: 0.0187\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.0502e-04 - val_mae: 0.0190\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.2146e-04 - val_mae: 0.0188\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.1537e-04 - val_mae: 0.0190\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.5391e-04 - val_mae: 0.0196\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.9116e-04 - val_mae: 0.0202\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 8.3305e-04 - val_mae: 0.0215\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 6.9406e-04 - val_mae: 0.0191\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.1312e-04 - val_mae: 0.0186\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.1749e-04 - val_mae: 0.0192\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.1631e-04 - val_mae: 0.0192\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.3144e-04 - val_mae: 0.0194\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 8.6567e-04 - val_mae: 0.0208\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.0975e-04 - val_mae: 0.0193\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.5323e-04 - val_mae: 0.0203\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.6576e-04 - val_mae: 0.0195\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 6.9973e-04 - val_mae: 0.0186\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.2529e-04 - val_mae: 0.0192\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 9.3155e-04 - val_mae: 0.0226\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.2414e-04 - val_mae: 0.0191\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 8.7004e-04 - val_mae: 0.0212\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 6.6770e-04 - val_mae: 0.0182\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 8.7220e-04 - val_mae: 0.0206\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.1456e-04 - val_mae: 0.0190\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.0398e-04 - val_mae: 0.0187\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.1263e-04 - val_mae: 0.0190\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 6.9134e-04 - val_mae: 0.0185\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 6.7512e-04 - val_mae: 0.0182\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.6279e-04 - val_mae: 0.0198\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0233 - val_loss: 6.7459e-04 - val_mae: 0.0180\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 6.6597e-04 - val_mae: 0.0183\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.1914e-04 - val_mae: 0.0195\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.1030e-04 - val_mae: 0.0189\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.5432e-04 - val_mae: 0.0192\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 6.9135e-04 - val_mae: 0.0189\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.1768e-04 - val_mae: 0.0191\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.1381e-04 - val_mae: 0.0185\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.6956e-04 - val_mae: 0.0200\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.1236e-04 - val_mae: 0.0185\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.2376e-04 - val_mae: 0.0189\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.0140e-04 - val_mae: 0.0184\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 8.1069e-04 - val_mae: 0.0211\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.4498e-04 - val_mae: 0.0192\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 6.8498e-04 - val_mae: 0.0184\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.0486e-04 - val_mae: 0.0186\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.7034e-04 - val_mae: 0.0200\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.8691e-04 - val_mae: 0.0185\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 6.6163e-04 - val_mae: 0.0178\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.0084e-04 - val_mae: 0.0187\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.2922e-04 - val_mae: 0.0188\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.0485e-04 - val_mae: 0.0192\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.4373e-04 - val_mae: 0.0191\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.8459e-04 - val_mae: 0.0199\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.1942e-04 - val_mae: 0.0190\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.6088e-04 - val_mae: 0.0194\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 6.8395e-04 - val_mae: 0.0181\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.1835e-04 - val_mae: 0.0185\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.5407e-04 - val_mae: 0.0195\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.2771e-04 - val_mae: 0.0188\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.1641e-04 - val_mae: 0.0187\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.1382e-04 - val_mae: 0.0189\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 7.2610e-04 - val_mae: 0.0187\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.0257e-04 - val_mae: 0.0184\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 9.3002e-04 - val_mae: 0.0216\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 9.2068e-04 - val_mae: 0.0235\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 6.7118e-04 - val_mae: 0.0180\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.6007e-04 - val_mae: 0.0193\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.5453e-04 - val_mae: 0.0196\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 6.8635e-04 - val_mae: 0.0187\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 6.7151e-04 - val_mae: 0.0180\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 7.2013e-04 - val_mae: 0.0189\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.9614e-04 - val_mae: 0.0191\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.7366e-04 - val_mae: 0.0185\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 6.8674e-04 - val_mae: 0.0181\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.5835e-04 - val_mae: 0.0193\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 6.9868e-04 - val_mae: 0.0182\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 8.2609e-04 - val_mae: 0.0205\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 6.8737e-04 - val_mae: 0.0182\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 6.7977e-04 - val_mae: 0.0180\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 8.0452e-04 - val_mae: 0.0209\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.2953e-04 - val_mae: 0.0191\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 7.1811e-04 - val_mae: 0.0192\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 6.9784e-04 - val_mae: 0.0185\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 7.1736e-04 - val_mae: 0.0189\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 6.8741e-04 - val_mae: 0.0182\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 7.1335e-04 - val_mae: 0.0192\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 8.2035e-04 - val_mae: 0.0200\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.4738e-04 - val_mae: 0.0189\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 7.0970e-04 - val_mae: 0.0186\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.9616e-04 - val_mae: 0.0183\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.9672e-04 - val_mae: 0.0185\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.8558e-04 - val_mae: 0.0180\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 8.1875e-04 - val_mae: 0.0212\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.8983e-04 - val_mae: 0.0185\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.0508e-04 - val_mae: 0.0185\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 6.8480e-04 - val_mae: 0.0185\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.5957e-04 - val_mae: 0.0190\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 7.4440e-04 - val_mae: 0.0190\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 7.4719e-04 - val_mae: 0.0193\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 6.7402e-04 - val_mae: 0.0180\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 7.0674e-04 - val_mae: 0.0183\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 8.3623e-04 - val_mae: 0.0205\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.4415e-04 - val_mae: 0.0186\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 6.7283e-04 - val_mae: 0.0181\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 7.2045e-04 - val_mae: 0.0186\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.8071e-04 - val_mae: 0.0200\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 7.2201e-04 - val_mae: 0.0185\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 8.0079e-04 - val_mae: 0.0203\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.3339e-04 - val_mae: 0.0188\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 8.0269e-04 - val_mae: 0.0199\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.1676e-04 - val_mae: 0.0186\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 6.7842e-04 - val_mae: 0.0179\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 7.8099e-04 - val_mae: 0.0191\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 7.0642e-04 - val_mae: 0.0183\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 7.4357e-04 - val_mae: 0.0190\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 8.3580e-04 - val_mae: 0.0200\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 7.2733e-04 - val_mae: 0.0186\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.3268e-04 - val_mae: 0.0188\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.3030e-04 - val_mae: 0.0187\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 8.1057e-04 - val_mae: 0.0211\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0216 - val_loss: 7.3047e-04 - val_mae: 0.0187\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.2943e-04 - val_mae: 0.0187\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.3824e-04 - val_mae: 0.0186\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0214 - val_loss: 7.0663e-04 - val_mae: 0.0182\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 7.6845e-04 - val_mae: 0.0189\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.8524e-04 - val_mae: 0.0193\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 7.9020e-04 - val_mae: 0.0196\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 6.9525e-04 - val_mae: 0.0184\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 8.5844e-04 - val_mae: 0.0214\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 7.4552e-04 - val_mae: 0.0185\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 7.2184e-04 - val_mae: 0.0187\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 7.2700e-04 - val_mae: 0.0187\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 7.4182e-04 - val_mae: 0.0186\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.9382e-04 - val_mae: 0.0208\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.0829e-04 - val_mae: 0.0185\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 6.9606e-04 - val_mae: 0.0182\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 7.0265e-04 - val_mae: 0.0182\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 7.3220e-04 - val_mae: 0.0184\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 7.4532e-04 - val_mae: 0.0187\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0212 - val_loss: 8.0817e-04 - val_mae: 0.0204\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 8.0440e-04 - val_mae: 0.0197\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0210 - val_loss: 7.2165e-04 - val_mae: 0.0184\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 7.9090e-04 - val_mae: 0.0195\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 9.9968e-04 - mae: 0.0208 - val_loss: 7.7101e-04 - val_mae: 0.0198\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0209 - val_loss: 7.4720e-04 - val_mae: 0.0193\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 9.9952e-04 - mae: 0.0209 - val_loss: 7.3742e-04 - val_mae: 0.0186\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 9.8418e-04 - mae: 0.0208 - val_loss: 7.0637e-04 - val_mae: 0.0183\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0010 - mae: 0.0211 - val_loss: 8.0384e-04 - val_mae: 0.0195\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 11.704137796827624\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('CNN-LSTM')\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_cnnlstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_cnnlstm.load_weights(filepath_simple)\n",
    "preds = simple_cnnlstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention model\n",
    "K.clear_session()\n",
    "atten_cnnlstm = keras.Sequential()\n",
    "atten_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "atten_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3))\n",
    "atten_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_cnnlstm.add(attention(return_sequences=True))\n",
    "atten_cnnlstm.add(keras.layers.Flatten())\n",
    "atten_cnnlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(32))\n",
    "atten_cnnlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_cnnlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 1s 6ms/step - loss: 0.0331 - mae: 0.1249 - val_loss: 0.0025 - val_mae: 0.0396\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0053 - mae: 0.0532 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0045 - mae: 0.0478 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0041 - mae: 0.0459 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0038 - mae: 0.0440 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0035 - mae: 0.0424 - val_loss: 0.0013 - val_mae: 0.0278\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0033 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0028 - mae: 0.0374 - val_loss: 0.0012 - val_mae: 0.0259\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0027 - mae: 0.0363 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0025 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0024 - mae: 0.0338 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0023 - mae: 0.0331 - val_loss: 9.8688e-04 - val_mae: 0.0229\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 9.8975e-04 - val_mae: 0.0232\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.7558e-04 - val_mae: 0.0232\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0021 - mae: 0.0308 - val_loss: 9.3164e-04 - val_mae: 0.0223\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0011 - val_mae: 0.0241\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0020 - mae: 0.0300 - val_loss: 9.1586e-04 - val_mae: 0.0221\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0294 - val_loss: 9.0216e-04 - val_mae: 0.0217\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 9.3300e-04 - val_mae: 0.0229\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0019 - mae: 0.0293 - val_loss: 9.5516e-04 - val_mae: 0.0223\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 8.4022e-04 - val_mae: 0.0210\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 8.4958e-04 - val_mae: 0.0211\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0018 - mae: 0.0284 - val_loss: 8.4229e-04 - val_mae: 0.0208\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 8.4951e-04 - val_mae: 0.0209\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 8.5816e-04 - val_mae: 0.0210\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0274 - val_loss: 7.8174e-04 - val_mae: 0.0202\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 8.7780e-04 - val_mae: 0.0213\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 8.5377e-04 - val_mae: 0.0215\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 7.7062e-04 - val_mae: 0.0198\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 7.8064e-04 - val_mae: 0.0197\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.7481e-04 - val_mae: 0.0212\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 7.4761e-04 - val_mae: 0.0198\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 7.4057e-04 - val_mae: 0.0197\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 8.2908e-04 - val_mae: 0.0205\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 7.5258e-04 - val_mae: 0.0197\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 8.1419e-04 - val_mae: 0.0208\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.4926e-04 - val_mae: 0.0195\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 7.2793e-04 - val_mae: 0.0193\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 7.2482e-04 - val_mae: 0.0192\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.8842e-04 - val_mae: 0.0197\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.9410e-04 - val_mae: 0.0200\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 7.0684e-04 - val_mae: 0.0190\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 7.0975e-04 - val_mae: 0.0189\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 8.5516e-04 - val_mae: 0.0209\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.0201e-04 - val_mae: 0.0188\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.3167e-04 - val_mae: 0.0193\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 9.1304e-04 - val_mae: 0.0215\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 8.5950e-04 - val_mae: 0.0209\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.5386e-04 - val_mae: 0.0195\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 7.7870e-04 - val_mae: 0.0206\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 8.1956e-04 - val_mae: 0.0204\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 7.4049e-04 - val_mae: 0.0195\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 9.3446e-04 - val_mae: 0.0225\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 8.1228e-04 - val_mae: 0.0216\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 8.0615e-04 - val_mae: 0.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 7.0103e-04 - val_mae: 0.0189\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 7.4426e-04 - val_mae: 0.0194\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 7.6743e-04 - val_mae: 0.0201\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 8.3656e-04 - val_mae: 0.0216\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 8.5244e-04 - val_mae: 0.0207\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.2500e-04 - val_mae: 0.0190\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 8.7442e-04 - val_mae: 0.0215\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 7.0826e-04 - val_mae: 0.0188\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.2113e-04 - val_mae: 0.0189\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.1157e-04 - val_mae: 0.0190\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 9.2877e-04 - val_mae: 0.0218\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.0376e-04 - val_mae: 0.0186\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.1191e-04 - val_mae: 0.0189\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.7036e-04 - val_mae: 0.0203\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.4326e-04 - val_mae: 0.0194\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 8.0517e-04 - val_mae: 0.0206\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 8.2798e-04 - val_mae: 0.0208\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 8.4883e-04 - val_mae: 0.0216\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.1237e-04 - val_mae: 0.0191\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.4838e-04 - val_mae: 0.0189\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.3419e-04 - val_mae: 0.0193\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.4048e-04 - val_mae: 0.0190\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.6651e-04 - val_mae: 0.0193\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.5906e-04 - val_mae: 0.0199\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.0253e-04 - val_mae: 0.0187\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.0154e-04 - val_mae: 0.0188\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.3459e-04 - val_mae: 0.0191\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 6.9765e-04 - val_mae: 0.0185\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.3160e-04 - val_mae: 0.0197\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.2478e-04 - val_mae: 0.0188\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 8.9525e-04 - val_mae: 0.0218\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.3506e-04 - val_mae: 0.0191\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.0792e-04 - val_mae: 0.0188\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.7335e-04 - val_mae: 0.0200\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.3769e-04 - val_mae: 0.0192\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.9855e-04 - val_mae: 0.0204\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 8.5670e-04 - val_mae: 0.0219\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.2420e-04 - val_mae: 0.0194\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.1170e-04 - val_mae: 0.0186\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.2054e-04 - val_mae: 0.0194\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.1371e-04 - val_mae: 0.0189\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.3095e-04 - val_mae: 0.0194\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.3546e-04 - val_mae: 0.0192\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.1095e-04 - val_mae: 0.0189\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.2403e-04 - val_mae: 0.0188\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.0599e-04 - val_mae: 0.0188\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.1515e-04 - val_mae: 0.0190\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.4424e-04 - val_mae: 0.0194\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.4032e-04 - val_mae: 0.0192\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.3382e-04 - val_mae: 0.0193\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.5175e-04 - val_mae: 0.0199\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.2426e-04 - val_mae: 0.0188\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.3346e-04 - val_mae: 0.0196\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.2116e-04 - val_mae: 0.0194\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.8667e-04 - val_mae: 0.0193\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 9.3695e-04 - val_mae: 0.0223\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.5873e-04 - val_mae: 0.0197\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.0625e-04 - val_mae: 0.0190\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 6.9127e-04 - val_mae: 0.0186\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 7.8367e-04 - val_mae: 0.0208\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 8.4555e-04 - val_mae: 0.0225\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0234 - val_loss: 7.0921e-04 - val_mae: 0.0186\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.0481e-04 - val_mae: 0.0188\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.5055e-04 - val_mae: 0.0193\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0235 - val_loss: 7.5368e-04 - val_mae: 0.0195\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.1637e-04 - val_mae: 0.0185\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.0457e-04 - val_mae: 0.0186\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.2811e-04 - val_mae: 0.0195\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.7816e-04 - val_mae: 0.0202\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0013 - mae: 0.0236 - val_loss: 7.4967e-04 - val_mae: 0.0195\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.0488e-04 - val_mae: 0.0187\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.0932e-04 - val_mae: 0.0188\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.4142e-04 - val_mae: 0.0193\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 8.4680e-04 - val_mae: 0.0213\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 6.8440e-04 - val_mae: 0.0184\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.9737e-04 - val_mae: 0.0184\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 6.9699e-04 - val_mae: 0.0184\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.9145e-04 - val_mae: 0.0199\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.0964e-04 - val_mae: 0.0185\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.0457e-04 - val_mae: 0.0189\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 6.9709e-04 - val_mae: 0.0185\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 6.9026e-04 - val_mae: 0.0183\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 7.9033e-04 - val_mae: 0.0205\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 7.5552e-04 - val_mae: 0.0198\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 7.4113e-04 - val_mae: 0.0190\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.6529e-04 - val_mae: 0.0194\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 8.3926e-04 - val_mae: 0.0205\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 8.2381e-04 - val_mae: 0.0199\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 8.3682e-04 - val_mae: 0.0208\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 7.8937e-04 - val_mae: 0.0206\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 8.4765e-04 - val_mae: 0.0208\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.2507e-04 - val_mae: 0.0188\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.5913e-04 - val_mae: 0.0190\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 8.5861e-04 - val_mae: 0.0221\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 8.0672e-04 - val_mae: 0.0196\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0223 - val_loss: 7.5204e-04 - val_mae: 0.0193\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.3764e-04 - val_mae: 0.0190\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 8.0345e-04 - val_mae: 0.0201\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.2226e-04 - val_mae: 0.0189\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 8.0500e-04 - val_mae: 0.0202\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 7.1353e-04 - val_mae: 0.0187\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0225 - val_loss: 7.1726e-04 - val_mae: 0.0187\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.0761e-04 - val_mae: 0.0188\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.4530e-04 - val_mae: 0.0187\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.0909e-04 - val_mae: 0.0186\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 7.9212e-04 - val_mae: 0.0201\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.2282e-04 - val_mae: 0.0187\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0226 - val_loss: 7.1116e-04 - val_mae: 0.0185\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.5825e-04 - val_mae: 0.0193\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.2095e-04 - val_mae: 0.0184\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0012 - mae: 0.0224 - val_loss: 8.4068e-04 - val_mae: 0.0201\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 8.3932e-04 - val_mae: 0.0214\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.4460e-04 - val_mae: 0.0197\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.8295e-04 - val_mae: 0.0182\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 6.9084e-04 - val_mae: 0.0183\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 8.1756e-04 - val_mae: 0.0198\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.3399e-04 - val_mae: 0.0195\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.6837e-04 - val_mae: 0.0196\n",
      "Epoch 179/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.4121e-04 - val_mae: 0.0188\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.3238e-04 - val_mae: 0.0186\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 8.2951e-04 - val_mae: 0.0213\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.7512e-04 - val_mae: 0.0204\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.2688e-04 - val_mae: 0.0185\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.0203e-04 - val_mae: 0.0183\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 8.0539e-04 - val_mae: 0.0209\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 8.1576e-04 - val_mae: 0.0207\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.4296e-04 - val_mae: 0.0193\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0218 - val_loss: 7.7383e-04 - val_mae: 0.0192\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.4192e-04 - val_mae: 0.0190\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.5657e-04 - val_mae: 0.0197\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.0732e-04 - val_mae: 0.0185\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 7.5235e-04 - val_mae: 0.0191\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 8.0585e-04 - val_mae: 0.0203\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.5009e-04 - val_mae: 0.0192\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 7.2348e-04 - val_mae: 0.0189\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.4718e-04 - val_mae: 0.0191\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.7903e-04 - val_mae: 0.0199\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 7.1718e-04 - val_mae: 0.0188\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 7.5711e-04 - val_mae: 0.0191\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 1s 4ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 7.4920e-04 - val_mae: 0.0194\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 11.669131477071934\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('CNN-LSTM')\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_cnnlstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_cnnlstm.load_weights(filepath_attention)\n",
    "preds = atten_cnnlstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('CNN-LStM Results.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_convlstm.hdf5'\n",
    "filepath_attention = 'attention_convlstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping the training and testing data to suit the convlstm model\n",
    "x_train_conv =x_train.reshape(x_train.shape[0], 1, 1, x_train.shape[1], x_train.shape[2])\n",
    "x_test_conv = x_test.reshape(x_test.shape[0], 1, 1, x_test.shape[1], x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple ConvLSTM model\n",
    "K.clear_session()\n",
    "simple_convlstm = keras.Sequential()\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True, \n",
    "                                            input_shape=(x_train_conv.shape[1], x_train_conv.shape[2], \n",
    "                                                         x_train_conv.shape[3], x_train_conv.shape[4])))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.Flatten())\n",
    "simple_convlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(32))\n",
    "simple_convlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_convlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new directory......\n",
      "New Directory Created\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0517 - mae: 0.1711 - val_loss: 0.0076 - val_mae: 0.0711\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0069 - mae: 0.0620 - val_loss: 0.0025 - val_mae: 0.0404\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0056 - mae: 0.0545 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0051 - mae: 0.0517 - val_loss: 0.0018 - val_mae: 0.0313\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0048 - mae: 0.0497 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0045 - mae: 0.0483 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0041 - mae: 0.0464 - val_loss: 0.0017 - val_mae: 0.0301\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0038 - mae: 0.0443 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0033 - mae: 0.0410 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0030 - mae: 0.0392 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0028 - mae: 0.0375 - val_loss: 0.0012 - val_mae: 0.0269\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0027 - mae: 0.0370 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0026 - mae: 0.0364 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0026 - mae: 0.0363 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0025 - mae: 0.0354 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0333 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 9.9807e-04 - val_mae: 0.0238\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0010 - val_mae: 0.0245\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 9.9064e-04 - val_mae: 0.0236\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 9.9847e-04 - val_mae: 0.0237\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 9.9887e-04 - val_mae: 0.0237\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 9.9937e-04 - val_mae: 0.0234\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0022 - mae: 0.0327 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 9.6910e-04 - val_mae: 0.0230\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 9.8370e-04 - val_mae: 0.0233\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 9.9155e-04 - val_mae: 0.0234\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 9.8830e-04 - val_mae: 0.0233\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 9.7616e-04 - val_mae: 0.0232\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 9.9645e-04 - val_mae: 0.0231\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 9.9469e-04 - val_mae: 0.0232\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 9.7849e-04 - val_mae: 0.0231\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0010 - val_mae: 0.0242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 9.9034e-04 - val_mae: 0.0232\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.7380e-04 - val_mae: 0.0228\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.5919e-04 - val_mae: 0.0226\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 9.8512e-04 - val_mae: 0.0229\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 9.9524e-04 - val_mae: 0.0235\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 9.7746e-04 - val_mae: 0.0229\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.7865e-04 - val_mae: 0.0231\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.6237e-04 - val_mae: 0.0225\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0231\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 9.9663e-04 - val_mae: 0.0230\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.4669e-04 - val_mae: 0.0225\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.6844e-04 - val_mae: 0.0228\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.7247e-04 - val_mae: 0.0232\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 9.9196e-04 - val_mae: 0.0231\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 9.3733e-04 - val_mae: 0.0224\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0232\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.8050e-04 - val_mae: 0.0232\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 9.3416e-04 - val_mae: 0.0224\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 9.1977e-04 - val_mae: 0.0222\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 9.4175e-04 - val_mae: 0.0227\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0019 - mae: 0.0303 - val_loss: 9.8863e-04 - val_mae: 0.0234\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 9.5677e-04 - val_mae: 0.0230\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 9.3913e-04 - val_mae: 0.0225\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0019 - mae: 0.0296 - val_loss: 9.2773e-04 - val_mae: 0.0225\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0019 - mae: 0.0297 - val_loss: 9.1189e-04 - val_mae: 0.0223\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 8.9860e-04 - val_mae: 0.0222\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 9.0232e-04 - val_mae: 0.0222\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 9.1221e-04 - val_mae: 0.0225\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 9.8966e-04 - val_mae: 0.0234\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 9.0577e-04 - val_mae: 0.0221\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 9.8291e-04 - val_mae: 0.0231\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 9.4497e-04 - val_mae: 0.0225\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 8.9514e-04 - val_mae: 0.0221\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 8.7673e-04 - val_mae: 0.0218\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 9.5297e-04 - val_mae: 0.0227\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 9.1949e-04 - val_mae: 0.0220\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 8.7423e-04 - val_mae: 0.0218\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 8.6895e-04 - val_mae: 0.0217\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 9.2009e-04 - val_mae: 0.0227\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 8.9710e-04 - val_mae: 0.0224\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 8.7477e-04 - val_mae: 0.0217\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 8.4606e-04 - val_mae: 0.0212\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 8.3691e-04 - val_mae: 0.0211\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0278 - val_loss: 8.5658e-04 - val_mae: 0.0216\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 9.6005e-04 - val_mae: 0.0226\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0279 - val_loss: 9.1037e-04 - val_mae: 0.0226\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.9256e-04 - val_mae: 0.0218\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.5936e-04 - val_mae: 0.0213\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0275 - val_loss: 8.4504e-04 - val_mae: 0.0213\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 9.1884e-04 - val_mae: 0.0222\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 8.7863e-04 - val_mae: 0.0221\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 8.1902e-04 - val_mae: 0.0207\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.6252e-04 - val_mae: 0.0210\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 8.7673e-04 - val_mae: 0.0218\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 8.1578e-04 - val_mae: 0.0206\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 8.5267e-04 - val_mae: 0.0210\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 8.6712e-04 - val_mae: 0.0214\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.3517e-04 - val_mae: 0.0208\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.2933e-04 - val_mae: 0.0207\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 7.9742e-04 - val_mae: 0.0203\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 8.6764e-04 - val_mae: 0.0215\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 8.2264e-04 - val_mae: 0.0208\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 8.3909e-04 - val_mae: 0.0209\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 8.7006e-04 - val_mae: 0.0212\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 8.1439e-04 - val_mae: 0.0208\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 7.8130e-04 - val_mae: 0.0202\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 9.1174e-04 - val_mae: 0.0227\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 8.5074e-04 - val_mae: 0.0216\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0227\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0016 - mae: 0.0264 - val_loss: 9.2787e-04 - val_mae: 0.0217\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 8.0018e-04 - val_mae: 0.0204\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 8.1335e-04 - val_mae: 0.0202\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 8.0565e-04 - val_mae: 0.0202\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.9206e-04 - val_mae: 0.0202\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.7825e-04 - val_mae: 0.0202\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.8041e-04 - val_mae: 0.0200\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.5443e-04 - val_mae: 0.0197\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.5152e-04 - val_mae: 0.0193\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 8.0670e-04 - val_mae: 0.0203\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 7.9346e-04 - val_mae: 0.0202\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 8.0190e-04 - val_mae: 0.0205\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 7.9065e-04 - val_mae: 0.0204\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.5484e-04 - val_mae: 0.0196\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 9.4182e-04 - val_mae: 0.0222\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 8.2697e-04 - val_mae: 0.0208\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0015 - mae: 0.0255 - val_loss: 7.8620e-04 - val_mae: 0.0200\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.8672e-04 - val_mae: 0.0198\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.3796e-04 - val_mae: 0.0194\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.4856e-04 - val_mae: 0.0197\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.4659e-04 - val_mae: 0.0194\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.9471e-04 - val_mae: 0.0199\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.5853e-04 - val_mae: 0.0196\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.4218e-04 - val_mae: 0.0193\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.4465e-04 - val_mae: 0.0191\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 8.1852e-04 - val_mae: 0.0202\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 9.0864e-04 - val_mae: 0.0221\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.4878e-04 - val_mae: 0.0199\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.4002e-04 - val_mae: 0.0195\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.3319e-04 - val_mae: 0.0192\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.2280e-04 - val_mae: 0.0190\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.5251e-04 - val_mae: 0.0192\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.8538e-04 - val_mae: 0.0210\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.9875e-04 - val_mae: 0.0201\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.4890e-04 - val_mae: 0.0197\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.3106e-04 - val_mae: 0.0192\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 8.8547e-04 - val_mae: 0.0217\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.4017e-04 - val_mae: 0.0193\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.8362e-04 - val_mae: 0.0201\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.5501e-04 - val_mae: 0.0198\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.5693e-04 - val_mae: 0.0194\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.3257e-04 - val_mae: 0.0191\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0240 - val_loss: 7.6377e-04 - val_mae: 0.0193\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.4908e-04 - val_mae: 0.0192\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.7345e-04 - val_mae: 0.0194\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.4562e-04 - val_mae: 0.0192\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.9487e-04 - val_mae: 0.0197\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 6s 23ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.4023e-04 - val_mae: 0.0194\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.8739e-04 - val_mae: 0.0203\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.8676e-04 - val_mae: 0.0196\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 8.2121e-04 - val_mae: 0.0204\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.2375e-04 - val_mae: 0.0188\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 12.826096480881398\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('ConvLSTM')\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_convlstm.fit(x_train_conv,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_convlstm.load_weights(filepath_simple)\n",
    "preds = simple_convlstm.predict(x_test_conv)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention model\n",
    "K.clear_session()\n",
    "atten_convlstm = keras.Sequential()\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True, \n",
    "                                            input_shape=(x_train_conv.shape[1], x_train_conv.shape[2], \n",
    "                                                         x_train_conv.shape[3], x_train_conv.shape[4])))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,2),return_sequences=True))\n",
    "atten_convlstm.add(attention(return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.Flatten())\n",
    "atten_convlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(32))\n",
    "atten_convlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_convlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0519 - mae: 0.1716 - val_loss: 0.0102 - val_mae: 0.0844\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0070 - mae: 0.0622 - val_loss: 0.0023 - val_mae: 0.0365\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0054 - mae: 0.0535 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0051 - mae: 0.0514 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0047 - mae: 0.0496 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0046 - mae: 0.0488 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0044 - mae: 0.0478 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0043 - mae: 0.0471 - val_loss: 0.0016 - val_mae: 0.0308\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0042 - mae: 0.0464 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0040 - mae: 0.0456 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0038 - mae: 0.0444 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0036 - mae: 0.0431 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0033 - mae: 0.0409 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0029 - mae: 0.0387 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0026 - mae: 0.0361 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0025 - mae: 0.0357 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0025 - mae: 0.0356 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0025 - mae: 0.0352 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0024 - mae: 0.0346 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0024 - mae: 0.0344 - val_loss: 9.9972e-04 - val_mae: 0.0234\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0024 - mae: 0.0343 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0023 - mae: 0.0340 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0013 - val_mae: 0.0273\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0023 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 9.5556e-04 - val_mae: 0.0228\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0329 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 9.7065e-04 - val_mae: 0.0233\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 9.6896e-04 - val_mae: 0.0231\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0326 - val_loss: 9.5974e-04 - val_mae: 0.0232\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0325 - val_loss: 9.7929e-04 - val_mae: 0.0233\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 9.8251e-04 - val_mae: 0.0232\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 9.9876e-04 - val_mae: 0.0237\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 9.7247e-04 - val_mae: 0.0228\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0322 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 9.9329e-04 - val_mae: 0.0234\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0319 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 9.8786e-04 - val_mae: 0.0234\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0323 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0022 - mae: 0.0321 - val_loss: 9.9426e-04 - val_mae: 0.0235\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 9.7100e-04 - val_mae: 0.0227\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 9.5416e-04 - val_mae: 0.0228\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 9.6471e-04 - val_mae: 0.0230\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 9.9174e-04 - val_mae: 0.0231\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 9.8250e-04 - val_mae: 0.0233\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 9.3111e-04 - val_mae: 0.0223\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 9.7262e-04 - val_mae: 0.0231\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.9157e-04 - val_mae: 0.0233\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 6s 24ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 9.7472e-04 - val_mae: 0.0229\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0317 - val_loss: 0.0011 - val_mae: 0.0238\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 9.5985e-04 - val_mae: 0.0228\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 9.9959e-04 - val_mae: 0.0236\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 9.9443e-04 - val_mae: 0.0234\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 9.9418e-04 - val_mae: 0.0230\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0318 - val_loss: 0.0011 - val_mae: 0.0240\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0233\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 9.7559e-04 - val_mae: 0.0231\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 9.7643e-04 - val_mae: 0.0231\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 9.7587e-04 - val_mae: 0.0231\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 9.9392e-04 - val_mae: 0.0230\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0315 - val_loss: 9.9022e-04 - val_mae: 0.0234\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 9.5685e-04 - val_mae: 0.0228\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0021 - mae: 0.0313 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.5827e-04 - val_mae: 0.0227\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0242\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 9.9127e-04 - val_mae: 0.0234\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 9.6086e-04 - val_mae: 0.0227\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 9.9282e-04 - val_mae: 0.0236\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 9.9839e-04 - val_mae: 0.0234\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0307 - val_loss: 9.4746e-04 - val_mae: 0.0228\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.5428e-04 - val_mae: 0.0230\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0308 - val_loss: 9.2287e-04 - val_mae: 0.0223\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0305 - val_loss: 9.5742e-04 - val_mae: 0.0230\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 0.0020 - mae: 0.0304 - val_loss: 9.0978e-04 - val_mae: 0.0222\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 9.3299e-04 - val_mae: 0.0224\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 9.2039e-04 - val_mae: 0.0226\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 9.2971e-04 - val_mae: 0.0225\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0299 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0298 - val_loss: 9.3655e-04 - val_mae: 0.0227\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0297 - val_loss: 8.9891e-04 - val_mae: 0.0219\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0019 - mae: 0.0295 - val_loss: 8.9614e-04 - val_mae: 0.0221\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0018 - mae: 0.0290 - val_loss: 8.9968e-04 - val_mae: 0.0222\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0018 - mae: 0.0289 - val_loss: 8.8611e-04 - val_mae: 0.0218\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 8.7441e-04 - val_mae: 0.0217\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0018 - mae: 0.0287 - val_loss: 9.0164e-04 - val_mae: 0.0220\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 8.7092e-04 - val_mae: 0.0216\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0018 - mae: 0.0286 - val_loss: 8.8728e-04 - val_mae: 0.0218\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 9.0947e-04 - val_mae: 0.0219\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 9.3112e-04 - val_mae: 0.0226\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 9.6599e-04 - val_mae: 0.0226\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 8.5092e-04 - val_mae: 0.0213\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 8.8300e-04 - val_mae: 0.0214\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 8.8159e-04 - val_mae: 0.0219\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.7381e-04 - val_mae: 0.0217\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 9.7348e-04 - val_mae: 0.0238\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 8.7765e-04 - val_mae: 0.0220\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 8.4951e-04 - val_mae: 0.0214\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0277 - val_loss: 8.6478e-04 - val_mae: 0.0216\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0276 - val_loss: 8.3681e-04 - val_mae: 0.0211\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 8.2050e-04 - val_mae: 0.0206\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 8.5718e-04 - val_mae: 0.0215\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 8.3262e-04 - val_mae: 0.0209\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 8.2440e-04 - val_mae: 0.0208\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 8.2087e-04 - val_mae: 0.0205\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 8.1030e-04 - val_mae: 0.0205\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0016 - mae: 0.0269 - val_loss: 8.0106e-04 - val_mae: 0.0204\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 8.4636e-04 - val_mae: 0.0208\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 8.2554e-04 - val_mae: 0.0206\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 8.3438e-04 - val_mae: 0.0209\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0267 - val_loss: 7.7658e-04 - val_mae: 0.0202\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0268 - val_loss: 8.8325e-04 - val_mae: 0.0216\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 8.4293e-04 - val_mae: 0.0216\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 9.0226e-04 - val_mae: 0.0216\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0266 - val_loss: 8.6636e-04 - val_mae: 0.0214\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0263 - val_loss: 8.8042e-04 - val_mae: 0.0215\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 7.7192e-04 - val_mae: 0.0198\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 9.8926e-04 - val_mae: 0.0226\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 8.6156e-04 - val_mae: 0.0218\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 8.4974e-04 - val_mae: 0.0212\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.8163e-04 - val_mae: 0.0197\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 7.6744e-04 - val_mae: 0.0201\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 7.7399e-04 - val_mae: 0.0199\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 7.9203e-04 - val_mae: 0.0202\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 7.4017e-04 - val_mae: 0.0191\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0257 - val_loss: 7.3545e-04 - val_mae: 0.0192\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 8.4146e-04 - val_mae: 0.0208\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0254 - val_loss: 8.2056e-04 - val_mae: 0.0201\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 7.8560e-04 - val_mae: 0.0199\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 8.0105e-04 - val_mae: 0.0204\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.9661e-04 - val_mae: 0.0206\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0015 - mae: 0.0253 - val_loss: 8.1250e-04 - val_mae: 0.0209\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.4269e-04 - val_mae: 0.0191\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0256 - val_loss: 7.5726e-04 - val_mae: 0.0197\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.7718e-04 - val_mae: 0.0194\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.5867e-04 - val_mae: 0.0197\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.4040e-04 - val_mae: 0.0192\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.6066e-04 - val_mae: 0.0194\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.9991e-04 - val_mae: 0.0211\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.8664e-04 - val_mae: 0.0195\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0246 - val_loss: 7.7880e-04 - val_mae: 0.0206\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - ETA: 0s - loss: 0.0014 - mae: 0.025 - 6s 26ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.5329e-04 - val_mae: 0.0196\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.3608e-04 - val_mae: 0.0196\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.3557e-04 - val_mae: 0.0193\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.2197e-04 - val_mae: 0.0191\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 8.3076e-04 - val_mae: 0.0202\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.2876e-04 - val_mae: 0.0191\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.9794e-04 - val_mae: 0.0197\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 7.7137e-04 - val_mae: 0.0200\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.6773e-04 - val_mae: 0.0195\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 7.3503e-04 - val_mae: 0.0190\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.2838e-04 - val_mae: 0.0190\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.4386e-04 - val_mae: 0.0198\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.5197e-04 - val_mae: 0.0189\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.3025e-04 - val_mae: 0.0193\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 7.7000e-04 - val_mae: 0.0192\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.6161e-04 - val_mae: 0.0193\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 7.3837e-04 - val_mae: 0.0192\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.8979e-04 - val_mae: 0.0193\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0244 - val_loss: 7.3282e-04 - val_mae: 0.0189\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 7.4447e-04 - val_mae: 0.0195\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0242 - val_loss: 7.2872e-04 - val_mae: 0.0188\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.8314e-04 - val_mae: 0.0194\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 7.8401e-04 - val_mae: 0.0194\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0241 - val_loss: 7.6088e-04 - val_mae: 0.0191\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0243 - val_loss: 7.3882e-04 - val_mae: 0.0191\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 12.677123526406021\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('ConvLSTM')\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_convlstm.fit(x_train_conv,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_convlstm.load_weights(filepath_attention)\n",
    "preds = atten_convlstm.predict(x_test_conv)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('ConvLSTM Results.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_seq2seq.hdf5'\n",
    "filepath_attention = 'attention_seq2seq.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping the training data to suit Seq2Seq model\n",
    "y_train_seq = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_7/PartitionedCall:1\", shape=(None, 6, 128), dtype=float32)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 2)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 6, 128)       67072       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 6, 128)       131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 6, 128)       131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 128), (None, 131584      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 6, 128)       0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 6, 128)       131584      repeat_vector[0][0]              \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 6, 128)       131584      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 6, 128)       131584      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 6, 128)       131584      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 1)         129         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 988,289\n",
      "Trainable params: 988,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Simple Model\n",
    "K.clear_session()\n",
    "input_train = keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "output_train = keras.layers.Input(shape=(y_train_seq.shape[1], y_train_seq.shape[2]))\n",
    "\n",
    "### --------------------------------Encoder Section -----------------------------------------------###\n",
    "encoder_first = keras.layers.LSTM(128, return_sequences=True, return_state=False)(input_train)\n",
    "encoder_second = keras.layers.LSTM(128, return_sequences=True)(encoder_first)\n",
    "encoder_third = keras.layers.LSTM(128, return_sequences=True)(encoder_second)\n",
    "encoder_fourth, encoder_fourth_s1, encoder_fourth_s2 = keras.layers.LSTM(128,return_sequences=False, return_state=True)(encoder_third)\n",
    "\n",
    "###---------------------------------Decorder Section-----------------------------------------------###\n",
    "decoder_first = keras.layers.RepeatVector(output_train.shape[1])(encoder_fourth)\n",
    "decoder_second = keras.layers.LSTM(128, return_state=False, return_sequences=True)(decoder_first,initial_state=[encoder_fourth,encoder_fourth_s2])\n",
    "decoder_third = keras.layers.LSTM(128,return_sequences=True)(decoder_second)\n",
    "decoder_fourth = keras.layers.LSTM(128,return_sequences=True)(decoder_third)\n",
    "decoder_fifth = keras.layers.LSTM(128,return_sequences=True)(decoder_fourth)\n",
    "print(decoder_fifth)\n",
    "\n",
    "###--------------------------------Output Section-------------------------------------------------###\n",
    "output = keras.layers.TimeDistributed(keras.layers.Dense(output_train.shape[2]))(decoder_fifth)\n",
    "\n",
    "simple_seq = keras.Model(inputs=input_train, outputs=output)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "simple_seq.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "simple_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new directory......\n",
      "New Directory Created\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 4s 16ms/step - loss: 0.0176 - mae: 0.0913 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0061 - mae: 0.0571 - val_loss: 0.0024 - val_mae: 0.0398\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0048 - mae: 0.0499 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0031 - mae: 0.0400 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0024 - mae: 0.0347 - val_loss: 9.7129e-04 - val_mae: 0.0232\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 9.1942e-04 - val_mae: 0.0225\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0021 - mae: 0.0324 - val_loss: 9.4315e-04 - val_mae: 0.0225\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0020 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0018 - mae: 0.0294 - val_loss: 7.8126e-04 - val_mae: 0.0200\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0017 - mae: 0.0280 - val_loss: 9.5961e-04 - val_mae: 0.0222\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 8.0746e-04 - val_mae: 0.0211\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 9.7406e-04 - val_mae: 0.0229\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 8.9283e-04 - val_mae: 0.0221\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 8.2249e-04 - val_mae: 0.0198\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 8.2304e-04 - val_mae: 0.0205\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 7.6647e-04 - val_mae: 0.0201\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 7.5405e-04 - val_mae: 0.0197\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0016 - mae: 0.0275 - val_loss: 8.8136e-04 - val_mae: 0.0201\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0265 - val_loss: 7.5200e-04 - val_mae: 0.0189\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 8.2744e-04 - val_mae: 0.0202\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 8.9836e-04 - val_mae: 0.0211\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 7.5659e-04 - val_mae: 0.0195\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0262 - val_loss: 6.8777e-04 - val_mae: 0.0190\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0258 - val_loss: 9.8713e-04 - val_mae: 0.0230\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 6.9390e-04 - val_mae: 0.0191\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.5356e-04 - val_mae: 0.0197\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 8.0783e-04 - val_mae: 0.0203\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.8649e-04 - val_mae: 0.0207\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 8.1841e-04 - val_mae: 0.0201\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 9.4789e-04 - val_mae: 0.0215\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.0380e-04 - val_mae: 0.0188\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0247 - val_loss: 8.7040e-04 - val_mae: 0.0217\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 7.2930e-04 - val_mae: 0.0189\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.6263e-04 - val_mae: 0.0202\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.4624e-04 - val_mae: 0.0196\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 9.9317e-04 - val_mae: 0.0218\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 8.7124e-04 - val_mae: 0.0218\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 9.4069e-04 - val_mae: 0.0226\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 9.2723e-04 - val_mae: 0.0229\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 8.4991e-04 - val_mae: 0.0203\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.1055e-04 - val_mae: 0.0186\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 8.7580e-04 - val_mae: 0.0209\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 9.2123e-04 - val_mae: 0.0225\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 9.0747e-04 - val_mae: 0.0212\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 6.9960e-04 - val_mae: 0.0188\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 6.9353e-04 - val_mae: 0.0186\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.7847e-04 - val_mae: 0.0191\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 8.0515e-04 - val_mae: 0.0211\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.7038e-04 - val_mae: 0.0188\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.7792e-04 - val_mae: 0.0205\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 6.7597e-04 - val_mae: 0.0180\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.0748e-04 - val_mae: 0.0188\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 7.8471e-04 - val_mae: 0.0193\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 8.3656e-04 - val_mae: 0.0202\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 8.2610e-04 - val_mae: 0.0209\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 8.3812e-04 - val_mae: 0.0214\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 7.2014e-04 - val_mae: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 7.2348e-04 - val_mae: 0.0189\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0230 - val_loss: 7.3337e-04 - val_mae: 0.0188\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0228 - val_loss: 8.4197e-04 - val_mae: 0.0202\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0229 - val_loss: 6.9913e-04 - val_mae: 0.0182\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.8462e-04 - val_mae: 0.0205\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.7873e-04 - val_mae: 0.0190\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0012 - mae: 0.0227 - val_loss: 7.7900e-04 - val_mae: 0.0202\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.5825e-04 - val_mae: 0.0191\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 6.4829e-04 - val_mae: 0.0180\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 9.2296e-04 - val_mae: 0.0210\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.2203e-04 - val_mae: 0.0197\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 8.9716e-04 - val_mae: 0.0221\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.1433e-04 - val_mae: 0.0190\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0221 - val_loss: 7.1509e-04 - val_mae: 0.0181\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 6.4397e-04 - val_mae: 0.0175\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 6.9227e-04 - val_mae: 0.0184\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 7.0753e-04 - val_mae: 0.0184\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0219 - val_loss: 8.0391e-04 - val_mae: 0.0198\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0011 - mae: 0.0217 - val_loss: 8.7183e-04 - val_mae: 0.0223\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0011 - mae: 0.0220 - val_loss: 7.0838e-04 - val_mae: 0.0191\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 7.2805e-04 - val_mae: 0.0192\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 6.9319e-04 - val_mae: 0.0187\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 6.7393e-04 - val_mae: 0.0182\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0010 - mae: 0.0213 - val_loss: 6.8855e-04 - val_mae: 0.0180\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 7.3908e-04 - val_mae: 0.0196\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0010 - mae: 0.0214 - val_loss: 9.7107e-04 - val_mae: 0.0224\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0010 - mae: 0.0215 - val_loss: 7.2588e-04 - val_mae: 0.0192\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.6420e-04 - mae: 0.0208 - val_loss: 7.9015e-04 - val_mae: 0.0204\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.9682e-04 - mae: 0.0213 - val_loss: 7.6792e-04 - val_mae: 0.0191\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.6335e-04 - mae: 0.0208 - val_loss: 7.6069e-04 - val_mae: 0.0186\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.5437e-04 - mae: 0.0207 - val_loss: 8.2748e-04 - val_mae: 0.0201\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.6391e-04 - mae: 0.0209 - val_loss: 7.5364e-04 - val_mae: 0.0191\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.4905e-04 - mae: 0.0209 - val_loss: 9.3433e-04 - val_mae: 0.0226\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.2813e-04 - mae: 0.0206 - val_loss: 8.6792e-04 - val_mae: 0.0209\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.4463e-04 - mae: 0.0208 - val_loss: 6.9828e-04 - val_mae: 0.0185\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.2947e-04 - mae: 0.0207 - val_loss: 6.8934e-04 - val_mae: 0.0180\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.0869e-04 - mae: 0.0205 - val_loss: 8.2523e-04 - val_mae: 0.0196\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 8.9006e-04 - mae: 0.0202 - val_loss: 7.6088e-04 - val_mae: 0.0193\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 9.1074e-04 - mae: 0.0207 - val_loss: 8.4334e-04 - val_mae: 0.0200\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.7743e-04 - mae: 0.0200 - val_loss: 8.3242e-04 - val_mae: 0.0205\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.1366e-04 - mae: 0.0205 - val_loss: 7.3515e-04 - val_mae: 0.0190\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.7463e-04 - mae: 0.0200 - val_loss: 7.9878e-04 - val_mae: 0.0191\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.6671e-04 - mae: 0.0199 - val_loss: 7.4282e-04 - val_mae: 0.0188\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 8.7575e-04 - mae: 0.0201 - val_loss: 7.1989e-04 - val_mae: 0.0196\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 8.3648e-04 - mae: 0.0196 - val_loss: 7.7410e-04 - val_mae: 0.0192\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.2219e-04 - mae: 0.0194 - val_loss: 7.7661e-04 - val_mae: 0.0193\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.3082e-04 - mae: 0.0196 - val_loss: 9.5665e-04 - val_mae: 0.0212\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 8.3072e-04 - mae: 0.0196 - val_loss: 7.2385e-04 - val_mae: 0.0184\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.1049e-04 - mae: 0.0194 - val_loss: 7.5872e-04 - val_mae: 0.0189\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 8.4471e-04 - mae: 0.0199 - val_loss: 7.4526e-04 - val_mae: 0.0187\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 7.9506e-04 - mae: 0.0191 - val_loss: 8.1009e-04 - val_mae: 0.0205\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 8.2618e-04 - mae: 0.0197 - val_loss: 7.8373e-04 - val_mae: 0.0193\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 7.4716e-04 - mae: 0.0187 - val_loss: 7.4554e-04 - val_mae: 0.0188\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 7.8123e-04 - mae: 0.0193 - val_loss: 8.7675e-04 - val_mae: 0.0202\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 7.5506e-04 - mae: 0.0188 - val_loss: 8.1171e-04 - val_mae: 0.0204\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 7.3952e-04 - mae: 0.0186 - val_loss: 8.1406e-04 - val_mae: 0.0194\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 7.5208e-04 - mae: 0.0190 - val_loss: 8.4829e-04 - val_mae: 0.0201\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 7.3669e-04 - mae: 0.0186 - val_loss: 8.4034e-04 - val_mae: 0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.8675e-04 - mae: 0.0179 - val_loss: 8.0755e-04 - val_mae: 0.0193\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 7.0179e-04 - mae: 0.0183 - val_loss: 8.3242e-04 - val_mae: 0.0195\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 6.9976e-04 - mae: 0.0181 - val_loss: 8.6698e-04 - val_mae: 0.0207\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.6415e-04 - mae: 0.0176 - val_loss: 8.2210e-04 - val_mae: 0.0196\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 7.0040e-04 - mae: 0.0182 - val_loss: 9.0108e-04 - val_mae: 0.0212\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 6.9663e-04 - mae: 0.0183 - val_loss: 7.8961e-04 - val_mae: 0.0191\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.5115e-04 - mae: 0.0176 - val_loss: 8.8006e-04 - val_mae: 0.0199\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.6513e-04 - mae: 0.0177 - val_loss: 8.6557e-04 - val_mae: 0.0195\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.4889e-04 - mae: 0.0177 - val_loss: 9.6447e-04 - val_mae: 0.0218\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.4353e-04 - mae: 0.0176 - val_loss: 9.7771e-04 - val_mae: 0.0225\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 6.2376e-04 - mae: 0.0173 - val_loss: 9.4061e-04 - val_mae: 0.0211\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 5.7437e-04 - mae: 0.0165 - val_loss: 8.2672e-04 - val_mae: 0.0197\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 5.5249e-04 - mae: 0.0163 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 5.7109e-04 - mae: 0.0166 - val_loss: 8.4635e-04 - val_mae: 0.0198\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.0693e-04 - mae: 0.0171 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 5.9612e-04 - mae: 0.0170 - val_loss: 8.7509e-04 - val_mae: 0.0202\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 5.3320e-04 - mae: 0.0161 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 5.5948e-04 - mae: 0.0165 - val_loss: 9.5754e-04 - val_mae: 0.0209\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 5.6006e-04 - mae: 0.0164 - val_loss: 9.3382e-04 - val_mae: 0.0207\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.9232e-04 - mae: 0.0155 - val_loss: 0.0010 - val_mae: 0.0217\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.9661e-04 - mae: 0.0155 - val_loss: 9.0270e-04 - val_mae: 0.0202\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 4.7474e-04 - mae: 0.0153 - val_loss: 8.7345e-04 - val_mae: 0.0198\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.7512e-04 - mae: 0.0153 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.5261e-04 - mae: 0.0150 - val_loss: 9.6566e-04 - val_mae: 0.0208\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 4.9726e-04 - mae: 0.0156 - val_loss: 0.0010 - val_mae: 0.0212\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.4636e-04 - mae: 0.0148 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.3075e-04 - mae: 0.0147 - val_loss: 9.4059e-04 - val_mae: 0.0207\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.9489e-04 - mae: 0.0141 - val_loss: 9.4714e-04 - val_mae: 0.0206\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.3396e-04 - mae: 0.0146 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.0689e-04 - mae: 0.0143 - val_loss: 9.5836e-04 - val_mae: 0.0211\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.3978e-04 - mae: 0.0149 - val_loss: 9.7981e-04 - val_mae: 0.0212\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.9003e-04 - mae: 0.0140 - val_loss: 9.5642e-04 - val_mae: 0.0211\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.8274e-04 - mae: 0.0139 - val_loss: 0.0010 - val_mae: 0.0213\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.5318e-04 - mae: 0.0134 - val_loss: 0.0010 - val_mae: 0.0221\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.6574e-04 - mae: 0.0136 - val_loss: 0.0010 - val_mae: 0.0215\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.8926e-04 - mae: 0.0139 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.8740e-04 - mae: 0.0140 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 4.6943e-04 - mae: 0.0151 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.1972e-04 - mae: 0.0128 - val_loss: 0.0010 - val_mae: 0.0214\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.9215e-04 - mae: 0.0123 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.8084e-04 - mae: 0.0120 - val_loss: 0.0011 - val_mae: 0.0221\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 3.1574e-04 - mae: 0.0128 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.1514e-04 - mae: 0.0127 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 3.1125e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.7914e-04 - mae: 0.0121 - val_loss: 0.0011 - val_mae: 0.0219\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.8345e-04 - mae: 0.0121 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.5124e-04 - mae: 0.0115 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.4652e-04 - mae: 0.0115 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.4166e-04 - mae: 0.0113 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.6220e-04 - mae: 0.0118 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 3.7591e-04 - mae: 0.0136 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.6831e-04 - mae: 0.0119 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.1840e-04 - mae: 0.0108 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.2402e-04 - mae: 0.0108 - val_loss: 9.9871e-04 - val_mae: 0.0216\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.0842e-04 - mae: 0.0106 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.4427e-04 - mae: 0.0114 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.3809e-04 - mae: 0.0112 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 2.1021e-04 - mae: 0.0106 - val_loss: 0.0011 - val_mae: 0.0223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.8042e-04 - mae: 0.0099 - val_loss: 0.0010 - val_mae: 0.0218\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.6830e-04 - mae: 0.0096 - val_loss: 9.6976e-04 - val_mae: 0.0211\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.7552e-04 - mae: 0.0097 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 3.2269e-04 - mae: 0.0126 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 3.9334e-04 - mae: 0.0140 - val_loss: 9.4576e-04 - val_mae: 0.0216\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.5726e-04 - mae: 0.0115 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.8397e-04 - mae: 0.0099 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.5023e-04 - mae: 0.0091 - val_loss: 0.0011 - val_mae: 0.0223\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.3353e-04 - mae: 0.0086 - val_loss: 0.0011 - val_mae: 0.0222\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.3128e-04 - mae: 0.0085 - val_loss: 0.0011 - val_mae: 0.0225\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.4835e-04 - mae: 0.0091 - val_loss: 0.0011 - val_mae: 0.0238\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.5033e-04 - mae: 0.0091 - val_loss: 0.0011 - val_mae: 0.0233\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.4940e-04 - mae: 0.0091 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.4608e-04 - mae: 0.0090 - val_loss: 0.0011 - val_mae: 0.0228\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.3873e-04 - mae: 0.0088 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.5831e-04 - mae: 0.0093 - val_loss: 9.9973e-04 - val_mae: 0.0224\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 6.8730e-04 - mae: 0.0176 - val_loss: 0.0011 - val_mae: 0.0230\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.9702e-04 - mae: 0.0102 - val_loss: 0.0011 - val_mae: 0.0231\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.3338e-04 - mae: 0.0086 - val_loss: 0.0011 - val_mae: 0.0226\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.0492e-04 - mae: 0.0077 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 9.4416e-05 - mae: 0.0073 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 9.2730e-05 - mae: 0.0073 - val_loss: 0.0010 - val_mae: 0.0219\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 1.3635e-04 - mae: 0.0085 - val_loss: 9.9947e-04 - val_mae: 0.0219\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 1.3756e-04 - mae: 0.0087 - val_loss: 0.0010 - val_mae: 0.0225\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 2.2647e-04 - mae: 0.0104 - val_loss: 9.4356e-04 - val_mae: 0.0212\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzy0lEQVR4nO3deXwU9f3H8deHhCTKJYSgXDYghyJHgIAnCuKBF6h4QNWCtxalUluPVi21WsFqVX7eFetNwIvGiqWCWDxaJCAiIEjEKEHABDCAGCDJ5/fHZ5Ys2U3YhFzI5/l47GN3v/Od2e/M7s57Z74zs6KqOOecc+Ea1HUDnHPO1T8eDs455yJ4ODjnnIvg4eCccy6Ch4NzzrkI8XXdgOrQsmVLTU1NretmOOfcPmXBggX5qpoSbdhPIhxSU1PJysqq62Y459w+RUS+Lm+Y71ZyzjkXwcPBOedcBA8H55xzEX4SfQ7Oudqxc+dOcnNzKSwsrOumuEpISkqiXbt2NGzYMOZxPBycczHLzc2lSZMmpKamIiJ13RwXA1Vlw4YN5Obm0qFDh5jH891KzrmYFRYWkpyc7MGwDxERkpOTK721F1M4iMgQEVkhItkicmuU4YkiMjUYPk9EUoPyZBGZIyJbReSRsPpNRGRR2C1fRB4Kho0WkbywYVdWao6cczXKg2HfU5X3bI/hICJxwKPA6UA3YKSIdCtT7Qpgk6p2Ah4EJgblhcAdwG/CK6vqFlVNC92Ar4HXw6pMDRv+dKXnKlYffAB33AE7d9bYSzjn3L4oli2H/kC2qq5S1R1ABjCsTJ1hwHPB41eBwSIiqvqDqn6AhURUItIFaAW8X+nW763//hfuvhu2b6/1l3bOVd6GDRtIS0sjLS2NQw45hLZt2+56vmPHjgrHzcrKYuzYsXt8jWOPPbZa2vree+9x1llnVcu06kIsHdJtgdVhz3OBo8qro6pFIlIAJAP5MUx/BLalEP6vQ8NF5ATgC2Ccqq6OPupeiouz++LiGpm8c656JScns2jRIgDGjx9P48aN+c1vSndMFBUVER8ffbWWnp5Oenr6Hl/jo48+qpa27uvqQ4f0CGBK2PM3gVRV7Qm8Q+kWyW5E5GoRyRKRrLy8vKq9soeDc/u80aNHc+2113LUUUdx88038/HHH3PMMcfQu3dvjj32WFasWAHs/kt+/PjxXH755QwcOJCOHTsyadKkXdNr3LjxrvoDBw7k/PPP5/DDD+fiiy8m9Bt2xowZHH744fTt25exY8dWagthypQp9OjRg+7du3PLLbcAUFxczOjRo+nevTs9evTgwQcfBGDSpEl069aNnj17MmLEiL1fWJUQy5bDGqB92PN2QVm0OrkiEg80AzbsacIi0guIV9UFoTJVDR/vaeC+aOOq6lPAUwDp6elV+69TDwfnqu7GGyH4FV9t0tLgoYcqPVpubi4fffQRcXFxbN68mffff5/4+HhmzZrF7373O1577bWIcZYvX86cOXPYsmULXbt25brrros4D+CTTz5h6dKltGnThuOOO44PP/yQ9PR0rrnmGubOnUuHDh0YOXJkzO389ttvueWWW1iwYAHNmzfn1FNPZfr06bRv3541a9awZMkSAL7//nsAJkyYwFdffUViYuKustoSy5bDfKCziHQQkQTsl35mmTqZwKjg8fnAuxrbn1OPZPetBkSkddjTocDnMUynajwcnPtJuOCCC4gLvs8FBQVccMEFdO/enXHjxrF06dKo45x55pkkJibSsmVLWrVqxfr16yPq9O/fn3bt2tGgQQPS0tLIyclh+fLldOzYcdc5A5UJh/nz5zNw4EBSUlKIj4/n4osvZu7cuXTs2JFVq1Zxww038K9//YumTZsC0LNnTy6++GJefPHFcneX1ZQ9vlrQh3A9MBOIA55R1aUicheQpaqZwGTgBRHJBjZiAQKAiOQATYEEETkHOFVVlwWDLwTOKPOSY0VkKFAUTGt01WdvDzwcnKu6KvzCrymNGjXa9fiOO+5g0KBBvPHGG+Tk5DBw4MCo4yQmJu56HBcXR1FRUZXqVIfmzZvz6aefMnPmTJ544gmmTZvGM888w1tvvcXcuXN58803ueeee/jss89qLSRiehVVnQHMKFN2Z9jjQuCCcsZNrWC6HaOU3QbcFku79pqHg3M/OQUFBbRt2xaAZ599ttqn37VrV1atWkVOTg6pqalMnTo15nH79+/P2LFjyc/Pp3nz5kyZMoUbbriB/Px8EhISGD58OF27duWSSy6hpKSE1atXM2jQII4//ngyMjLYunUrBx10ULXPUzT79+UzPByc+8m5+eabGTVqFHfffTdnnnlmtU//gAMO4LHHHmPIkCE0atSIfv36lVt39uzZtGvXbtfzV155hQkTJjBo0CBUlTPPPJNhw4bx6aefctlll1FSUgLAvffeS3FxMZdccgkFBQWoKmPHjq21YACQ2LoG6rf09HSt0p/9vPAC/OIXsHIldOpU/Q1z7ifm888/54gjjqjrZtS5rVu30rhxY1SVMWPG0LlzZ8aNG1fXzapQtPdORBaoatTje+vDoax1x7ccnHNV8Le//Y20tDSOPPJICgoKuOaaa+q6SdXOdyuBh4NzrlLGjRtX77cU9pZvOYCHg3POleHhAB4OzjlXhocDeDg451wZHg7g4eCcc2V4OICHg3P7iEGDBjFz5szdyh566CGuu+66cscZOHAgoUPdzzjjjKjXKBo/fjz3339/ha89ffp0li1btuv5nXfeyaxZsyrR+ujq66W9PRzAw8G5fcTIkSPJyMjYrSwjIyPm6xvNmDGjyieSlQ2Hu+66i5NPPrlK09oXeDiAh4Nz+4jzzz+ft956a9cf++Tk5PDtt98yYMAArrvuOtLT0znyyCP5wx/+EHX81NRU8vPtb2buueceunTpwvHHH7/rst5g5zD069ePXr16MXz4cLZt28ZHH31EZmYmv/3tb0lLS+PLL79k9OjRvPrqq4CdCd27d2969OjB5ZdfzvbgD8RSU1P5wx/+QJ8+fejRowfLly+PeV7r+tLefp4DeDg4VwV1ccXuFi1a0L9/f95++22GDRtGRkYGF154ISLCPffcQ4sWLSguLmbw4MEsXryYnj17Rp3OggULyMjIYNGiRRQVFdGnTx/69u0LwHnnncdVV10FwO23387kyZO54YYbGDp0KGeddRbnn3/+btMqLCxk9OjRzJ49my5duvCLX/yCxx9/nBtvvBGAli1bsnDhQh577DHuv/9+nn56z/98XB8u7e1bDuDh4Nw+JHzXUvgupWnTptGnTx969+7N0qVLd9sFVNb777/Pueeey4EHHkjTpk0ZOnTormFLlixhwIAB9OjRg5deeqncS36HrFixgg4dOtClSxcARo0axdy5c3cNP++88wDo27cvOTk5Mc1jfbi0t285gIeDc1VQV1fsHjZsGOPGjWPhwoVs27aNvn378tVXX3H//fczf/58mjdvzujRoyksLPev6ys0evRopk+fTq9evXj22Wd577339qq9oct+V8clv2vz0t6+5QAeDs7tQxo3bsygQYO4/PLLd201bN68mUaNGtGsWTPWr1/P22+/XeE0TjjhBKZPn86PP/7Ili1bePPNN3cN27JlC61bt2bnzp289NJLu8qbNGnCli1bIqbVtWtXcnJyyM7OBuCFF17gxBNP3Kt57N+/P//5z3/Iz8+nuLiYKVOmcOKJJ5Kfn09JSQnDhw/n7rvvZuHChbtd2nvixIkUFBSwdevWvXp98C0Hu/dwcG6fMnLkSM4999xdu5d69epF7969Ofzww2nfvj3HHXdcheP36dOHiy66iF69etGqVavdLrv9pz/9iaOOOoqUlBSOOuqoXYEwYsQIrrrqKiZNmrSrIxogKSmJv//971xwwQUUFRXRr18/rr322krNT328tPf+fcnuRYugd294/XU499xqb5dzPzV+ye59l1+yuzJ8y8E556LycAAPB+ecK8PDATwcnKuEn8Ku6P1NVd6zmMJBRIaIyAoRyRaRW6MMTxSRqcHweSKSGpQni8gcEdkqIo+UGee9YJqLgluriqZVI0KHenk4OBeTpKQkNmzY4AGxD1FVNmzYQFJSUqXG2+PRSiISBzwKnALkAvNFJFNVw88wuQLYpKqdRGQEMBG4CCgE7gC6B7eyLlbVsj3J5U2r+vmWg3OV0q5dO3Jzc8nLy6vrprhKSEpK2u1oqFjEcihrfyBbVVcBiEgGMAwID4dhwPjg8avAIyIiqvoD8IGIdKpEm8qbVvX/VPFwcK5SGjZsSIcOHeq6Ga4WxLJbqS2wOux5blAWtY6qFgEFQHIM0/57sEvpDhGRykxLRK4WkSwRyaryrxgPB+eci6ouO6QvVtUewIDgdmllRlbVp1Q1XVXTU1JSqtYCDwfnnIsqlnBYA7QPe94uKItaR0TigWbAhoomqqprgvstwMvY7qsqTavKPByccy6qWMJhPtBZRDqISAIwAsgsUycTGBU8Ph94t6I+AhGJF5GWweOGwFnAkqpMa694ODjnXFR77JBW1SIRuR6YCcQBz6jqUhG5C8hS1UxgMvCCiGQDG7EAAUBEcoCmQIKInAOcCnwNzAyCIQ6YBfwtGKXcaVU7DwfnnIsqpgvvqeoMYEaZsjvDHhcCF5Qzbmo5k+1bTv1yp1XtPByccy4qP0MaPBycc64MDweAvfwDDuec+6nxcADfcnDOuTL273BoEMy+h4Nzzu1m/w4HsK0HDwfnnNuNh4OHg3PORfBw8HBwzrkIHg4eDs45F8HDwcPBOecieDh4ODjnXAQPBw8H55yL4OHg4eCccxE8HDwcnHMugoeDh4NzzkXwcPBwcM65CB4OHg7OORfBw8HDwTnnIng4eDg451wEDwcPB+ecixBTOIjIEBFZISLZInJrlOGJIjI1GD5PRFKD8mQRmSMiW0XkkbD6B4rIWyKyXESWisiEsGGjRSRPRBYFtyurYT7L5+HgnHMR9hgOIhIHPAqcDnQDRopItzLVrgA2qWon4EFgYlBeCNwB/CbKpO9X1cOB3sBxInJ62LCpqpoW3J6u1BxVloeDc85FiGXLoT+QraqrVHUHkAEMK1NnGPBc8PhVYLCIiKr+oKofYCGxi6puU9U5weMdwEKg3V7MR9V5ODjnXIRYwqEtsDrseW5QFrWOqhYBBUByLA0QkYOAs4HZYcXDRWSxiLwqIu3LGe9qEckSkay8vLxYXio6DwfnnItQpx3SIhIPTAEmqeqqoPhNIFVVewLvULpFshtVfUpV01U1PSUlpeqN8HBwzrkIsYTDGiD813u7oCxqnWCF3wzYEMO0nwJWqupDoQJV3aCq24OnTwN9Y5hO1Xk4OOdchFjCYT7QWUQ6iEgCMALILFMnExgVPD4feFdVtaKJisjdWIjcWKa8ddjTocDnMbSx6jwcnHMuQvyeKqhqkYhcD8wE4oBnVHWpiNwFZKlqJjAZeEFEsoGNWIAAICI5QFMgQUTOAU4FNgO/B5YDC0UE4JHgyKSxIjIUKAqmNbp6ZrUcHg7OORdhj+EAoKozgBllyu4Me1wIXFDOuKnlTFbKqX8bcFss7aoWHg7OORfBz5D2cHDOuQgeDh4OzjkXwcPBw8E55yJ4OHg4OOdcBA8HDwfnnIvg4eDh4JxzETwcPByccy6Ch4OHg3PORfBw8HBwzrkIHg4eDs45F8HDwcPBOecieDh4ODjnXAQPBw8H55yL4OHg4eCccxE8HDwcnHMugoeDh4NzzkXwcPBwcM65CB4O8fFQUgIV/+W1c87tVzwc4uLsvqSkbtvhnHP1SEzhICJDRGSFiGSLyK1RhieKyNRg+DwRSQ3Kk0VkjohsFZFHyozTV0Q+C8aZJCISlLcQkXdEZGVw37wa5rN8oXDwXUvOObfLHsNBROKAR4HTgW7ASBHpVqbaFcAmVe0EPAhMDMoLgTuA30SZ9OPAVUDn4DYkKL8VmK2qnYHZwfOa4+HgnHMRYtly6A9kq+oqVd0BZADDytQZBjwXPH4VGCwioqo/qOoHWEjsIiKtgaaq+j9VVeB54Jwo03ourLxmeDg451yEWMKhLbA67HluUBa1jqoWAQVA8h6mmVvONA9W1bXB43XAwdEmICJXi0iWiGTl5eXFMBvl8HBwzrkI9bpDOtiqiHoYkao+parpqpqekpJS9RfxcHDOuQixhMMaoH3Y83ZBWdQ6IhIPNAM27GGa7cqZ5vpgt1No99N3MbSx6jwcnHMuQizhMB/oLCIdRCQBGAFklqmTCYwKHp8PvBv86o8q2G20WUSODo5S+gXwjyjTGhVWXjM8HJxzLkL8niqoapGIXA/MBOKAZ1R1qYjcBWSpaiYwGXhBRLKBjViAACAiOUBTIEFEzgFOVdVlwC+BZ4EDgLeDG8AEYJqIXAF8DVxYDfNZPg8H55yLsMdwAFDVGcCMMmV3hj0uBC4oZ9zUcsqzgO5RyjcAg2NpV7XwcHDOuQj1ukO6Vng4OOdcBA8HDwfnnIvg4eDh4JxzETwcPByccy6Ch4OHg3PORfBw8HBwzrkIHg4eDs45F8HDwcPBOecieDh4ODjnXAQPBw8H55yL4OHg4eCccxE8HDwcnHMugoeDh4NzzkXwcPBwcM65CB4OHg7OORfBw8HDwTnnIng4eDg451wEDwcPB+eci+Dh4OHgnHMRYgoHERkiIitEJFtEbo0yPFFEpgbD54lIatiw24LyFSJyWlDWVUQWhd02i8iNwbDxIrImbNgZ1TOr5fBwcM65CPF7qiAiccCjwClALjBfRDJVdVlYtSuATaraSURGABOBi0SkGzACOBJoA8wSkS6qugJIC5v+GuCNsOk9qKr37/XcxcLDwTnnIsSy5dAfyFbVVaq6A8gAhpWpMwx4Lnj8KjBYRCQoz1DV7ar6FZAdTC/cYOBLVf26qjOxVzwcnHMuQizh0BZYHfY8NyiLWkdVi4ACIDnGcUcAU8qUXS8ii0XkGRFpHq1RInK1iGSJSFZeXl4Ms1EODwfnnItQpx3SIpIADAVeCSt+HDgM2+20Fngg2riq+pSqpqtqekpKStUb4eHgnHMRYgmHNUD7sOftgrKodUQkHmgGbIhh3NOBhaq6PlSgqutVtVhVS4C/Ebkbqnp5ODjnXIRYwmE+0FlEOgS/9EcAmWXqZAKjgsfnA++qqgblI4KjmToAnYGPw8YbSZldSiLSOuzpucCSWGemSjwcnHMuwh6PVlLVIhG5HpgJxAHPqOpSEbkLyFLVTGAy8IKIZAMbsQAhqDcNWAYUAWNUtRhARBphR0BdU+Yl7xORNECBnCjDq5eHg3PORdhjOACo6gxgRpmyO8MeFwIXlDPuPcA9Ucp/wDqty5ZfGkubqk0oHIqKavVlnXOuPvMzpH3LwTnnIng4eDg451wEDwcPB+eci+Dh4OHgnHMRPBwaBIvAw8E553bxcADbevBwcM65XTwcwMPBOefK8HAADwfnnCvDwwE8HJxzrgwPB/BwcM65MjwcAJo2hYKCum6Fc87VGx4OAG3awNq1dd0K55yrNzwcwMLh22/ruhXOOVdveDgAtG7t4eCcc2E8HMC2HDZuhO3b67olzjlXL3g4gIUDeL+Dc84FPBzAdiuB71pyzrmAhwP4loNzzpXh4QC+5eCcc2XEFA4iMkREVohItojcGmV4oohMDYbPE5HUsGG3BeUrROS0sPIcEflMRBaJSFZYeQsReUdEVgb3zfdyHvcsORkaNvRwcM65wB7DQUTigEeB04FuwEgR6Vam2hXAJlXtBDwITAzG7QaMAI4EhgCPBdMLGaSqaaqaHlZ2KzBbVTsDs4PnNatBA9t68N1KzjkHxLbl0B/IVtVVqroDyACGlakzDHguePwqMFhEJCjPUNXtqvoVkB1MryLh03oOOCeGNu49P9fBOed2iSUc2gKrw57nBmVR66hqEVAAJO9hXAX+LSILROTqsDoHq2roJ/w64OAY2rj3/Cxp55zbpS47pI9X1T7Y7qoxInJC2QqqqliIRBCRq0UkS0Sy8vLy9r41fn0l55zbJZZwWAO0D3veLiiLWkdE4oFmwIaKxlXV0P13wBuU7m5aLyKtg2m1Br6L1ihVfUpV01U1PSUlJYbZ2IPWre0s6cLCvZ+Wc87t42IJh/lAZxHpICIJWAdzZpk6mcCo4PH5wLvBr/5MYERwNFMHoDPwsYg0EpEmACLSCDgVWBJlWqOAf1Rt1iopdDjrunW18nLOOVefxe+pgqoWicj1wEwgDnhGVZeKyF1AlqpmApOBF0QkG9iIBQhBvWnAMqAIGKOqxSJyMPCG9VkTD7ysqv8KXnICME1ErgC+Bi6sxvktX2jrIz8fUlNr5SWdc66+2mM4AKjqDGBGmbI7wx4XAheUM+49wD1lylYBvcqpvwEYHEu7qlXLlnZfHf0Xzjm3j/MzpENCWw4eDs455+Gwi4eDc87t4uEQ0rSpXUIjP7+uW+Kcc3XOwyFExPodfMvBOec8HHaTkuLh4JxzeDjszsPBOecAD4fdeTg45xzg4bC7li29Q9o55/Bw2F1KCnz/PezcWdctcc65OuXhEC78EhrOObcf83AI5yfCOecc4OGwu9D1lXzLwTm3n/NwCOdbDs45B3g47M7DwTnnAA+H3SUn22U0PBycc/s5D4dwcXHQooWHg3Nuv+fhUNahh8KqVXXdCuecq1MeDmWlpcEnn4BqXbfEOefqjIdDWb17w3ffwdq1dd0S55yrMx4OZaWl2f0nn9RpM5xzri7FFA4iMkREVohItojcGmV4oohMDYbPE5HUsGG3BeUrROS0oKy9iMwRkWUislREfhVWf7yIrBGRRcHtjGqYz9j16mX3Hg7Ouf1Y/J4qiEgc8ChwCpALzBeRTFVdFlbtCmCTqnYSkRHAROAiEekGjACOBNoAs0SkC1AE3KSqC0WkCbBARN4Jm+aDqnp/dc1kpTRtCp06waJFdfLyzjlXH8Sy5dAfyFbVVaq6A8gAhpWpMwx4Lnj8KjBYRCQoz1DV7ar6FZAN9FfVtaq6EEBVtwCfA233fnaqSe/evuXgnNuvxRIObYHVYc9ziVyR76qjqkVAAZAcy7jBLqjewLyw4utFZLGIPCMizaM1SkSuFpEsEcnKq+J5CR9/DDfeCP37w8svhw3o3dsOZ/3++ypN1znn9nV12iEtIo2B14AbVXVzUPw4cBiQBqwFHog2rqo+parpqpqeErrsRSV9/DE8+SQsWQIZGWEDBg2y++efr9J0nXNuXxdLOKwB2oc9bxeURa0jIvFAM2BDReOKSEMsGF5S1ddDFVR1vaoWq2oJ8Ddst1aNuOwy2zgYNgwWLw4bcPTRcMIJMHEiFBbW1Ms751y9FUs4zAc6i0gHEUnAOpgzy9TJBEYFj88H3lVVDcpHBEczdQA6Ax8H/RGTgc9V9a/hExKR1mFPzwWWVHamYtWoESQmQo8e8PXXUFAQNvDOO+Hbb+HSS2H8eN/F5Jzbr+wxHII+hOuBmVjH8TRVXSoid4nI0KDaZCBZRLKBXwO3BuMuBaYBy4B/AWNUtRg4DrgUOCnKIav3ichnIrIYGASMq66ZLU/Pnna/JDyGTjoJTj8dMjPhrrvsuV9zyTm3nxD9CVwmIj09XbOysqo8/tdfQ2oqPP44XHttlApvvw3nnWd/BvTYY3D22VV+Leecqy9EZIGqpkcb5mdIY9faa9q0TL9DuNNPh7lz4aCDYOhQuPxy2Lq1NpvonHO1ysMB+wuHHj3gs88qqNSvHyxYALffDs8+C0cdBd98U1tNdM65WuXhEOjZ08Khwr1sCQnwpz/BO+/AmjWQng4dO0KbNrbb6f777fjYkpLScXJzYdu2Gm+/c85VJw+HQFqaHa20fHkMlQcPhvfft0RJT7fO6sWL4be/tS2Ktm3hjDPg2GOhfXs45BAYMgSOPBJ++csyh0U551z94x3SgTVroF072zC4/fYqTmT9epg1C/75T0sZVbjwQli5ErKybAtj1ixo3txOy+7e3W7dusGnn8Ls2dC3rwVJt262v8s552pIRR3SHg5hjj8etmyx9XSNmT8fJk2yfViffw47dpQOa9kS8vPtcdu20LmzDc/OtuTq0aP01q4d/Pij9aS3amX327ZZWcuWu7/m99/btaIGDID4PV5r0Tm3n/BwiNHDD9u1lpYvh65d975de1RUZCv+pUttq+Loo2H1apg5E957z46xjYuzq8SuXm2Bsm5d9Gk1bAg7d9rjww+HLl0sMBIT4fXXYdMmu2bU4MGwbBkceKAdv9u7t7Vj0yb44Qc48UQr++YbSEqy8bdutboNG9bCQnHO1RYPhxiFdi398Y92gnS9lJdnZ+utW2cr+C1b7J/r8vKgWTPbFTV3rs3M5s12O+ooOzfjrrtgwwY44gjbIlm1CrZvj+11k5OtbyUuDnJybAuna1frRzn0UHv9khJo0cL+E+PQQ61tb74JBxxgh/8ecIBNK3QfsnmznY3etavvSnOuFnk4VMKpp9pupVWr7PIaPynFxXZLSABgx5btPPHnDVw+spDG7Q6yFX9mpq38O3SwANm+3bYg/v1v2yUmYgnasiWsWGGbWaEtlmhErO8ldA+QkmKv1aqV7cvLyICNG0s78o8+2qa5bZtt1TRqBD/7mbUp1P6DDrLbpk22lZOcbJ3/wby56rd4MRx2WP34XixbZr89OnWy3yPff196oGCXLtbOEFV44w3b+P75z+3jF7J5s33My+6JjYWqdSd27rzn3zT/+x+89ZY97tsXTjst8jcS2Mb79Ok2vbPOso3/muThUAn//a8dZPTnP8Ntt5WWf/CBrYMGDLB10E/Byy/DxRfDLbfAhAlVnMjOnbYV0bKlrfDz861/Y/16e37SSVY2bZpt6RQX27dUFb74wo76OukkOxR49mwLoS1bqtaWhATbagl9+7dutTVHs2bQoIGFSfv2Fj5Nm1rbi4qsnS1blr6xJSVWfz+kCu++C8cdZ78J8vJs0WRl2QbogAH2FiUm2uJbt27374OqLb64OPuB9eKL9hbfd5/trQT48EP7LXDWWbuvVHNy7IdZx4722t99Z6cWbdpk023c2B5/+CH85z+l4zVrZh+Z8CPIjz/e9oQWFVmQhE5wTUy0PautWpUekS5ie1MvucSC5bnn7GN62GF2P2eO/S467zy4/npbDgsXwm9+Y8Nuv90+whdeaEc9pqXZuiL0m6mgwJZpaF5Vrevv0EPt907Xrnbxz48+ggcftMAC+zifdprN38KF9tE++WQ45hjbE52UBGeeuXcb2x4OlXT22faB/utf7Ufy1KnwzDM2rEEDS/aTToIHHoDRo+2X1LXXWtlVV+1dn+/YsXY/aVL5dVasgK++soOayvP663DTTfD3v9sBUf/6l60bjzqqdN05fLjVS0qyro/t22393apVLa4bd+7cvS9jxw47NyQpCT3gQDZtjqNF4g+2psnJsW/Mjh32U3HTJmjSxNYCGzfaN+aTT2yYqr0xmzbZt6242L6lYWe2F9OAm7mPYfyDE3jfOvoLC23h9utnfTeNGkFBAcWJB/JBgxM4+oQEEhOx8DvkEFuDdOxY+hNv+3ZbA4H9DDzwwAq/vVOm2CT619i1h6NbsgTuuce6tZo3t5XQVVfZivG662xF+fOf23fhoots0X/2ma2ETz3VNvAef9x+OU+YYCvKlSttZZWfb2/JokU2602a2Gv+7nd2DMZzwd+C9etnv54LC21RzphhK/OKhLrgrrzSVuRffmm35GQYONA+y3PmwGuv2cegQQP7PF95pR11/vTT9jr5+XDKKfYrfts2ex9WrrTXaNLE3vZQ997hh9v788YbNv9t2the0BYtoE8fOwAxIcFW9mDL9Gc/s3lTtTace64to8REC7Y5c0o/0kuWlH4shw+HX/3K1iGvvGLzUVhor7NoUWSX49lnw1NP2fKriorCAVXd5299+/bV6rR8ueoRR6jaW6vaoIHqLbeoLlig2r27avv2qiNG2LCuXVUHDiyte8QRqv/8p2p+vuqPP5ZO88cfVceOVX35ZXu+caPqzTerduummpVlZV98oSpitxUrorfto49UmzWzNi1erPrJJ6p/+YtqUVFpnW3brI2gmpCg2rhxafsaN1b9859VCwpUDzhA9ayzVBs2VG3UqLROv367tz1WO3bYMvriC9Vly6x9JSW71ykpsTbv3Lnn6f3xj6qJiVb/jTdUjz5a9ZtvKh5n2zbVRx5RnTy5nArffqv6j3+oTp2qf7tugYJqaqutWnjfw6qDBqmefbbquHGqxx6rJW3b6Y/NDlb92c/0tgMeVFBtxzc6lQtKFxboNpJUk5O15JDW+iHH6NxWw3XdkSfZG9m6teqFF6pee63qZZepXn656osvqi5bptOfL1BQbd1qp27+JFt1+3bVNWtUZ81S3brVFtaWLaqqun696jXXqL7yir3XO3eqzpunmpGh+vbbNlpo+T/6qOqdd6r+5z+q11+vethhqrNn22SHD1e95BLVpCTVFi1UBw+2zzCo9u1rn4OWLUs/O4ccUjqrkyerPvyw6oEH2vPOnVXPPNMed+pk46Wk2CwOGKB67732fq1ebd8bUI2PV73pJtUnnrDP/nHHWRtSU1V/+UvVDz6weXrxRdXMTJuv4mK7FRTE9rmpipIS1Y8/ttfdvNnKCgttmYZs3qz6f/9n35lJk+w7vGOHPU9Ls/coNK3K+OEH+3yH1gMVtXHJEtWnn1b98EPVv/7V3sdJkyr3euGALC1nvVrnK/bquFV3OKjaGzFvnuq779qKPuSDD0q/LCNH2soLVP/+d3uDO3cuHX7AAfZFefZZ1ZNOKi0fNUr1oINs3dG8uX1JP/lE9brr7AuZmKh69dX2pbr9dvvyHnusrRzj4+2L2Ly5fbFatbJpXnaZBccLL6j+6ldW9tpr9uUdMcI++O+/r3rOOTasRw+7f/dd1fvuUz39dFup3HWXlf/udza/339vK5pBg+wLMGaM6m23qU6YYCviUJ3f/c5WDGHrTAVboe3cacuzoMDmPbTsvv7a2nrttTbN++5TfeopW8YbN6o2aVIawKGAO+648lcQmZm2Lg699ksvlf/+btpkK7PUVKs7bpwt/yuvVJ040ZbF8cfbsDPOsPtzztqh6Uf+oHFxJfrea/mqCxfqtF//VxvGFemJrVfo4NZLSt/7Bj/qw6f+U285/A09+8BZOqXJlfp9myM076BOOonr9WYm6EFs1E58oaD6a+7Xd+UkfZMz9VXO0xMbzNWu8St1JC/pE32e1CPabNo17cSGRRofXxKxrBMSIpd/gwaqbdvaPagefLCt8IcOVV23rnR5vPGGrfSbNFH96ivVk0+2el9/bYFw6aWlP0CKilRzcmzFWFJi79nQofYj6fPPoy/voiLV776zFe5PTUlJ5QOhunz5pQVnVXk4VLM77rCVXFGRrVyffrp02PbttlJ6+GFb0YR+ZcXF2S+vYcPs+emnqy5apJqdrdqmjX15GzZUveIKW6HGx9s4IvZFPeEEWzHecovq2rWqDzxg02na1OqXXSmceWb57b/7bquTnBx9RTt6tL32yJG2shWxrYnBg21+4uNt/J497bVDoXDOObZl9Pzzdn/TTVZ+4IGlK6fQvIeWSWKiraRD0wzd0tLs/t577T4lxbaQwLaK0tJseb75pgXpoEE2rFcv1XfeseWVkGDzmJyset55quPHqz70kG3BtWlj87VwoeqQIaVhnpxc2oa2bS3ck5JsXrdts4Dr2tXafOmlNg9paVa3WTP7Fffvf6uedlrpyrlNm/CVta3Ukxru1M4pG/XLP72kvzhuZcT7d2jjfB3Wbr62aWSh0JjN+m78KTqVC/Qm/qK3cY9mcKEuprvO5Xh9IPkevannTJ3S7wHNGXy5brrwap121b/1szGPa8HZF+uo1Dl6y4APddv7Wapz5tgvhZwc1Q0bdq31V660rT1V+1wEGy2uthQU2AcofDdADasoHLzPoYYVFlqnV1KSHYxTXGz7Gjt3Lq3z3Xf2p3OZmXZEQ8OG1rk1aJDt/+3QIXK627fDmDEwcqT1dUyfbtPu1s2ml5ZmfQzlefJJ27f6859HDtu40cqzs23/6gMP2P5hsE4/EevDGDXK2nHiifCHP9j+27JeecU685s0sdvRR1v9iROtk3PiRNtlr2q76Ddtgnvvtf3Z555rfSIvvGDdAWlp8H//ZwcNrFhhnXRgHXZdutg+5DvvtP26+fnW0d6wobVx7lzrSlC14aecYp2Lp51mXRyvv27z3LJl6RHArVrZvuT8fBsntO98xQqb92++sXl++eXS/cuh7pOSEuvwDHVJvPeedWpu3mzvWffupctowwab3969rT9o61br+G3Y0Ka5bG4+zbevo83gI6wxK1bYTu8mTazSl1/agl60CFq3tsauXWs7qEVs4RQX2xsaTUKCfSCHDrWe0c6d7UOUlWW9v/HxdvjzpZfajOblWcMOOWS/7bivEZMmWYfD229X3KFYjbxD2tWI4mK7j4ur/mnPmWNHZ7RoEX24qh01U1JiR3DEcn5eYaEFUIsW+8HpFKoWBs2blx6nmZtrydqihR0IsGaNJdHatdaRP3t26Zsa0rSpLayCAgujoiI7Cx/sHJcxYyyMDj7YfsXEx9vjpCRLxEaN7NCn6ljgO3fa9H+qb94558A//mFn4j74YK28pIeDc27P1q+38Fi1yjabjjzSErpBAzuJ4MknLSy6dLHNsSefLP9KlaGjysAO4znySLulp9u0CgrsMKClS22lf9FF9rxVK9sUBAuqnBwLo/ffh9//3o5Dzcionl8kqtUTNJs22Ty0alX1aRQXW4h//71t/i9duvftioGHg3Ou+oVW3nFxthXyzTe2KZeba7u0Tj7ZVpzTp1vgLF1qgZGQYFshGzbYMahgj0NC+1xzc0u3UsDCZelS26f361/bMa0iFmh5ebZVER9v+2/T0io+pnz2bNuPOHSo7atMSqr8/O/cCXffbce8JybayQyh/xyurAULLDj79rXH33xTKydUeTg45+retm22cu/Wzc7/yM+3cCgqsk6hdessbBYssABp184CoWlT2z120klwxx12gkZI+Jn34RISbFjz5nZWa0qK9ZckJNhrvPaa9ZmsWWMdQGPG2MkJqtZvs2KFnZGXlGSdRv37W2iF+lhKSqwP5uWX7eSEefMsyCZPtsCp7BbJX/4CN99s+0pPPdVOyLjiiorHUYXnn7d+ooo6GCuw1+EgIkOAh4E44GlVnVBmeCLwPNAX2ABcpKo5wbDbgCuAYmCsqs6saJoi0gHIAJKBBcClqrqDCng4OLcfWbnSeve/+cYC5+ijrb+jqMh+zWdnW8CArfxDu7F+/NF2h7VrByecYFfafO89uxTCsmWRrxMXt3sfzEEH2enMycm2C27BAjt64tZb7TXPPtt2s/XsaVtN3bpZAMXFWb9OXp6FRoMGpfcHHGD3jzxibV+61NqXmGhHV5x2moVVyNatFqRbtliAzJplR3XcfHOVFuVehYOIxAFfAKcAucB8YKSqLgur80ugp6peKyIjgHNV9SIR6QZMAfoDbYBZQJdgtKjTFJFpwOuqmiEiTwCfqurjFbXRw8E5V2WqpRdrAguU9u1tF4+qrfA//ti2DlatssP5GjWy63/89relWwlFRXYphZdftl1dOyr8Tbu7+HjbRXXLLbbL68Yb7dRpsNdq1MiuH7JmTenFMhs3ti2Oq6+u8lFjexsOxwDjVfW04PltAKp6b1idmUGd/4pIPLAOSAFuDa8bqheMFjFNYAKQBxyiqkVlX7s8Hg7OuXoldDTYd99ZaBx8sN1EbJeUqt3/+KOFSNu2u/eRqNrV+ubNs2uR/fCDbTWkpNgWyiGH2BZF8+Z71cyKwiGWqwC1BVaHPc8FjiqvTrBSL8B2C7UF/ldm3LbB42jTTAa+V9WiKPV3IyJXA1cDHBq6qIlzztUHDRvaBaZSUyuuV15fgYhdYe+YY6q5YbHbZ89gUdWnVDVdVdNTwq/B65xzbq/FEg5rgPBjqtoFZVHrBLuVmmEd0+WNW175BuCgYBrlvZZzzrkaFks4zAc6i0gHEUkARgCZZepkAqOCx+cD7wbX7cgERohIYnAUUmfg4/KmGYwzJ5gGwTT/UfXZc845VxV77HMI+hCuB2Zih50+o6pLReQu7KJNmcBk4AURyQY2Yit7gnrTgGVAETBGVYsBok0zeMlbgAwRuRv4JJi2c865WuQnwTnn3H6qoqOV9tkOaeecczXHw8E551wEDwfnnHMRfhJ9DiKSB3xdxdFbAvnV2JzqVF/b5u2qHG9X5dXXtv3U2vUzVY16othPIhz2hohkldchU9fqa9u8XZXj7aq8+tq2/aldvlvJOedcBA8H55xzETwc4Km6bkAF6mvbvF2V4+2qvPratv2mXft9n4NzzrlIvuXgnHMugoeDc865CPt1OIjIEBFZISLZInJrHbajvYjMEZFlIrJURH4VlI8XkTUisii4nVEHbcsRkc+C188KylqIyDsisjK437u/o6p8m7qGLZNFIrJZRG6sq+UlIs+IyHcisiSsLOoyEjMp+MwtFpE+tdyuv4jI8uC13xCRg4LyVBH5MWzZPVHL7Sr3vROR24LltUJEKvxXyBpq29SwduWIyKKgvFaWWQXrh5r9jKnqfnnDrgb7JdARSAA+BbrVUVtaA32Cx02w/9fuhv2l6m/qeDnlAC3LlN0H3Bo8vhWYWMfv4zrgZ3W1vIATgD7Akj0tI+AM4G1AgKOBebXcrlOB+ODxxLB2pYbXq4PlFfW9C74HnwKJQIfgOxtXm20rM/wB4M7aXGYVrB9q9DO2P2859AeyVXWVqu4AMoBhddEQVV2rqguDx1uAzynn71HriWHAc8Hj54Bz6q4pDAa+VNWqniG/11R1Lnap+nDlLaNhwPNq/of9uVXr2mqXqv5bS/+G93/YH2rVqnKWV3mGARmqul1VvwKyse9urbdNRAS4EJhSU69fTpvKWz/U6Gdsfw6HaP+NXecrZBFJBXoD84Ki64NNw2dqe/dNQIF/i8gCsf/tBjhYVdcGj9cBB9dBu0JGsPuXta6XV0h5y6g+fe4ux35hhnQQkU9E5D8iMqAO2hPtvatPy2sAsF5VV4aV1eoyK7N+qNHP2P4cDvWOiDQGXgNuVNXNwOPAYUAasBbbpK1tx6tqH+B0YIyInBA+UG07tk6Ohxb7F8GhwCtBUX1YXhHqchmVR0R+j/0B10tB0VrgUFXtDfwaeFlEmtZik+rle1fGSHb/IVKryyzK+mGXmviM7c/hEMt/Y9caEWmIvfEvqerrAKq6XlWLVbUE+Bs1uDldHlVdE9x/B7wRtGF9aDM1uP+uttsVOB1YqKrrgzbW+fIKU94yqvPPnYiMBs4CLg5WKgS7bTYEjxdg+/a71FabKnjv6nx5AYj9r/15wNRQWW0us2jrB2r4M7Y/h0Ms/41dK4J9mZOBz1X1r2Hl4fsJzwWWlB23htvVSESahB5jnZlL2P0/w+vyf753+yVX18urjPKWUSbwi+CIkqOBgrBdAzVORIYANwNDVXVbWHmKiMQFjzti//e+qhbbVd57V97/0Ne2k4HlqpobKqitZVbe+oGa/ozVdE97fb5hvfpfYIn/+zpsx/HYJuFiYFFwOwN4AfgsKM8EWtdyuzpiR4p8CiwNLSMgGZgNrARmAS3qYJk1AjYAzcLK6mR5YQG1FtiJ7d+9orxlhB1B8mjwmfsMSK/ldmVj+6NDn7MngrrDg/d4EbAQOLuW21Xuewf8PlheK4DTa/u9DMqfBa4tU7dWllkF64ca/Yz55TOcc85F2J93KznnnCuHh4NzzrkIHg7OOecieDg455yL4OHgnHMugoeDc865CB4OzjnnIvw/DA67gfBr1dgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2168, 6)\n",
      "The Mean Squared Error is: 11.562320751968961\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Seq2Seq')\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_seq.fit(x_train,y_train_seq,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_seq.load_weights(filepath_simple)\n",
    "preds = simple_seq.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 6, 2)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 6, 128)       67072       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 6, 128)       131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 6, 128)       131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 6, 128), (No 131584      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 6, 128)       0           lstm_3[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 6, 128)       131584      repeat_vector[0][0]              \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 6, 6)         0           lstm_4[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 6, 6)         0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 6, 128)       0           activation[0][0]                 \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 256)       0           dot_1[0][0]                      \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 6, 128)       197120      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 6, 128)       131584      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 6, 128)       131584      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 1)         129         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,053,825\n",
      "Trainable params: 1,053,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Attention Model\n",
    "K.clear_session()\n",
    "\n",
    "input_train = keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "output_train = keras.layers.Input(shape=(y_train_seq.shape[1], y_train_seq.shape[2]))\n",
    "\n",
    "###----------------------------------------Encoder Section------------------------------------------###\n",
    "encoder_first = keras.layers.LSTM(128, return_sequences=True, return_state=False)(input_train)\n",
    "encoder_second = keras.layers.LSTM(128, return_sequences=True)(encoder_first)\n",
    "encoder_third = keras.layers.LSTM(128, return_sequences=True)(encoder_second)\n",
    "encoder_fourth, encoder_fourth_s1, encoder_fourth_s2 = keras.layers.LSTM(128,return_sequences=True,return_state=True)(encoder_third)\n",
    "\n",
    "###-----------------------------------------Decoder Section------------------------------------------###\n",
    "decoder_first = keras.layers.RepeatVector(output_train.shape[1])(encoder_fourth_s1)\n",
    "decoder_second = keras.layers.LSTM(128, return_state=False, return_sequences=True)(decoder_first, initial_state=[encoder_fourth_s1, encoder_fourth_s2])\n",
    "\n",
    "attention = keras.layers.dot([decoder_second, encoder_fourth], axes=[2, 2])\n",
    "attention = keras.layers.Activation('softmax')(attention)\n",
    "context = keras.layers.dot([attention, encoder_fourth], axes=[2, 1])\n",
    "\n",
    "decoder_third = keras.layers.concatenate([context, decoder_second])\n",
    "\n",
    "decoder_fourth = keras.layers.LSTM(128, return_sequences=True)(decoder_third)\n",
    "decoder_fifth = keras.layers.LSTM(128, return_sequences=True)(decoder_fourth)\n",
    "decoder_sixth = keras.layers.LSTM(128, return_sequences=True)(decoder_fifth)\n",
    "\n",
    "###-----------------------------------------Output Section-----------------------------------------###\n",
    "output = keras.layers.TimeDistributed(keras.layers.Dense(output_train.shape[2]))(decoder_sixth)\n",
    "\n",
    "atten_seq = keras.Model(inputs=input_train, outputs=output)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "atten_seq.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "atten_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 4s 17ms/step - loss: 0.0475 - mae: 0.1660 - val_loss: 0.0035 - val_mae: 0.0474\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0071 - mae: 0.0621 - val_loss: 0.0030 - val_mae: 0.0450\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0065 - mae: 0.0590 - val_loss: 0.0026 - val_mae: 0.0404\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0062 - mae: 0.0573 - val_loss: 0.0025 - val_mae: 0.0379\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0061 - mae: 0.0568 - val_loss: 0.0023 - val_mae: 0.0367\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0061 - mae: 0.0569 - val_loss: 0.0022 - val_mae: 0.0368\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0059 - mae: 0.0558 - val_loss: 0.0025 - val_mae: 0.0403\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0060 - mae: 0.0564 - val_loss: 0.0022 - val_mae: 0.0366\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0060 - mae: 0.0563 - val_loss: 0.0022 - val_mae: 0.0364\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0060 - mae: 0.0564 - val_loss: 0.0023 - val_mae: 0.0372\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0059 - mae: 0.0556 - val_loss: 0.0022 - val_mae: 0.0362\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0058 - mae: 0.0550 - val_loss: 0.0021 - val_mae: 0.0355\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0059 - mae: 0.0557 - val_loss: 0.0021 - val_mae: 0.0349\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0057 - mae: 0.0546 - val_loss: 0.0021 - val_mae: 0.0354\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0057 - mae: 0.0546 - val_loss: 0.0022 - val_mae: 0.0355\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0056 - mae: 0.0542 - val_loss: 0.0025 - val_mae: 0.0410\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0055 - mae: 0.0538 - val_loss: 0.0023 - val_mae: 0.0360\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0055 - mae: 0.0536 - val_loss: 0.0022 - val_mae: 0.0356\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0052 - mae: 0.0520 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0050 - mae: 0.0514 - val_loss: 0.0019 - val_mae: 0.0333\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0050 - mae: 0.0512 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0047 - mae: 0.0497 - val_loss: 0.0018 - val_mae: 0.0326\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0043 - mae: 0.0474 - val_loss: 0.0016 - val_mae: 0.0307\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0042 - mae: 0.0468 - val_loss: 0.0016 - val_mae: 0.0304\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0450 - val_loss: 0.0021 - val_mae: 0.0368\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0440 - val_loss: 0.0016 - val_mae: 0.0307\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0428 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0035 - mae: 0.0423 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0034 - mae: 0.0415 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0032 - mae: 0.0402 - val_loss: 0.0016 - val_mae: 0.0302\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0032 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0032 - mae: 0.0403 - val_loss: 0.0016 - val_mae: 0.0312\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0032 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0032 - mae: 0.0404 - val_loss: 0.0015 - val_mae: 0.0293\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0281\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0030 - mae: 0.0392 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0030 - mae: 0.0386 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0030 - mae: 0.0393 - val_loss: 0.0014 - val_mae: 0.0289\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0015 - val_mae: 0.0295\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0018 - val_mae: 0.0351\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0028 - mae: 0.0377 - val_loss: 0.0015 - val_mae: 0.0297\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0028 - mae: 0.0375 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0012 - val_mae: 0.0267\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0028 - mae: 0.0370 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0027 - mae: 0.0366 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0026 - mae: 0.0361 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0026 - mae: 0.0359 - val_loss: 0.0012 - val_mae: 0.0267\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0025 - mae: 0.0350 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0026 - mae: 0.0360 - val_loss: 0.0012 - val_mae: 0.0268\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0025 - mae: 0.0351 - val_loss: 0.0013 - val_mae: 0.0278\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0024 - mae: 0.0349 - val_loss: 0.0013 - val_mae: 0.0279\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0024 - mae: 0.0345 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0023 - mae: 0.0338 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0023 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0022 - mae: 0.0330 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0023 - mae: 0.0337 - val_loss: 0.0010 - val_mae: 0.0236\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0021 - mae: 0.0320 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0021 - mae: 0.0321 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 8.8561e-04 - val_mae: 0.0219\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0020 - mae: 0.0311 - val_loss: 9.5986e-04 - val_mae: 0.0233\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0019 - mae: 0.0305 - val_loss: 9.7421e-04 - val_mae: 0.0232\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 9.4997e-04 - val_mae: 0.0235\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0019 - mae: 0.0308 - val_loss: 8.6617e-04 - val_mae: 0.0219\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0301 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 9.5031e-04 - val_mae: 0.0229\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0019 - mae: 0.0300 - val_loss: 0.0010 - val_mae: 0.0251\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0019 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 9.0483e-04 - val_mae: 0.0228\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 9.3968e-04 - val_mae: 0.0228\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0296 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 8.7528e-04 - val_mae: 0.0218\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0018 - mae: 0.0293 - val_loss: 8.7112e-04 - val_mae: 0.0216\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 9.2241e-04 - val_mae: 0.0221\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 8.4681e-04 - val_mae: 0.0214\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0239\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 8.1880e-04 - val_mae: 0.0210\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 9.8559e-04 - val_mae: 0.0231\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 9.6557e-04 - val_mae: 0.0234\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 9.9202e-04 - val_mae: 0.0235\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 8.8090e-04 - val_mae: 0.0223\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0290 - val_loss: 9.1605e-04 - val_mae: 0.0224\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 9.1161e-04 - val_mae: 0.0227\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0284 - val_loss: 8.4332e-04 - val_mae: 0.0208\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 9.7931e-04 - val_mae: 0.0224\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 8.5507e-04 - val_mae: 0.0215\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0279 - val_loss: 9.5185e-04 - val_mae: 0.0231\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 8.5463e-04 - val_mae: 0.0219\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 9.1294e-04 - val_mae: 0.0228\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.0422e-04 - val_mae: 0.0207\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0017 - mae: 0.0281 - val_loss: 9.1067e-04 - val_mae: 0.0226\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 8.6726e-04 - val_mae: 0.0216\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 9.6148e-04 - val_mae: 0.0222\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 7.9351e-04 - val_mae: 0.0208\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 7.8961e-04 - val_mae: 0.0208\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0016 - mae: 0.0272 - val_loss: 9.7336e-04 - val_mae: 0.0235\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 7.9141e-04 - val_mae: 0.0202\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 7.8841e-04 - val_mae: 0.0204\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0276 - val_loss: 7.6674e-04 - val_mae: 0.0203\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.0801e-04 - val_mae: 0.0206\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 2s 10ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.0866e-04 - val_mae: 0.0206\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 9.7787e-04 - val_mae: 0.0245\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0016 - mae: 0.0270 - val_loss: 8.3683e-04 - val_mae: 0.0210\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 7.7337e-04 - val_mae: 0.0201\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.6461e-04 - val_mae: 0.0201\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 7.6945e-04 - val_mae: 0.0202\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 9.8546e-04 - val_mae: 0.0227\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 8.3075e-04 - val_mae: 0.0213\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 7.6209e-04 - val_mae: 0.0197\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 7.6561e-04 - val_mae: 0.0205\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 7.1518e-04 - val_mae: 0.0195\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 7.8662e-04 - val_mae: 0.0207\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0015 - mae: 0.0260 - val_loss: 8.3362e-04 - val_mae: 0.0212\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 8.7334e-04 - val_mae: 0.0226\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0259 - val_loss: 8.3063e-04 - val_mae: 0.0210\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0264 - val_loss: 8.9886e-04 - val_mae: 0.0208\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0015 - mae: 0.0261 - val_loss: 8.5073e-04 - val_mae: 0.0218\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 7.6469e-04 - val_mae: 0.0201\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 6.9031e-04 - val_mae: 0.0191\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 7.9642e-04 - val_mae: 0.0203\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 8.3264e-04 - val_mae: 0.0215\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.2003e-04 - val_mae: 0.0195\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 7.3279e-04 - val_mae: 0.0193\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 7.4456e-04 - val_mae: 0.0198\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 8.7204e-04 - val_mae: 0.0218\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 7.7332e-04 - val_mae: 0.0204\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 7.5212e-04 - val_mae: 0.0198\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 7.6564e-04 - val_mae: 0.0203\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 8.3183e-04 - val_mae: 0.0201\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 8.6433e-04 - val_mae: 0.0218\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 9.3793e-04 - val_mae: 0.0224\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 8.4434e-04 - val_mae: 0.0208\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0251 - val_loss: 7.5077e-04 - val_mae: 0.0201\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.6673e-04 - val_mae: 0.0200\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.1174e-04 - val_mae: 0.0192\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.6543e-04 - val_mae: 0.0200\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 8.6303e-04 - val_mae: 0.0219\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 8.1624e-04 - val_mae: 0.0212\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.5463e-04 - val_mae: 0.0198\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 8.8025e-04 - val_mae: 0.0222\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0250 - val_loss: 7.6401e-04 - val_mae: 0.0195\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0248 - val_loss: 7.7999e-04 - val_mae: 0.0202\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 7.5391e-04 - val_mae: 0.0199\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 7.9458e-04 - val_mae: 0.0213\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 9.1672e-04 - val_mae: 0.0228\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.9624e-04 - val_mae: 0.0209\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0014 - mae: 0.0249 - val_loss: 7.3102e-04 - val_mae: 0.0195\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 7.4341e-04 - val_mae: 0.0194\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.9303e-04 - val_mae: 0.0208\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 8.4231e-04 - val_mae: 0.0217\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 8.5772e-04 - val_mae: 0.0214\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 9.3287e-04 - val_mae: 0.0238\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 8.1001e-04 - val_mae: 0.0205\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.6765e-04 - val_mae: 0.0201\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.2677e-04 - val_mae: 0.0194\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.5012e-04 - val_mae: 0.0208\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 8.5223e-04 - val_mae: 0.0212\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.8031e-04 - val_mae: 0.0197\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 8.1543e-04 - val_mae: 0.0209\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.5544e-04 - val_mae: 0.0202\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 7.9383e-04 - val_mae: 0.0200\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 6.8662e-04 - val_mae: 0.0190\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0246 - val_loss: 7.4725e-04 - val_mae: 0.0196\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.6897e-04 - val_mae: 0.0196\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 9.4803e-04 - val_mae: 0.0231\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0235\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0237 - val_loss: 7.3304e-04 - val_mae: 0.0198\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.9748e-04 - val_mae: 0.0205\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0238 - val_loss: 7.7999e-04 - val_mae: 0.0201\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 8.2497e-04 - val_mae: 0.0211\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 7.6516e-04 - val_mae: 0.0193\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.5342e-04 - val_mae: 0.0197\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.5700e-04 - val_mae: 0.0188\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 7.9533e-04 - val_mae: 0.0208\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 7.6789e-04 - val_mae: 0.0201\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 7.5050e-04 - val_mae: 0.0195\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 7.1492e-04 - val_mae: 0.0188\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0013 - mae: 0.0239 - val_loss: 8.1595e-04 - val_mae: 0.0221\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0236 - val_loss: 8.5139e-04 - val_mae: 0.0212\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 8.2207e-04 - val_mae: 0.0204\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 7.2581e-04 - val_mae: 0.0193\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0235 - val_loss: 8.2371e-04 - val_mae: 0.0213\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 7.8684e-04 - val_mae: 0.0198\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0013 - mae: 0.0240 - val_loss: 7.2433e-04 - val_mae: 0.0193\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 8.6000e-04 - val_mae: 0.0218\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.3446e-04 - val_mae: 0.0193\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 8.2745e-04 - val_mae: 0.0210\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 8.0221e-04 - val_mae: 0.0198\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn20lEQVR4nO3deXxU9b3/8deHBIIkhDVuBCXIoiB7gLpQwRWXigtU+HErXLxuXaz0tmrvvUV+Lq22tnpta1tbV+pP3KrFKxWvWsXWjYCgIDtECSBCkLAGSPL9/fGZyTYJJBAy4fB+Ph7zyMyZMzPfOWfyPt/zOZuFEBARkehqluwGiIjIoaWgFxGJOAW9iEjEKehFRCJOQS8iEnGpyW5AdR07dgxdunRJdjNERA4rc+fO3RRCyKrpuSYX9F26dCEvLy/ZzRAROayY2We1PafSjYhIxCnoRUQiTkEvIhJxTa5GLyKNZ+/evRQUFFBcXJzspkgdtWzZkuzsbJo3b17n1yjoRY5gBQUFtG7dmi5dumBmyW6O7EcIgcLCQgoKCsjJyanz61S6ETmCFRcX06FDB4X8YcLM6NChQ73XwBT0Ikc4hfzh5UDmV3SCvqAApkyBZcuS3RIRkSYlOkG/fj3ceScsX57slohIHRQWFtK/f3/69+/PscceS6dOncof79mzZ5+vzcvL46abbtrvZ5x++ukN0ta33nqLSy65pEHeKxmiszG2WWyZVVaW3HaISJ106NCB+fPnAzB16lQyMjL44Q9/WP58SUkJqak1R1Rubi65ubn7/Yx33323Qdp6uItOjz4e9KWlyW2HiBywiRMncsMNNzB06FBuueUWPvzwQ0477TQGDBjA6aefztKlS4GqPeypU6cyadIkhg8fTteuXXnwwQfL3y8jI6N8/OHDhzN69GhOPvlkxo8fT/zqejNnzuTkk09m0KBB3HTTTfXquT/99NP06dOHU089lVtvvRWA0tJSJk6cyKmnnkqfPn24//77AXjwwQfp1asXffv2ZezYsQc/seohOj36lBT/qx69yIG5+WaI9bAbTP/+8MAD9XpJQUEB7777LikpKWzdupV33nmH1NRUXn/9df7jP/6DF154IeE1S5Ys4e9//zvbtm2jZ8+e3HjjjQn7mX/00UcsWrSI448/njPOOIN//vOf5Obmcv311zN79mxycnIYN25cndu5bt06br31VubOnUu7du04//zzeemll+jcuTNr165l4cKFAGzZsgWAe+65h9WrV5OWllY+rLFEr0evoBc5rI0ZM4aUWMetqKiIMWPGcOqppzJ58mQWLVpU42suvvhi0tLS6NixI0cffTQbNmxIGGfIkCFkZ2fTrFkz+vfvT35+PkuWLKFr167l+6TXJ+jnzJnD8OHDycrKIjU1lfHjxzN79my6du3KqlWr+N73vserr75KZmYmAH379mX8+PH8+c9/rrUkdahEp0evoBc5OPXseR8q6enp5fd/8pOfMGLECF588UXy8/MZPnx4ja9JS0srv5+SkkJJSckBjdMQ2rVrx4IFC5g1axa///3vefbZZ3n00Ud55ZVXmD17Ni+//DJ33303n3zySaMFfvR69KrRi0RGUVERnTp1AuDxxx9v8Pfv2bMnq1atIj8/H4Bnnnmmzq8dMmQIb7/9Nps2baK0tJSnn36as846i02bNlFWVsaVV17JXXfdxbx58ygrK2PNmjWMGDGCe++9l6KiIrZv397g36c20enRq0YvEjm33HILEyZM4K677uLiiy9u8Pc/6qijeOihhxg5ciTp6ekMHjy41nHfeOMNsrOzyx8/99xz3HPPPYwYMYIQAhdffDGjRo1iwYIF/Ou//itlsSz62c9+RmlpKf/yL/9CUVERIQRuuukm2rZt2+DfpzYW3/LcVOTm5oYDuvDIypXQrRs8+SR861sN3zCRCFq8eDGnnHJKspuRVNu3bycjI4MQAt/5znfo3r07kydPTnaz9qmm+WZmc0MINe5zqtKNiBzR/vjHP9K/f3969+5NUVER119/fbKb1OBUuhGRI9rkyZObfA/+YEWvR6+gFxGpInpBr9KNiEgV0Ql6lW5ERGoUnaBX6UZEpEYKehFJmhEjRjBr1qwqwx544AFuvPHGWl8zfPhw4rtgX3TRRTWeN2bq1Kncd999+/zsl156iU8//bT88ZQpU3j99dfr0fqaNcVTGkcv6FWjFzlsjBs3junTp1cZNn369Dqfc2bmzJkHfOBR9aC/4447OPfccw/ovZq66AS9avQih53Ro0fzyiuvlF9oJD8/n3Xr1jFs2DBuvPFGcnNz6d27N7fffnuNr+/SpQubNm0C4O6776ZHjx6ceeaZ5aczBt9PfvDgwfTr148rr7ySnTt38u677zJjxgx+9KMf0b9/f1auXMnEiRN5/vnnAT8KdsCAAfTp04dJkyaxe/fu8s+7/fbbGThwIH369GHJkiV1/q7JPKVxdPajV+lG5KAk4yzF7du3Z8iQIfztb39j1KhRTJ8+nW9+85uYGXfffTft27entLSUc845h48//pi+ffvW+D5z585l+vTpzJ8/n5KSEgYOHMigQYMAuOKKK7j22msB+K//+i8eeeQRvve973HppZdyySWXMHr06CrvVVxczMSJE3njjTfo0aMHV199Nb/73e+4+eabAejYsSPz5s3joYce4r777uNPf/rTfqdDsk9pHJ0evUo3IoelyuWbymWbZ599loEDBzJgwAAWLVpUpcxS3TvvvMPll19Oq1atyMzM5NJLLy1/buHChQwbNow+ffrw1FNP1Xqq47ilS5eSk5NDjx49AJgwYQKzZ88uf/6KK64AYNCgQeUnQ9ufZJ/SODo9epVuRA5Kss5SPGrUKCZPnsy8efPYuXMngwYNYvXq1dx3333MmTOHdu3aMXHiRIqLiw/o/SdOnMhLL71Ev379ePzxx3nrrbcOqr3x0x03xKmOG+uUxtHr0SvoRQ4rGRkZjBgxgkmTJpX35rdu3Up6ejpt2rRhw4YN/O1vf9vne3z961/npZdeYteuXWzbto2XX365/Llt27Zx3HHHsXfvXp566qny4a1bt2bbtm0J79WzZ0/y8/NZsWIFANOmTeOss846qO+Y7FMaR6dHr6AXOWyNGzeOyy+/vLyE069fPwYMGMDJJ59M586dOeOMM/b5+oEDB3LVVVfRr18/jj766CqnG77zzjsZOnQoWVlZDB06tDzcx44dy7XXXsuDDz5YvhEWoGXLljz22GOMGTOGkpISBg8ezA033FCv79PUTmkcndMUh+Bhf/vtMHVqg7dLJIp0muLD05F7mmIzv6lHLyJSRXSCHrxHr6AXEakiekGv3StF6qWplW9l3w5kfkUr6FNS1KMXqYeWLVtSWFiosD9MhBAoLCykZcuW9XpddPa6AZVuROopOzubgoICNm7cmOymSB21bNmyyh49dVGnoDezkcB/AynAn0II91R7Pg14EhgEFAJXhRDyKz1/AvApMDWEsO9Tyh0MlW5E6qV58+bk5OQkuxlyiO23dGNmKcBvgQuBXsA4M+tVbbRrgK9CCN2A+4F7qz3/K2DfRzw0BJVuREQS1KVGPwRYEUJYFULYA0wHRlUbZxTwROz+88A5ZmYAZnYZsBrY9wkmGoJKNyIiCeoS9J2ANZUeF8SG1ThOCKEEKAI6mFkGcCvwf/f1AWZ2nZnlmVneQdUKFfQiIgkO9V43U4H7Qwj7PFFDCOHhEEJuCCE3KyvrwD8tJUU1ehGRauqyMXYt0LnS4+zYsJrGKTCzVKANvlF2KDDazH4OtAXKzKw4hPCbg214jdSjFxFJUJegnwN0N7McPNDHAv+n2jgzgAnAe8Bo4M3gO+YOi49gZlOB7Ycs5EFBLyJSg/0GfQihxMy+C8zCd698NISwyMzuAPJCCDOAR4BpZrYC2IwvDBqfdq8UEUlQp/3oQwgzgZnVhk2pdL8YGLOf95h6AO2rH+1eKSKSIFqnQFDpRkQkQfSCXqUbEZEqohX0Kt2IiCSIVtCrdCMikkBBLyIScdELetXoRUSqiFbQq0YvIpIgWkGv0o2ISILoBb1KNyIiVUQr6FW6ERFJEK2gV+lGRCSBgl5EJOKiFfS68IiISIJoBb169CIiCRT0IiIRF72gV+lGRKSKaAW9dq8UEUkQraBX6UZEJEH0gl6lGxGRKqIV9CrdiIgkiFbQq3QjIpJAQS8iEnHRCnodGSsikiBaQa8evYhIAgW9iEjERS/oVboREakiWkGv3StFRBJEK+hVuhERSaCgFxGJuGgFvXavFBFJEK2gV49eRCSBgl5EJOKiFfQq3YiIJKhT0JvZSDNbamYrzOy2Gp5PM7NnYs9/YGZdYsOHmNn82G2BmV3ewO2vSj16EZEE+w16M0sBfgtcCPQCxplZr2qjXQN8FULoBtwP3BsbvhDIDSH0B0YCfzCz1AZqeyIFvYhIgrr06IcAK0IIq0IIe4DpwKhq44wCnojdfx44x8wshLAzhFASG94SCA3R6FrpyFgRkQR1CfpOwJpKjwtiw2ocJxbsRUAHADMbamaLgE+AGyoFfzkzu87M8swsb+PGjfX/FnE6MlZEJMEh3xgbQvgghNAbGAz82Mxa1jDOwyGE3BBCblZW1oF/mEo3IiIJ6hL0a4HOlR5nx4bVOE6sBt8GKKw8QghhMbAdOPVAG7tfCnoRkQR1Cfo5QHczyzGzFsBYYEa1cWYAE2L3RwNvhhBC7DWpAGZ2InAykN8gLa+Jdq8UEUmw3z1gQgglZvZdYBaQAjwaQlhkZncAeSGEGcAjwDQzWwFsxhcGAGcCt5nZXqAM+HYIYdOh+CKAevQiIjWo066OIYSZwMxqw6ZUul8MjKnhddOAaQfZxrpr1gxC8JtZo32siEhTFr0jY0G9ehGRSqIV9M1iX0dBLyJSTkEvIhJx0Qx67XkjIlIuWkGvGr2ISIJoBb1KNyIiCRT0IiIRF62gj5duVKMXESkXraBXj15EJIGCXkQk4qIV9CrdiIgkiFbQq0cvIpJAQS8iEnEKehGRiItW0KtGLyKSIFpBrx69iEgCBb2ISMRFK+hVuhERSRCtoFePXkQkgYJeRCTiohX0Kt2IiCSIVtCrRy8ikkBBLyIScQp6EZGIi1bQq0YvIpIgWkGvHr2ISAIFvYhIxEUr6FW6ERFJEK2gV49eRCSBgl5EJOKiFfQq3YiIJIhW0KtHLyKSQEEvIhJxdQp6MxtpZkvNbIWZ3VbD82lm9kzs+Q/MrEts+HlmNtfMPon9PbuB21+Vgl5EJMF+g97MUoDfAhcCvYBxZtar2mjXAF+FELoB9wP3xoZvAr4RQugDTACmNVTDa6QavYhIgrr06IcAK0IIq0IIe4DpwKhq44wCnojdfx44x8wshPBRCGFdbPgi4CgzS2uIhtdIPXoRkQR1CfpOwJpKjwtiw2ocJ4RQAhQBHaqNcyUwL4Swu/oHmNl1ZpZnZnkbN26sa9sTKehFRBI0ysZYM+uNl3Our+n5EMLDIYTcEEJuVlbWgX+QSjciIgnqEvRrgc6VHmfHhtU4jpmlAm2AwtjjbOBF4OoQwsqDbfA+qUcvIpKgLkE/B+huZjlm1gIYC8yoNs4MfGMrwGjgzRBCMLO2wCvAbSGEfzZQm2unoBcRSbDfoI/V3L8LzAIWA8+GEBaZ2R1mdmlstEeADma2AvgBEN8F87tAN2CKmc2P3Y5u8G8RFy/dKOhFRMql1mWkEMJMYGa1YVMq3S8GxtTwuruAuw6yjXUX79GrRi8iUk5HxoqIRJyCXkQk4qIV9Nq9UkQkQbSCXj16EZEECnoRkYiLVtCrdCMikiBaQa8evYhIAgW9iEjEKehFRCIuWkGvGr2ISIJoBb169CIiCRT0IiIRF62gV+lGRCRBtILezP+qRy8iUi5aQQ9evlHQi4iUi17Qp6Qo6EVEKole0Ddrphq9iEgl0Qx69ehFRMop6EVEIi56QZ+SotKNiEgl0Qt69ehFRKpQ0IuIRFz0gl6lGxGRKqIX9OrRi4hUoaAXEYm46AW9jowVEakiekGvI2NFRKqIZtCrRy8iUk5BLyIScdELeu1eKSJSRfSCXj16EZEqFPQiIhEXvaBX6UZEpIo6Bb2ZjTSzpWa2wsxuq+H5NDN7Jvb8B2bWJTa8g5n93cy2m9lvGrjtNVOPXkSkiv0GvZmlAL8FLgR6AePMrFe10a4BvgohdAPuB+6NDS8GfgL8sMFavD8KehGRKurSox8CrAghrAoh7AGmA6OqjTMKeCJ2/3ngHDOzEMKOEMI/8MBvHDoyVkSkiroEfSdgTaXHBbFhNY4TQigBioAODdHAetORsSIiVTSJjbFmdp2Z5ZlZ3saNGw/uzVS6ERGpoi5BvxboXOlxdmxYjeOYWSrQBiisayNCCA+HEHJDCLlZWVl1fVnNFPQiIlXUJejnAN3NLMfMWgBjgRnVxpkBTIjdHw28GUIIDdfMetDulSIiVaTub4QQQomZfReYBaQAj4YQFpnZHUBeCGEG8AgwzcxWAJvxhQEAZpYPZAItzOwy4PwQwqcN/k3i1KMXEaliv0EPEEKYCcysNmxKpfvFwJhaXtvlINpXfwp6EZEqmsTG2Aal3StFRKqIXtBr90oRkSqiGfTq0YuIlIte0Kt0IyJSRfSCXqUbEZEqohn06tGLiJSLXtCnpMCOHZCk47VERJqa6AX92WfD8uXwl78kuyUiIk1C9IL+hhugXz+4+WbYti3ZrRERSbroBX1qKjz0EKxdC5dcAlu3JrtFIiJJVadTIBx2Tj8dnnoKrr4aeveGs86C3bshPR1uvRU6doSVK6GoCJo3h2OPhVNOAbNkt1xEpMFFM+gBxo2DrCz4zW/g7bchIwMKCuCJJ2oev3NnuPRSGDQI8vKge3cvA7Vs2bjtFhFpYJasswnXJjc3N+Tl5R2aN9+4ER5+GI46Ck4+Gdq2hZIS33j78svw2muwaxe0agU7d/rzZWVwzDFw/vlwwQXQvz+0a+cLDhGRJsLM5oYQcmt87ogK+v3ZtQtWrYKePeGdd+DPf/Zyz6pV8Pe/e/iD76t/yy1w552+TUBEJMkU9A1h92745z+9tv+Pf8CTT8LAgfCjH8HIkd77FxFJkn0FffT2ujlU0tJ8H/1rr/U6/9NP+x4948Z5KefMM70EJCLSxCjoD9TYsbB0Kbz5JtxxB3z6qffw//d/k90yEZEqFPQHo1kzGDECfvITmD8funaFyy+HDz5IdstERMop6BvKCSfArFm+h86wYX6w1ty5yW6ViIiCvkEde6zvs//97/u++GecAY88orNpikhSKegbWnY2/OIXsHChH6H7b//m+94/8UTF7pkiIo0oMkG/Zg184xt+8GuT0LGjb5j985/9oKyJE73H/81vwh//6BtyRUQaQWT2o1+8GIYM8VPbvP227w3ZZIQAs2d76P/P/8AXX/jwCy+Eiy/2xrZoAcXFfi79o4+GTp287p+To3PwiMh+HTEHTD3/PIwZAzfe6CewbJJCgBUr4Lnn4Fe/gsLCfY9/3HG+cbdnT/jsM9i+HXr18tM0dOzoX1gHa4kc8Y6YoAc/M8EvfgGPPw4TJjRcuw6JPXtgyxb/u3u39+zT0+HLL70GtWKFn3rhww9h9WoP/YwMPzo3voG3ZUvo29dft3ix7/Vzxhl+ANfXvgZdumiNQOQIcEQFfUmJn3/svfdg/HjPvPHjvTJSUuJnLx42zHd5r6vPP4ef/9x3pune/YCbdnD27vVTKsfvl5XBokUwbZr/3bbNT9S2Zg28/76XgADatPGef+/eMHgwLFjgC5Thw6FbN994nJ2ts3SKHOaOqKAH7xBPmuQd4Y0bK85AnJfnxzJlZsJPfwonnugh/tVXnnt9+kDr1lU7wF9+WXF2gzZt/Dxmp53mZzNush3lkhL4+GP/sosWeXno/fchP9+/9K5d/sXizPzL9+3rawxLlvi1d6+91peImzf7id2GDYNTT03a1xKR2h1xQR8Xgp95+Je/hHff9Y7sT3/qZZ3336/5NS1aeAc4Lc23jX75pQ977DEvCcWPgerbF267zUvktZ3AcsECP4bq3//dczOpQvBz87RpU7Gd4PPPfQ1g1SqfIMuX+5pBt26+hFy1KvF9zj3Xw75FC99dtLjYtxmcf74vQDIzfQNyCF6SKitLXHqKSIM7YoO+stJSz57UVL+/eLHn1PHHe3n7zTc91zZt8owrKfEsO+YYuOwyr3qUlXmp/K23fOGxeLGXwPv1822jIcBVV8GoUd6J7t/fr2j44x/7Aga86pKaevC59+KLfjLNu+46RFWX0lI/S+f27R7enTr5sQB/+YtPqNJS/9LNm1ddO6hJ27a+9Cwr8/dKS/NtEkcd5Y/jtxYtKoa3aVOxUDLzPZCaNfOSVFqaf+n4rlWFhbB+vX9Gp04+U9u18xn8+ee+FnPSSf76r77ytmdl+czYsUMbsyUSFPSHQFkZ/PWvvkv82rWeKdu3+56Tffr4OEuXwnnnwSuveK8+JwemTPGFxlNPeVg/9xx88olvS7juOh9/yxZf0HTsmPi5u3f72sW3v+0ZePbZ8NJL3mmO27LFz8AwdCjcd18jdKZXrPA1gsxMD9LPPvOlWYsWPqHy871RZr5WsWePh/SuXf44ftu92wN81y6/zGNpacO208wnGkD79r72snevH9+Qne1tKiz0iZ+a6gux4mKfua1a+URu3drLWxkZVcfPyvLxW7Xy92rWzHsNy5f7a44/3l+Tnu7vvWOHPz7+eN/IvmmTb2RPT/cFT3p6xfWOO3aEDh18WAgV3yElpeLWrJlPs507fQHZrp2/T4sWFd+/rMyngdauIklB30hKSvyMB88+C8uWeahPmODHSj3zjP+fDRzoJR0zH79nT+/5v/22LyTOPts3JO/e7Ze67dPH87OoyMtGeXmek+efD6NH+66kOTnw6197ZqSmws03V5xE8/vf9xNt9ujh2bZ1q5ft42dUzsuD11/3bbXf+pZvy6jNzp1eCps/3/+uWwczZ3rlpj6++MLXRMaP9+0dNQrBP9DMA//zz314erpPgF27fCKBB9pxx3norl3rDSsq8pDr3NlXw9asYfsOI+O42BJx8WIPz3bt/P6XX/p7dujAprL2zCrozdjj3ialZSy8d+3yBUP8tmOHLwQ6dvSQ3bjRZ/C2bb5QA//8k07ycdev94VKY2vVyqfh7t3+g0tL8x9CfNWyVStv+/bt/j3MfGHbtm3FgqK42BdK8em1datP35Yt/bvt3OnHfhx7bMUlO4uL/bPS0nz+FRf7+K1a+Txs1co/r7jY1+DKymDDBh+ndeuKhVfz5j5+cbHfMjP97/bt3p6MjIpxKy/4Ki8AQ6h4fWmpf6fmzav+jX/u7t3+3vHhpaX+fTIzvWRZ0wE6paX+29uxw6dpvJOQmurjH3WU31q18uke32su3nFo3dqfKy729rZrd0CzWkHfBBQU+Pz9+tc9JB96yEP6ggsq/g/vugv+8Ac/hqpTJz+2auVK/91lZPh2gdNP99vFF/vvcPZsD+h4DsY98gjMmQO//33FsKws/5+uLC3N27Rokefjtdf6561d62sEOTn+PxyCb5NYudLbm5vrn5ma6guKk0/29ystrai+xDuO8+b5/8HXvuYbyCdN8tempPh73nabf7+SEl+7efFFH3/KFC+dxa1e7WeWGDnSs+Wtt+Cii/x/assW/1tW5v9vxxxTteM6bRpcc42vNf36197OlJTEzu3Wrb5h/qOP4N57fXfdmnz2mZ+d+gc/8IXkjh0+DVu3hlNOiO3x1LJl1Y0zsVJR2LMXa51RMaHXrfNQ7dGDsKuYss1bSNm1nV1pbWlmgbRtm7zHH1/wxRtdWuq3sjL/m5npgbF1q69Zbdnif0OoCN0dO3xY8+Y+wbdv9xncurWPV1ZWsUa1ZUvFzNy2zWfK5s2+xtC2rQdTq1b+/MaNvgTfts1/vOnp/trdu30axMt1O3f6bccO/6z4GpwZHHMMu4qNwq3NyabAv9OePf7XrGLDWUpK1TWeg1RIe0pJ4Wg27n/kQ23sWL/WxQFQ0B/G4rNnX2vbW7d64Mc7bccf7zvIhODB+fnn/nf5ct/O2qePB7OZ/49nZnoG3XILPPCAd/i6dfOwq9wJzcnxa62fdZb/n33yid/fssXLUStXVhz/lZrqndn4ed4qO+44L109/rhfqCsryztn+fkVnZrUVM+Tiy7yYcuWeXvA106++sqzpW9ff79Zs6p+Rk6Or2nEt7fMm+ed+zVrfAH20UcV21fef9/b2aeP31+61Ne85s+H66/3hUtWlufxp5/6mahnzfKMbt/eH0+b5plkBpMn+5pZSUnFLZ6fjz3mC7vLLvOFdY8evsA288+57TYf/4ILvDTYooXPkwEDfGHYqVNFOxYv9nm7a5fP8zVrPGtPPNG/12mnwSmn+DLivff8ddnZvj09XpVatw5eeMHfY8QIf//mzf03tXix/2bWr/e10KIi7xScfba3Z88eny7t2vmC7513/DuceKJ/r9at/VLMKSl+EHjz5j5vMzO98z57tncSBgzwUmPr1nD11V4JvPdeX+CuXAmrl5fw1dYUvthgzP+ojM6djcsuN3rk7KVzx10c06GEbVsDc+Y2Y85HKXQ7YS/tM0so3GyceOxu2mQGNu04in4DmtG+YzO+2ljCpg2lvPZmKr/8UyarC1rQPLWMn1+7gvNO285nW9pwVPMStmyBzVtT6T4gg6zUr2i2eiUpoYStu5qzaXsarVuW0CFjNx0y99K2c2u+2N2Ot+dm8Nm65hTvhqyMYgaf+CXHttzCPxa2pRU7OSlrK50HZvH2p1l8vKQFF/ZcxZ5txXySn0lmRhndB7dl8Pe+diBRoaCXuluzxnvD8eMONm3yqsbmzR7m6elVx1+3ztdO3nzTQ6VLl4oe9sKF/k979dVenvrwQw/mc8/1f3bwAPrVr/z+CSd4wJ57ri8wvv1t78U3b+57eQ4f7guPn/3MA3bMGF8LKi31NZGMjIqFxBtveBAfc4wHTe/evmvsD37gR1BfcYUvPJYt80Bct84Dvls3354yYoS3ecMGD6LNm/0zu3b1NY62bX3ta/Jkn2YTJ3pwz5pVdS2quhNOgHPO8RDfvDnx+UGDfKHz2mu+MFi92strcZU3M0BFVSDevuOP99Ddts2fz8jwzvP+/s1TUmrfJNK2rVct0tN9B4Dt22t/bWqq/27iUlP9s2t771NP9XmwZ48/7tjRp3f16/ekpvr369fPF0AHck6rZs28Q1F5rfaMM/y3MHu2z5MDVX2+HKiD6NAffNCb2Ujgv4EU4E8hhHuqPZ8GPAkMAgqBq0II+bHnfgxcA5QCN4UQqvW9qlLQS33Eqw2HYvfVoiIPh8obuqFiraVDBx9nxw4P2Lhly3x4vFwbLxU3a+ZrGvGqyYoV3mONV18yMnwBU/m7lJTAq696tWPLFu/BZ2f7QvWUU7xHbVZREo8HzrJlvnby4Ye+sDvvPO9pL1rkO1Olplbs9DRypK89vfeef7e9ez3Ue/TwbUiV9+rau9cXPEuW+Od98YV3BnJy/FxTffr4wnHZMu8gjBjhr4t/Zmmpry1kZXnIZ2f7tHrvPZ8Wo0b5WsVf/+rf/aSTfOHapk1FG8rKfKH8+ed++/JLn0c9e3pZc9Uqnyft2lXcb9vW1zjWr/e12WOP9YX60KEV0+yFF3ytOCfH/8YrVMuXV+ysVVrqn5WV5QvTzZt9mhUW+vDzzvODKtPSfDq88463b9gwf+3Klb7m2ru3T69XX/Xq1+DBvlbVooV//oE4qKA3sxRgGXAeUADMAcaFED6tNM63gb4hhBvMbCxweQjhKjPrBTwNDAGOB14HeoQQat2dQkEvIlJ/B3tx8CHAihDCqhDCHmA6MKraOKOAJ2L3nwfOMTOLDZ8eQtgdQlgNrIi9n4iINJK6BH0nYE2lxwWxYTWOE0IoAYqADnV8LWZ2nZnlmVnexuq7hYiIyEFpEhceCSE8HELIDSHkZmVlJbs5IiKRUpegXwt0rvQ4OzasxnHMLBVog2+UrctrRUTkEKpL0M8BuptZjpm1AMYCM6qNMwOIn/19NPBm8K28M4CxZpZmZjlAd+DDhmm6iIjURS3nXawQQigxs+8Cs/DdKx8NISwyszuAvBDCDOARYJqZrQA24wsDYuM9C3wKlADf2dceNyIi0vB0wJSISAQc7O6VIiJyGGtyPXoz2wh8dhBv0RHY1EDNaUhqV/2oXfXXVNumdtXPgbbrxBBCjbstNrmgP1hmllfb6ksyqV31o3bVX1Ntm9pVP4eiXSrdiIhEnIJeRCTiohj0Dye7AbVQu+pH7aq/pto2tat+GrxdkavRi4hIVVHs0YuISCUKehGRiItM0JvZSDNbamYrzOy2JLajs5n93cw+NbNFZvb92PCpZrbWzObHbhclqX35ZvZJrA15sWHtzex/zWx57O+BXYb+wNvUs9J0mW9mW83s5mRMMzN71My+NLOFlYbVOH3MPRj7zX1sZgMbuV2/MLMlsc9+0czaxoZ3MbNdlabbPi5ueMjaVuu8M7Mfx6bZUjO7oJHb9UylNuWb2fzY8EabZvvIiEP3OwshHPY3/Bw8K4GuQAtgAdArSW05DhgYu98avzpXL2Aq8MMmMK3ygY7Vhv0cuC12/zbg3iTPyy+AE5MxzYCvAwOBhfubPsBFwN8AA74GfNDI7TofSI3dv7dSu7pUHi9J06zGeRf7X1gApAE5sf/blMZqV7XnfwlMaexpto+MOGS/s6j06OtyFaxGEUJYH0KYF7u/DVhMDRdbaWIqXyHsCeCy5DWFc4CVIYSDOTr6gIUQZuMn5qustukzCngyuPeBtmZ2XGO1K4TwWvAL/QC8j58GvNHVMs1q02hXndtXu8zMgG/ilzptVPvIiEP2O4tK0NfpSlaNzcy6AAOAD2KDvhtb9Xq0scsjlQTgNTOba2bXxYYdE0JYH7v/BXBMcpoG+JlPK//zNYVpVtv0aUq/u0l4ry8ux8w+MrO3zWxYktpU07xrKtNsGLAhhLC80rBGn2bVMuKQ/c6iEvRNjpllAC8AN4cQtgK/A04C+gPr8dXGZDgzhDAQuBD4jpl9vfKTwdcVk7LPrfn1Di4FnosNairTrFwyp09tzOw/8dOAPxUbtB44IYQwAPgB8P/MLLORm9Xk5l0146jaoWj0aVZDRpRr6N9ZVIK+SV3Jysya4zPwqRDCXwBCCBtCCKUhhDLgjyTpIukhhLWxv18CL8basSG+Khj7+2Uy2oYvfOaFEDbE2tgkphm1T5+k/+7MbCJwCTA+Fg7EyiKFsftz8Tp4j8Zs1z7mXVOYZqnAFcAz8WGNPc1qyggO4e8sKkFfl6tgNYpY7e8RYHEI4VeVhleuqV0OLKz+2kZoW7qZtY7fxzfmLaTqFcImAH9t7LbFVOllNYVpFlPb9JkBXB3bK+JrQFGlVe9DzsxGArcAl4YQdlYanmVmKbH7XfEru61qrHbFPre2edcUrjp3LrAkhFAQH9CY06y2jOBQ/s4aYytzY9zwLdPL8CXxfyaxHWfiq1wfA/Njt4uAacAnseEzgOOS0Lau+B4PC4BF8ekEdADeAJYDrwPtk9C2dPw6w20qDWv0aYYvaNYDe/Fa6DW1TR98L4jfxn5znwC5jdyuFXjtNv47+31s3Ctj83c+MA/4RhKmWa3zDvjP2DRbClzYmO2KDX8cuKHauI02zfaREYfsd6ZTIIiIRFxUSjciIlILBb2ISMQp6EVEIk5BLyIScQp6EZGIU9CLiEScgl5EJOL+P+pK6CFXOucxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2168, 6)\n",
      "The Mean Squared Error is: 13.035554989125762\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Seq2Seq')\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_seq.fit(x_train,y_train_seq,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_seq.load_weights(filepath_attention)\n",
    "preds = atten_seq.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('Seq2Seq Results.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_wavenet.hdf5'\n",
    "filepath_attention = 'attention_wavenet.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 128\n",
    "filter_width = 2\n",
    "dilation_rates = [2**i for i in range(7)]\n",
    "\n",
    "inputs = keras.layers.Input(shape=(x_train.shape[1],x_train.shape[2]))\n",
    "x=inputs\n",
    "\n",
    "skips = []\n",
    "for dilation_rate in dilation_rates:\n",
    "\n",
    "    x   = keras.layers.Conv1D(64, 1, padding='same')(x) \n",
    "    x_f = keras.layers.Conv1D(filters=n_filters,kernel_size=filter_width,padding='causal',dilation_rate=dilation_rate)(x)\n",
    "    x_g = keras.layers.Conv1D(filters=n_filters,kernel_size=filter_width, padding='causal',dilation_rate=dilation_rate)(x)\n",
    "\n",
    "    z = keras.layers.Multiply()([keras.layers.Activation('tanh')(x_f),keras.layers.Activation('sigmoid')(x_g)])\n",
    "\n",
    "    z = keras.layers.Conv1D(64, 1, padding='same', activation='relu')(z)\n",
    "\n",
    "    x = keras.layers.Add()([x, z])    \n",
    "\n",
    "    skips.append(z)\n",
    "\n",
    "out = keras.layers.Activation('relu')(keras.layers.Add()(skips)) \n",
    "out = keras.layers.Conv1D(128, 1, padding='same')(out)\n",
    "out = keras.layers.Activation('relu')(out)\n",
    "out = keras.layers.Dropout(0.4)(out)\n",
    "out = keras.layers.Conv1D(1, 1, padding='same')(out)\n",
    "\n",
    "out = keras.layers.Flatten()(out)\n",
    "out = keras.layers.Dense(6)(out)\n",
    "\n",
    "simple_wavenet = keras.Model(inputs, out)\n",
    "\n",
    "simple_wavenet.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "(2168, 6)\n",
      "The Mean Squared Error is: 13.390524851173161\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'Wavenet'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Wavenet')\n",
    "    os.chdir(os.path.join(dest,'Wavenet'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_wavenet.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_wavenet.load_weights(filepath_simple)\n",
    "preds = simple_wavenet.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 6, 2)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 6, 64)        192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 6, 128)       16512       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 6, 128)       16512       conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 6, 128)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 6, 128)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, 6, 128)       0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 6, 64)        8256        multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 64)        0           conv1d_30[0][0]                  \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 6, 64)        4160        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 6, 128)       16512       conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 6, 128)       16512       conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 6, 128)       0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 6, 128)       0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, 6, 128)       0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 6, 64)        8256        multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 6, 64)        0           conv1d_34[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 6, 64)        4160        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 6, 128)       16512       conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 6, 128)       16512       conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 6, 128)       0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 6, 128)       0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, 6, 128)       0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 6, 64)        8256        multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 6, 64)        0           conv1d_38[0][0]                  \n",
      "                                                                 conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 6, 64)        4160        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 6, 128)       16512       conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 6, 128)       16512       conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 6, 128)       0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 6, 128)       0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, 6, 128)       0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 6, 64)        8256        multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 6, 64)        0           conv1d_42[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 6, 64)        4160        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 6, 128)       16512       conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 6, 128)       16512       conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 6, 128)       0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 6, 128)       0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, 6, 128)       0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 6, 64)        8256        multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 6, 64)        0           conv1d_46[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 6, 64)        4160        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 6, 128)       16512       conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 6, 128)       16512       conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 128)       0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 6, 128)       0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, 6, 128)       0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 6, 64)        8256        multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 6, 64)        0           conv1d_50[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 6, 64)        4160        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 6, 128)       16512       conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 6, 128)       16512       conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 6, 128)       0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 6, 128)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, 6, 128)       0           activation_28[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 6, 64)        8256        multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 6, 64)        0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_37[0][0]                  \n",
      "                                                                 conv1d_41[0][0]                  \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "                                                                 conv1d_49[0][0]                  \n",
      "                                                                 conv1d_53[0][0]                  \n",
      "                                                                 conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 6, 64)        0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention (attention)           (None, 6, 64)        70          activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 6, 128)       8320        attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 6, 128)       0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 128)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 6, 1)         129         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 6)            0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            42          flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 322,673\n",
      "Trainable params: 322,673\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Attention model\n",
    "n_filters = 128\n",
    "filter_width = 2\n",
    "dilation_rates = [2**i for i in range(7)]\n",
    "\n",
    "inputs = Input(shape=(x_train.shape[1],x_train.shape[2]))\n",
    "x=inputs\n",
    "\n",
    "skips = []\n",
    "for dilation_rate in dilation_rates:\n",
    "\n",
    "    x   = Conv1D(64, 1, padding='same')(x) \n",
    "    x_f = Conv1D(filters=n_filters,kernel_size=filter_width,padding='causal',dilation_rate=dilation_rate)(x)\n",
    "    x_g = Conv1D(filters=n_filters,kernel_size=filter_width, padding='causal',dilation_rate=dilation_rate)(x)\n",
    "\n",
    "    z = Multiply()([keras.layers.Activation('tanh')(x_f),keras.layers.Activation('sigmoid')(x_g)])\n",
    "\n",
    "    z = Conv1D(64, 1, padding='same', activation='relu')(z)\n",
    "\n",
    "    x = Add()([x, z])    \n",
    "\n",
    "    skips.append(z)\n",
    "\n",
    "out = Activation('relu')(keras.layers.Add()(skips)) \n",
    "out = attention(return_sequences=True)(out)\n",
    "out = Conv1D(128, 1, padding='same')(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(0.4)(out)\n",
    "out = Conv1D(1, 1, padding='same')(out)\n",
    "# out = attention(return_sequences=True)(out)\n",
    "out = Flatten()(out)\n",
    "out = Dense(6)(out)\n",
    "\n",
    "atten_wavenet = keras.Model(inputs, out)\n",
    "\n",
    "atten_wavenet.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])\n",
    "atten_wavenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 3s 11ms/step - loss: 0.0280 - mae: 0.1155 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0058 - mae: 0.0565 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0044 - mae: 0.0495 - val_loss: 0.0014 - val_mae: 0.0279\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0438 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0033 - mae: 0.0422 - val_loss: 0.0012 - val_mae: 0.0268\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.0013 - val_mae: 0.0261\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0026 - mae: 0.0368 - val_loss: 0.0012 - val_mae: 0.0249\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0247\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0026 - mae: 0.0366 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0024 - mae: 0.0350 - val_loss: 0.0011 - val_mae: 0.0235\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0023 - mae: 0.0347 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0021 - mae: 0.0327 - val_loss: 9.7202e-04 - val_mae: 0.0220\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0333 - val_loss: 9.3401e-04 - val_mae: 0.0216\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0022 - mae: 0.0334 - val_loss: 9.2389e-04 - val_mae: 0.0226\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0322 - val_loss: 0.0012 - val_mae: 0.0278\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0020 - mae: 0.0318 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0019 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0232\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0019 - mae: 0.0307 - val_loss: 9.1926e-04 - val_mae: 0.0223\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 9.2929e-04 - val_mae: 0.0228\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0304 - val_loss: 8.5774e-04 - val_mae: 0.0217\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 9.8622e-04 - val_mae: 0.0227\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0017 - mae: 0.0291 - val_loss: 9.2002e-04 - val_mae: 0.0216\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0018 - mae: 0.0298 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0017 - mae: 0.0294 - val_loss: 8.9031e-04 - val_mae: 0.0213\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0017 - mae: 0.0288 - val_loss: 8.6129e-04 - val_mae: 0.0213\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 8.7222e-04 - val_mae: 0.0224\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 9.1178e-04 - val_mae: 0.0224\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0016 - mae: 0.0284 - val_loss: 7.7953e-04 - val_mae: 0.0198\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 8.2632e-04 - val_mae: 0.0209\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 9.1164e-04 - val_mae: 0.0223\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0281 - val_loss: 8.4342e-04 - val_mae: 0.0217\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.1968e-04 - val_mae: 0.0212\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 9.0613e-04 - val_mae: 0.0226\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 8.9798e-04 - val_mae: 0.0214\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 9.8266e-04 - val_mae: 0.0225\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 7.8727e-04 - val_mae: 0.0199\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 8.0198e-04 - val_mae: 0.0208\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 8.5793e-04 - val_mae: 0.0207\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 9.0566e-04 - val_mae: 0.0211\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0275 - val_loss: 8.3472e-04 - val_mae: 0.0218\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 9.4454e-04 - val_mae: 0.0221\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 9.0684e-04 - val_mae: 0.0214\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 8.2151e-04 - val_mae: 0.0203\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.9591e-04 - val_mae: 0.0214\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 7.7844e-04 - val_mae: 0.0195\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 9.2801e-04 - val_mae: 0.0230\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 8.3769e-04 - val_mae: 0.0211\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 8.3480e-04 - val_mae: 0.0204\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 9.2708e-04 - val_mae: 0.0217\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 7.8198e-04 - val_mae: 0.0202\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 7.9492e-04 - val_mae: 0.0203\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 9.6391e-04 - val_mae: 0.0235\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0263 - val_loss: 8.9105e-04 - val_mae: 0.0206\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0256 - val_loss: 9.0111e-04 - val_mae: 0.0214\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 8.8335e-04 - val_mae: 0.0211\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 7.7024e-04 - val_mae: 0.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 8.2783e-04 - val_mae: 0.0205\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 9.9695e-04 - val_mae: 0.0232\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 8.6600e-04 - val_mae: 0.0208\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 9.2357e-04 - val_mae: 0.0214\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 8.1154e-04 - val_mae: 0.0200\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 7.9547e-04 - val_mae: 0.0207\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 8.3363e-04 - val_mae: 0.0205\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 9.4762e-04 - val_mae: 0.0224\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 8.5008e-04 - val_mae: 0.0221\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 8.3565e-04 - val_mae: 0.0213\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0013 - mae: 0.0249 - val_loss: 9.6296e-04 - val_mae: 0.0224\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 8.3717e-04 - val_mae: 0.0207\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 8.2718e-04 - val_mae: 0.0202\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 7.5786e-04 - val_mae: 0.0201\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 8.8431e-04 - val_mae: 0.0217\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 8.3419e-04 - val_mae: 0.0208\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 9.9911e-04 - val_mae: 0.0224\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 7.8041e-04 - val_mae: 0.0201\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 9.1508e-04 - val_mae: 0.0217\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 8.7667e-04 - val_mae: 0.0210\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 8.3791e-04 - val_mae: 0.0201\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 7.6817e-04 - val_mae: 0.0199\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 8.1952e-04 - val_mae: 0.0203\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 8.9734e-04 - val_mae: 0.0207\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 8.7201e-04 - val_mae: 0.0208\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 8.6082e-04 - val_mae: 0.0211\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 8.9950e-04 - val_mae: 0.0212\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 8.0298e-04 - val_mae: 0.0201\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 7.9393e-04 - val_mae: 0.0199\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 8.3771e-04 - val_mae: 0.0207\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 9.0009e-04 - val_mae: 0.0214\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 9.8454e-04 - val_mae: 0.0236\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 8.6003e-04 - val_mae: 0.0210\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 8.8146e-04 - val_mae: 0.0216\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 9.1478e-04 - val_mae: 0.0221\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0243\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 8.1874e-04 - val_mae: 0.0209\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 9.5256e-04 - val_mae: 0.0213\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 9.2590e-04 - val_mae: 0.0216\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 8.8263e-04 - val_mae: 0.0217\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.9275e-04 - mae: 0.0224 - val_loss: 9.3464e-04 - val_mae: 0.0220\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.9677e-04 - mae: 0.0224 - val_loss: 9.3806e-04 - val_mae: 0.0218\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.9617e-04 - mae: 0.0223 - val_loss: 8.6646e-04 - val_mae: 0.0210\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.9222e-04 - mae: 0.0224 - val_loss: 9.2062e-04 - val_mae: 0.0218\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.6529e-04 - mae: 0.0221 - val_loss: 9.7605e-04 - val_mae: 0.0219\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.5916e-04 - mae: 0.0220 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 2s 9ms/step - loss: 9.4047e-04 - mae: 0.0219 - val_loss: 9.1235e-04 - val_mae: 0.0217\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 9.8834e-04 - mae: 0.0225 - val_loss: 8.3448e-04 - val_mae: 0.0204\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0010 - mae: 0.0225 - val_loss: 9.4107e-04 - val_mae: 0.0220\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4348e-04 - mae: 0.0220 - val_loss: 9.3470e-04 - val_mae: 0.0221\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.5610e-04 - mae: 0.0218 - val_loss: 8.8561e-04 - val_mae: 0.0212\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 8.4536e-04 - val_mae: 0.0208\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.7203e-04 - mae: 0.0221 - val_loss: 9.5059e-04 - val_mae: 0.0217\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9998e-04 - mae: 0.0214 - val_loss: 9.1731e-04 - val_mae: 0.0220\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9541e-04 - mae: 0.0214 - val_loss: 9.1123e-04 - val_mae: 0.0218\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8576e-04 - mae: 0.0213 - val_loss: 8.8061e-04 - val_mae: 0.0212\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4610e-04 - mae: 0.0207 - val_loss: 9.3671e-04 - val_mae: 0.0220\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5460e-04 - mae: 0.0209 - val_loss: 9.2743e-04 - val_mae: 0.0212\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8343e-04 - mae: 0.0211 - val_loss: 8.7462e-04 - val_mae: 0.0213\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.3640e-04 - mae: 0.0219 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6624e-04 - mae: 0.0212 - val_loss: 9.4700e-04 - val_mae: 0.0223\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4867e-04 - mae: 0.0209 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8089e-04 - mae: 0.0213 - val_loss: 9.9172e-04 - val_mae: 0.0227\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5976e-04 - mae: 0.0211 - val_loss: 9.5512e-04 - val_mae: 0.0214\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9649e-04 - mae: 0.0202 - val_loss: 9.4085e-04 - val_mae: 0.0220\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0201e-04 - mae: 0.0203 - val_loss: 9.4575e-04 - val_mae: 0.0220\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7920e-04 - mae: 0.0213 - val_loss: 9.6162e-04 - val_mae: 0.0222\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7428e-04 - mae: 0.0200 - val_loss: 9.7643e-04 - val_mae: 0.0220\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9193e-04 - mae: 0.0201 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5470e-04 - mae: 0.0208 - val_loss: 9.3880e-04 - val_mae: 0.0215\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0874e-04 - mae: 0.0204 - val_loss: 9.0277e-04 - val_mae: 0.0213\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9586e-04 - mae: 0.0202 - val_loss: 9.8147e-04 - val_mae: 0.0225\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5664e-04 - mae: 0.0198 - val_loss: 9.5357e-04 - val_mae: 0.0220\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8111e-04 - mae: 0.0200 - val_loss: 8.7117e-04 - val_mae: 0.0218\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 7.6343e-04 - mae: 0.0198 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6737e-04 - mae: 0.0199 - val_loss: 0.0010 - val_mae: 0.0221\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3560e-04 - mae: 0.0195 - val_loss: 9.9225e-04 - val_mae: 0.0224\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3878e-04 - mae: 0.0196 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5776e-04 - mae: 0.0198 - val_loss: 9.5069e-04 - val_mae: 0.0220\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3650e-04 - mae: 0.0196 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.4689e-04 - mae: 0.0196 - val_loss: 9.3074e-04 - val_mae: 0.0216\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5913e-04 - mae: 0.0198 - val_loss: 9.5717e-04 - val_mae: 0.0217\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.0431e-04 - mae: 0.0191 - val_loss: 9.8528e-04 - val_mae: 0.0219\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.9991e-04 - mae: 0.0191 - val_loss: 0.0010 - val_mae: 0.0222\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.1769e-04 - mae: 0.0193 - val_loss: 0.0010 - val_mae: 0.0220\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3092e-04 - mae: 0.0196 - val_loss: 9.9097e-04 - val_mae: 0.0226\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.8249e-04 - mae: 0.0188 - val_loss: 9.2486e-04 - val_mae: 0.0219\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.0782e-04 - mae: 0.0192 - val_loss: 0.0012 - val_mae: 0.0243\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.4860e-04 - mae: 0.0197 - val_loss: 9.8196e-04 - val_mae: 0.0221\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5813e-04 - mae: 0.0198 - val_loss: 0.0011 - val_mae: 0.0227\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.0285e-04 - mae: 0.0190 - val_loss: 0.0011 - val_mae: 0.0224\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.9961e-04 - mae: 0.0191 - val_loss: 0.0010 - val_mae: 0.0224\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.4022e-04 - mae: 0.0197 - val_loss: 9.3477e-04 - val_mae: 0.0212\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.7208e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8323e-04 - mae: 0.0201 - val_loss: 8.5665e-04 - val_mae: 0.0213\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.6418e-04 - mae: 0.0187 - val_loss: 0.0010 - val_mae: 0.0216\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.2893e-04 - mae: 0.0182 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3662e-04 - mae: 0.0183 - val_loss: 9.3283e-04 - val_mae: 0.0216\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.2002e-04 - mae: 0.0193 - val_loss: 9.7106e-04 - val_mae: 0.0221\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.7626e-04 - mae: 0.0188 - val_loss: 9.4188e-04 - val_mae: 0.0220\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3440e-04 - mae: 0.0182 - val_loss: 9.3338e-04 - val_mae: 0.0225\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.6292e-04 - mae: 0.0186 - val_loss: 9.2290e-04 - val_mae: 0.0220\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.2826e-04 - mae: 0.0181 - val_loss: 9.6545e-04 - val_mae: 0.0226\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3913e-04 - mae: 0.0183 - val_loss: 0.0010 - val_mae: 0.0226\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3386e-04 - mae: 0.0182 - val_loss: 9.2757e-04 - val_mae: 0.0218\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.2674e-04 - mae: 0.0180 - val_loss: 9.9991e-04 - val_mae: 0.0223\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.0875e-04 - mae: 0.0179 - val_loss: 0.0010 - val_mae: 0.0223\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3072e-04 - mae: 0.0184 - val_loss: 0.0010 - val_mae: 0.0226\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3237e-04 - mae: 0.0182 - val_loss: 9.8571e-04 - val_mae: 0.0226\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.7789e-04 - mae: 0.0188 - val_loss: 0.0010 - val_mae: 0.0231\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3089e-04 - mae: 0.0182 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.0910e-04 - mae: 0.0180 - val_loss: 0.0011 - val_mae: 0.0229\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.7442e-04 - mae: 0.0175 - val_loss: 9.5291e-04 - val_mae: 0.0221\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3036e-04 - mae: 0.0181 - val_loss: 8.7512e-04 - val_mae: 0.0211\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.3904e-04 - mae: 0.0183 - val_loss: 0.0012 - val_mae: 0.0254\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5062e-04 - mae: 0.0171 - val_loss: 9.6428e-04 - val_mae: 0.0221\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.8889e-04 - mae: 0.0177 - val_loss: 9.8724e-04 - val_mae: 0.0225\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.1916e-04 - mae: 0.0181 - val_loss: 9.8777e-04 - val_mae: 0.0217\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.8964e-04 - mae: 0.0178 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5079e-04 - mae: 0.0171 - val_loss: 9.6711e-04 - val_mae: 0.0223\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5647e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mae: 0.0230\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.6413e-04 - mae: 0.0173 - val_loss: 0.0011 - val_mae: 0.0234\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.7265e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mae: 0.0226\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.9013e-04 - mae: 0.0177 - val_loss: 9.4705e-04 - val_mae: 0.0223\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 6.1378e-04 - mae: 0.0180 - val_loss: 9.3370e-04 - val_mae: 0.0218\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.7123e-04 - mae: 0.0174 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5293e-04 - mae: 0.0172 - val_loss: 0.0011 - val_mae: 0.0232\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.6482e-04 - mae: 0.0173 - val_loss: 0.0012 - val_mae: 0.0248\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5728e-04 - mae: 0.0172 - val_loss: 0.0010 - val_mae: 0.0234\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.8446e-04 - mae: 0.0176 - val_loss: 0.0010 - val_mae: 0.0228\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.4048e-04 - mae: 0.0170 - val_loss: 9.4154e-04 - val_mae: 0.0221\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.7968e-04 - mae: 0.0175 - val_loss: 0.0010 - val_mae: 0.0229\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.5188e-04 - mae: 0.0171 - val_loss: 9.6959e-04 - val_mae: 0.0220\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.3665e-04 - mae: 0.0169 - val_loss: 9.6122e-04 - val_mae: 0.0218\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.4768e-04 - mae: 0.0171 - val_loss: 9.5434e-04 - val_mae: 0.0217\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 5.2319e-04 - mae: 0.0168 - val_loss: 9.3582e-04 - val_mae: 0.0218\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2168, 6)\n",
      "The Mean Squared Error is: 12.59751158447979\n"
     ]
    }
   ],
   "source": [
    "## Saving the result file to the folder of the model\n",
    "try:\n",
    "    os.chdir(os.path.join(dest,'Wavenet'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Wavenet')\n",
    "    os.chdir(os.path.join(dest,'Wavenet'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_wavenet.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_wavenet.load_weights(filepath_attention)\n",
    "preds = atten_wavenet.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('Wavenet Results.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
