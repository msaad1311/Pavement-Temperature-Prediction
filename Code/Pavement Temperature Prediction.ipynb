{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xlwt \n",
    "from xlwt import Workbook \n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print('Libraries Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utilities \n",
    "\n",
    "def read_file(path):\n",
    "    df= pd.read_excel(path)\n",
    "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "def create_dataset(X, y, time_steps, ts_range):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps - ts_range):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.values[(i + time_steps):(i + time_steps + ts_range),0])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "def splitter(df,output,lag,duration,ts):\n",
    "    assert (0. <= ts <= 1.)\n",
    "    train_size = int(len(df) * ts)\n",
    "    test_size = len(df) - train_size\n",
    "    train, test = df.iloc[0:train_size], df[train_size:]\n",
    "    print(train.shape, test.shape)\n",
    "    scaler,scaler_single = MinMaxScaler(feature_range=(0, 1)),MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    scaler.fit(train)\n",
    "    scaler_single.fit(train[output])\n",
    "\n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=[df.columns])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=[df.columns])\n",
    "\n",
    "    df_train = train_scaled.copy(deep=True)\n",
    "    df_test = test_scaled.copy(deep=True)\n",
    "\n",
    "    x_train,y_train = create_dataset(df_train,df_train[[output]],lag,duration)\n",
    "    x_test, y_test = create_dataset(df_test, df_test[[output]], lag, duration)\n",
    "\n",
    "    return x_train,x_test,y_train,y_test,scaler_single\n",
    "\n",
    "class attention(keras.layers.Layer):\n",
    "    '''\n",
    "    if return_sequences=True, it will give 3D vector and if false it will give 2D vector. It is same as LSTMs.\n",
    "\n",
    "    https://stackoverflow.com/questions/62948332/how-to-add-attention-layer-to-a-bi-lstm/62949137#62949137\n",
    "    the  following code is being copied from the above link.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, return_sequences=True, **kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention, self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "\n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10896, 7)\n",
      "   Year  Month  Day  Hour  Temp  Solar  Pavement\n",
      "0  2009     11    1     1   8.4    0.0  9.333333\n",
      "1  2009     11    1     2   8.3    0.0  8.933333\n",
      "2  2009     11    1     3   7.9    0.0  8.700000\n",
      "3  2009     11    1     4   7.6    0.0  8.533333\n",
      "4  2009     11    1     5   6.9    0.0  8.533333\n"
     ]
    }
   ],
   "source": [
    "## Loading the file \n",
    "\n",
    "src = r'C:\\Users\\Saad.LAKES\\Desktop\\Pavement-Temperature-Prediction\\Data'\n",
    "filename = r'Pave_data_cleaned.xlsx'\n",
    "\n",
    "dest = r'C:\\Users\\Saad.LAKES\\Desktop\\Pavement-Temperature-Prediction\\Solutions'\n",
    "\n",
    "df = read_file(os.path.join(src,filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8716, 2) (2180, 2)\n",
      "The shape of x_train is (8686, 24, 2) and x_test is (2150, 24, 2)\n",
      "The shape of y_train is (8686, 6) and y_test is (2150, 6)\n"
     ]
    }
   ],
   "source": [
    "## Training the training and testing data\n",
    "\n",
    "x_train,x_test,y_train,y_test,scaler = splitter(df[['Temp','Pavement']],['Pavement'],24,6,0.8)\n",
    "print(f'The shape of x_train is {x_train.shape} and x_test is {x_test.shape}')\n",
    "print(f'The shape of y_train is {y_train.shape} and y_test is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_lstm.hdf5'\n",
    "filepath_attention = 'attention_lstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple LSTM\n",
    "K.clear_session()\n",
    "simple_lstm = keras.Sequential()\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.Dropout(0.3))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_lstm.add(keras.layers.Flatten())\n",
    "simple_lstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_lstm.add(keras.layers.Dropout(0.3))\n",
    "simple_lstm.add(keras.layers.Dense(32))\n",
    "simple_lstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_lstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "The Mean Squared Error is: 5.831630519312005\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('LSTM')\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "# history = simple_lstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "# plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "simple_lstm.load_weights(filepath_simple)\n",
    "preds = simple_lstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention model\n",
    "\n",
    "K.clear_session()\n",
    "atten_lstm = keras.Sequential()\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "# atten_lstm.add(attention(return_sequences=True))\n",
    "atten_lstm.add(keras.layers.Dropout(0.3))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_lstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_lstm.add(attention(return_sequences=True))\n",
    "atten_lstm.add(keras.layers.Flatten())\n",
    "atten_lstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_lstm.add(keras.layers.Dropout(0.3))\n",
    "atten_lstm.add(keras.layers.Dense(32))\n",
    "atten_lstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_lstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 3s 10ms/step - loss: 0.0166 - mae: 0.0919 - val_loss: 0.0046 - val_mae: 0.0550\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0067 - mae: 0.0614 - val_loss: 0.0032 - val_mae: 0.0446\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0051 - mae: 0.0530 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0043 - mae: 0.0485 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0434 - val_loss: 0.0014 - val_mae: 0.0290\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0278\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0025 - mae: 0.0359 - val_loss: 8.1998e-04 - val_mae: 0.0230\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0023 - mae: 0.0345 - val_loss: 9.7574e-04 - val_mae: 0.0243\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 7.8868e-04 - val_mae: 0.0227\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 2s 8ms/step - loss: 0.0021 - mae: 0.0326 - val_loss: 6.6729e-04 - val_mae: 0.0201\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0021 - mae: 0.0329 - val_loss: 8.4943e-04 - val_mae: 0.0225\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0020 - mae: 0.0316 - val_loss: 6.4670e-04 - val_mae: 0.0196\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0019 - mae: 0.0312 - val_loss: 5.9379e-04 - val_mae: 0.0191\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0305 - val_loss: 6.2856e-04 - val_mae: 0.0194\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0302 - val_loss: 5.0913e-04 - val_mae: 0.0172\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0301 - val_loss: 7.6135e-04 - val_mae: 0.0214\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0018 - mae: 0.0303 - val_loss: 7.9579e-04 - val_mae: 0.0223\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0299 - val_loss: 5.0978e-04 - val_mae: 0.0174\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0291 - val_loss: 5.1046e-04 - val_mae: 0.0172\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 8.1448e-04 - val_mae: 0.0236\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0292 - val_loss: 5.9474e-04 - val_mae: 0.0184\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0017 - mae: 0.0293 - val_loss: 6.7651e-04 - val_mae: 0.0208\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 7.7463e-04 - val_mae: 0.0218\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0292 - val_loss: 6.6507e-04 - val_mae: 0.0196\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0289 - val_loss: 8.9247e-04 - val_mae: 0.0236\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 5.9263e-04 - val_mae: 0.0188\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0283 - val_loss: 5.0157e-04 - val_mae: 0.0169\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0287 - val_loss: 6.0686e-04 - val_mae: 0.0194\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0278 - val_loss: 4.6925e-04 - val_mae: 0.0167\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0281 - val_loss: 8.8835e-04 - val_mae: 0.0236\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 0.0015 - val_mae: 0.0325\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 5.2127e-04 - val_mae: 0.0177\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0277 - val_loss: 5.1254e-04 - val_mae: 0.0172\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 4.7164e-04 - val_mae: 0.0161\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 6.1034e-04 - val_mae: 0.0189\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 6.2952e-04 - val_mae: 0.0197\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0256\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0276 - val_loss: 7.1237e-04 - val_mae: 0.0214\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0015 - mae: 0.0273 - val_loss: 4.6310e-04 - val_mae: 0.0161\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 6.4891e-04 - val_mae: 0.0190\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0267 - val_loss: 5.3622e-04 - val_mae: 0.0180\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 8.9043e-04 - val_mae: 0.0235\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 6.7912e-04 - val_mae: 0.0198\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 5.0501e-04 - val_mae: 0.0171\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0262 - val_loss: 5.3638e-04 - val_mae: 0.0175\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 6.9804e-04 - val_mae: 0.0211\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0264 - val_loss: 7.6167e-04 - val_mae: 0.0221\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0014 - mae: 0.0265 - val_loss: 7.3928e-04 - val_mae: 0.0216\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 7.1989e-04 - val_mae: 0.0215\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 4.9343e-04 - val_mae: 0.0165\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0259 - val_loss: 6.0149e-04 - val_mae: 0.0183\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0257 - val_loss: 4.9858e-04 - val_mae: 0.0168\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 6.9319e-04 - val_mae: 0.0199\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 4.8471e-04 - val_mae: 0.0163\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 7.5512e-04 - val_mae: 0.0227\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0252 - val_loss: 6.9901e-04 - val_mae: 0.0192\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 0.0014 - val_mae: 0.0317\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 6.0929e-04 - val_mae: 0.0187\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 5.4922e-04 - val_mae: 0.0171\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 4.8564e-04 - val_mae: 0.0166\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 4.5125e-04 - val_mae: 0.0159\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 5.4331e-04 - val_mae: 0.0177\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 4.4389e-04 - val_mae: 0.0156\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0243 - val_loss: 4.8704e-04 - val_mae: 0.0163\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0250 - val_loss: 4.6202e-04 - val_mae: 0.0157\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 6.0256e-04 - val_mae: 0.0186\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0251 - val_loss: 6.7643e-04 - val_mae: 0.0210\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 4.3849e-04 - val_mae: 0.0155\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 4.7764e-04 - val_mae: 0.0162\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 5.9106e-04 - val_mae: 0.0185\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 4.8004e-04 - val_mae: 0.0162\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 4.9090e-04 - val_mae: 0.0167\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0242 - val_loss: 5.1473e-04 - val_mae: 0.0167\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 5.0822e-04 - val_mae: 0.0166\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0244 - val_loss: 5.6761e-04 - val_mae: 0.0183\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0234 - val_loss: 4.4018e-04 - val_mae: 0.0156\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 5.1249e-04 - val_mae: 0.0168\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0241 - val_loss: 5.7695e-04 - val_mae: 0.0187\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 7.8082e-04 - val_mae: 0.0217\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 7.4469e-04 - val_mae: 0.0211\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 4.6033e-04 - val_mae: 0.0160\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 4.6329e-04 - val_mae: 0.0163\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 5.7212e-04 - val_mae: 0.0180\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 6.6960e-04 - val_mae: 0.0203\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 7.7749e-04 - val_mae: 0.0219\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 5.6750e-04 - val_mae: 0.0181\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 5.4974e-04 - val_mae: 0.0172\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0236 - val_loss: 5.5364e-04 - val_mae: 0.0184\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.8295e-04 - mae: 0.0226 - val_loss: 4.5449e-04 - val_mae: 0.0160\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0231 - val_loss: 5.0291e-04 - val_mae: 0.0162\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.8726e-04 - mae: 0.0227 - val_loss: 5.9155e-04 - val_mae: 0.0179\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0228 - val_loss: 5.4267e-04 - val_mae: 0.0175\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.8774e-04 - mae: 0.0227 - val_loss: 5.6822e-04 - val_mae: 0.0183\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0232 - val_loss: 4.7659e-04 - val_mae: 0.0162\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0229 - val_loss: 4.8763e-04 - val_mae: 0.0161\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.7805e-04 - mae: 0.0226 - val_loss: 7.5191e-04 - val_mae: 0.0206\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0233 - val_loss: 5.5288e-04 - val_mae: 0.0177\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 0.0010 - mae: 0.0227 - val_loss: 5.0948e-04 - val_mae: 0.0172\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4608e-04 - mae: 0.0221 - val_loss: 5.2689e-04 - val_mae: 0.0178\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.5670e-04 - mae: 0.0224 - val_loss: 4.9545e-04 - val_mae: 0.0168\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.1978e-04 - mae: 0.0219 - val_loss: 5.5618e-04 - val_mae: 0.0181\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.3504e-04 - mae: 0.0221 - val_loss: 5.0430e-04 - val_mae: 0.0169\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.7556e-04 - mae: 0.0225 - val_loss: 5.6658e-04 - val_mae: 0.0182\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.6598e-04 - mae: 0.0225 - val_loss: 5.9647e-04 - val_mae: 0.0192\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4924e-04 - mae: 0.0223 - val_loss: 4.7508e-04 - val_mae: 0.0161\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.3782e-04 - mae: 0.0220 - val_loss: 5.4138e-04 - val_mae: 0.0173\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4446e-04 - mae: 0.0221 - val_loss: 5.3772e-04 - val_mae: 0.0178\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9935e-04 - mae: 0.0217 - val_loss: 4.8833e-04 - val_mae: 0.0167\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.2538e-04 - mae: 0.0221 - val_loss: 4.8161e-04 - val_mae: 0.0166\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.7096e-04 - mae: 0.0224 - val_loss: 9.7204e-04 - val_mae: 0.0236\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.1934e-04 - mae: 0.0220 - val_loss: 5.0129e-04 - val_mae: 0.0161\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.1058e-04 - mae: 0.0219 - val_loss: 5.0125e-04 - val_mae: 0.0164\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.0438e-04 - mae: 0.0216 - val_loss: 4.8580e-04 - val_mae: 0.0168\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.0101e-04 - mae: 0.0216 - val_loss: 6.0205e-04 - val_mae: 0.0188\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4897e-04 - mae: 0.0221 - val_loss: 4.4494e-04 - val_mae: 0.0155\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8195e-04 - mae: 0.0215 - val_loss: 4.6716e-04 - val_mae: 0.0161\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9175e-04 - mae: 0.0217 - val_loss: 5.6525e-04 - val_mae: 0.0183\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9078e-04 - mae: 0.0215 - val_loss: 5.2264e-04 - val_mae: 0.0172\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.0543e-04 - mae: 0.0217 - val_loss: 6.5982e-04 - val_mae: 0.0201\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9142e-04 - mae: 0.0216 - val_loss: 4.9140e-04 - val_mae: 0.0167\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7356e-04 - mae: 0.0212 - val_loss: 5.5472e-04 - val_mae: 0.0179\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9580e-04 - mae: 0.0214 - val_loss: 4.8830e-04 - val_mae: 0.0164\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9202e-04 - mae: 0.0214 - val_loss: 5.7242e-04 - val_mae: 0.0178\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8238e-04 - mae: 0.0213 - val_loss: 4.3649e-04 - val_mae: 0.0156\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.4146e-04 - mae: 0.0220 - val_loss: 7.1329e-04 - val_mae: 0.0210\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.1766e-04 - mae: 0.0216 - val_loss: 5.4910e-04 - val_mae: 0.0180\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8786e-04 - mae: 0.0213 - val_loss: 4.9622e-04 - val_mae: 0.0167\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7645e-04 - mae: 0.0213 - val_loss: 5.0900e-04 - val_mae: 0.0172\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6961e-04 - mae: 0.0212 - val_loss: 4.6907e-04 - val_mae: 0.0160\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7499e-04 - mae: 0.0212 - val_loss: 4.5605e-04 - val_mae: 0.0159\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7462e-04 - mae: 0.0212 - val_loss: 5.2591e-04 - val_mae: 0.0169\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6613e-04 - mae: 0.0211 - val_loss: 4.5996e-04 - val_mae: 0.0158\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.9369e-04 - mae: 0.0213 - val_loss: 4.9049e-04 - val_mae: 0.0168\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6253e-04 - mae: 0.0212 - val_loss: 5.1040e-04 - val_mae: 0.0173\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5911e-04 - mae: 0.0210 - val_loss: 0.0011 - val_mae: 0.0270\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.7370e-04 - mae: 0.0212 - val_loss: 6.9705e-04 - val_mae: 0.0207\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 9.1493e-04 - mae: 0.0216 - val_loss: 5.6303e-04 - val_mae: 0.0179\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6946e-04 - mae: 0.0212 - val_loss: 5.7483e-04 - val_mae: 0.0183\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.8351e-04 - mae: 0.0211 - val_loss: 5.5137e-04 - val_mae: 0.0177\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6095e-04 - mae: 0.0212 - val_loss: 4.7717e-04 - val_mae: 0.0161\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.6476e-04 - mae: 0.0209 - val_loss: 5.4535e-04 - val_mae: 0.0182\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.2093e-04 - mae: 0.0206 - val_loss: 5.4468e-04 - val_mae: 0.0174\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5931e-04 - mae: 0.0210 - val_loss: 5.3032e-04 - val_mae: 0.0172\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4424e-04 - mae: 0.0208 - val_loss: 4.5169e-04 - val_mae: 0.0155\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5548e-04 - mae: 0.0209 - val_loss: 7.3757e-04 - val_mae: 0.0210\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4553e-04 - mae: 0.0207 - val_loss: 4.8686e-04 - val_mae: 0.0167\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4373e-04 - mae: 0.0208 - val_loss: 4.8167e-04 - val_mae: 0.0163\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5182e-04 - mae: 0.0209 - val_loss: 5.3387e-04 - val_mae: 0.0170\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.1782e-04 - mae: 0.0207 - val_loss: 4.8156e-04 - val_mae: 0.0166\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.1447e-04 - mae: 0.0205 - val_loss: 4.8484e-04 - val_mae: 0.0166\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0512e-04 - mae: 0.0204 - val_loss: 5.2836e-04 - val_mae: 0.0171\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0794e-04 - mae: 0.0205 - val_loss: 4.8704e-04 - val_mae: 0.0166\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.2947e-04 - mae: 0.0205 - val_loss: 5.7756e-04 - val_mae: 0.0183\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.5727e-04 - mae: 0.0209 - val_loss: 6.1027e-04 - val_mae: 0.0183\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.1789e-04 - mae: 0.0205 - val_loss: 4.8282e-04 - val_mae: 0.0159\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.4968e-04 - mae: 0.0207 - val_loss: 6.2155e-04 - val_mae: 0.0193\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.3651e-04 - mae: 0.0206 - val_loss: 4.9101e-04 - val_mae: 0.0164\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.2479e-04 - mae: 0.0205 - val_loss: 5.3363e-04 - val_mae: 0.0177\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.2365e-04 - mae: 0.0205 - val_loss: 4.9522e-04 - val_mae: 0.0165\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9751e-04 - mae: 0.0201 - val_loss: 5.0268e-04 - val_mae: 0.0173\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7028e-04 - mae: 0.0199 - val_loss: 5.0949e-04 - val_mae: 0.0169\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9885e-04 - mae: 0.0203 - val_loss: 5.5046e-04 - val_mae: 0.0178\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9663e-04 - mae: 0.0201 - val_loss: 4.7762e-04 - val_mae: 0.0162\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8949e-04 - mae: 0.0201 - val_loss: 5.1915e-04 - val_mae: 0.0173\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.1346e-04 - mae: 0.0203 - val_loss: 5.6353e-04 - val_mae: 0.0180\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8592e-04 - mae: 0.0202 - val_loss: 4.8551e-04 - val_mae: 0.0159\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.1087e-04 - mae: 0.0204 - val_loss: 5.2328e-04 - val_mae: 0.0172\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8152e-04 - mae: 0.0199 - val_loss: 5.1955e-04 - val_mae: 0.0171\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7043e-04 - mae: 0.0200 - val_loss: 4.8279e-04 - val_mae: 0.0164\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9113e-04 - mae: 0.0201 - val_loss: 6.0441e-04 - val_mae: 0.0187\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8267e-04 - mae: 0.0200 - val_loss: 5.3228e-04 - val_mae: 0.0173\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8489e-04 - mae: 0.0200 - val_loss: 4.6516e-04 - val_mae: 0.0161\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.2217e-04 - mae: 0.0204 - val_loss: 5.1090e-04 - val_mae: 0.0174\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7475e-04 - mae: 0.0200 - val_loss: 5.5545e-04 - val_mae: 0.0179\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8380e-04 - mae: 0.0199 - val_loss: 5.3275e-04 - val_mae: 0.0172\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.9122e-04 - mae: 0.0200 - val_loss: 5.0088e-04 - val_mae: 0.0173\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8802e-04 - mae: 0.0199 - val_loss: 4.5936e-04 - val_mae: 0.0156\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8169e-04 - mae: 0.0200 - val_loss: 4.8299e-04 - val_mae: 0.0162\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7544e-04 - mae: 0.0199 - val_loss: 4.8265e-04 - val_mae: 0.0167\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6379e-04 - mae: 0.0199 - val_loss: 5.1002e-04 - val_mae: 0.0173\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8607e-04 - mae: 0.0200 - val_loss: 5.3755e-04 - val_mae: 0.0173\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5366e-04 - mae: 0.0196 - val_loss: 6.1328e-04 - val_mae: 0.0188\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8392e-04 - mae: 0.0199 - val_loss: 5.8162e-04 - val_mae: 0.0177\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0141e-04 - mae: 0.0200 - val_loss: 4.9190e-04 - val_mae: 0.0164\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7495e-04 - mae: 0.0198 - val_loss: 4.4135e-04 - val_mae: 0.0156\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5836e-04 - mae: 0.0195 - val_loss: 5.5903e-04 - val_mae: 0.0177\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6309e-04 - mae: 0.0198 - val_loss: 6.0272e-04 - val_mae: 0.0191\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.4513e-04 - mae: 0.0195 - val_loss: 4.9822e-04 - val_mae: 0.0168\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7511e-04 - mae: 0.0197 - val_loss: 5.0211e-04 - val_mae: 0.0168\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.4107e-04 - mae: 0.0194 - val_loss: 5.5299e-04 - val_mae: 0.0186\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6471e-04 - mae: 0.0196 - val_loss: 4.9453e-04 - val_mae: 0.0163\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6762e-04 - mae: 0.0197 - val_loss: 4.7398e-04 - val_mae: 0.0161\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.8908e-04 - mae: 0.0201 - val_loss: 8.9701e-04 - val_mae: 0.0227\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 8.0021e-04 - mae: 0.0202 - val_loss: 5.7299e-04 - val_mae: 0.0183\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3829e-04 - mae: 0.0193 - val_loss: 4.9209e-04 - val_mae: 0.0167\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.3725e-04 - mae: 0.0193 - val_loss: 5.6572e-04 - val_mae: 0.0176\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.5500e-04 - mae: 0.0196 - val_loss: 7.1731e-04 - val_mae: 0.0214\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.7683e-04 - mae: 0.0198 - val_loss: 5.1770e-04 - val_mae: 0.0176\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.6047e-04 - mae: 0.0196 - val_loss: 5.2973e-04 - val_mae: 0.0168\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 2s 7ms/step - loss: 7.2178e-04 - mae: 0.0192 - val_loss: 5.0018e-04 - val_mae: 0.0166\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 6.021731217632003\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('LSTM')\n",
    "    os.chdir(os.path.join(dest,'LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_lstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_lstm.load_weights(filepath_attention)\n",
    "preds = atten_lstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "\n",
    "wk.save(f'LSTM Result.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_cnnlstm.hdf5'\n",
    "filepath_attention = 'attention_cnnlstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "simple_cnnlstm = keras.Sequential()\n",
    "simple_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "simple_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3))\n",
    "simple_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "simple_cnnlstm.add(keras.layers.Flatten())\n",
    "simple_cnnlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_cnnlstm.add(keras.layers.Dense(32))\n",
    "simple_cnnlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_cnnlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "The Mean Squared Error is: 7.532575327078259\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('CNN-LSTM')\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "# history = simple_cnnlstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "# plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "simple_cnnlstm.load_weights(filepath_simple)\n",
    "preds = simple_cnnlstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attention model\n",
    "\n",
    "K.clear_session()\n",
    "atten_cnnlstm = keras.Sequential()\n",
    "atten_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3, input_shape=(x_train.shape[1],x_train.shape[2])))\n",
    "atten_cnnlstm.add(keras.layers.Conv1D(64, kernel_size=3))\n",
    "atten_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_cnnlstm.add(keras.layers.LSTM(64, return_sequences=True))\n",
    "atten_cnnlstm.add(attention(return_sequences=True))\n",
    "atten_cnnlstm.add(keras.layers.Flatten())\n",
    "atten_cnnlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_cnnlstm.add(keras.layers.Dense(32))\n",
    "atten_cnnlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_cnnlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "The Mean Squared Error is: 6.202507857381984\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('CNN-LSTM')\n",
    "    os.chdir(os.path.join(dest,'CNN-LSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "# history = atten_cnnlstm.fit(x_train,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "# plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "atten_cnnlstm.load_weights(filepath_attention)\n",
    "preds = atten_cnnlstm.predict(x_test)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('CNN-LStM Results.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvLSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_convlstm.hdf5'\n",
    "filepath_attention = 'attention_convlstm.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_conv =x_train.reshape(x_train.shape[0], 1, 1, x_train.shape[1], x_train.shape[2])\n",
    "x_test_conv = x_test.reshape(x_test.shape[0], 1, 1, x_test.shape[1], x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "simple_convlstm = keras.Sequential()\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True, \n",
    "                                            input_shape=(x_train_conv.shape[1], x_train_conv.shape[2], \n",
    "                                                         x_train_conv.shape[3], x_train_conv.shape[4])))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "simple_convlstm.add(keras.layers.Flatten())\n",
    "simple_convlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "simple_convlstm.add(keras.layers.Dense(32))\n",
    "simple_convlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "simple_convlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new directory......\n",
      "New Directory Created\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 0.0359 - mae: 0.1351 - val_loss: 0.0068 - val_mae: 0.0649\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0081 - mae: 0.0669 - val_loss: 0.0038 - val_mae: 0.0475\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0060 - mae: 0.0571 - val_loss: 0.0029 - val_mae: 0.0415\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0050 - mae: 0.0521 - val_loss: 0.0027 - val_mae: 0.0400\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0047 - mae: 0.0501 - val_loss: 0.0025 - val_mae: 0.0383\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0024 - val_mae: 0.0379\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0041 - mae: 0.0464 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0037 - mae: 0.0438 - val_loss: 0.0021 - val_mae: 0.0343\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0035 - mae: 0.0417 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0033 - mae: 0.0404 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0031 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0306\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0029 - mae: 0.0377 - val_loss: 0.0017 - val_mae: 0.0321\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0027 - mae: 0.0365 - val_loss: 0.0015 - val_mae: 0.0285\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0026 - mae: 0.0351 - val_loss: 0.0014 - val_mae: 0.0278\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0025 - mae: 0.0344 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0023 - mae: 0.0333 - val_loss: 0.0015 - val_mae: 0.0300\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0022 - mae: 0.0328 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0312 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0020 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0020 - mae: 0.0304 - val_loss: 9.7103e-04 - val_mae: 0.0230\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0018 - mae: 0.0291 - val_loss: 9.3282e-04 - val_mae: 0.0224\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0018 - mae: 0.0292 - val_loss: 8.9993e-04 - val_mae: 0.0219\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0017 - mae: 0.0286 - val_loss: 8.9788e-04 - val_mae: 0.0219\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0017 - mae: 0.0282 - val_loss: 9.4265e-04 - val_mae: 0.0229\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0277 - val_loss: 9.7108e-04 - val_mae: 0.0228\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0016 - mae: 0.0274 - val_loss: 8.5328e-04 - val_mae: 0.0214\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.2489e-04 - val_mae: 0.0209\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 7.8864e-04 - val_mae: 0.0204\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0015 - mae: 0.0270 - val_loss: 8.4589e-04 - val_mae: 0.0216\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 8.3331e-04 - val_mae: 0.0216\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0015 - mae: 0.0263 - val_loss: 8.4253e-04 - val_mae: 0.0217\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0259 - val_loss: 7.7774e-04 - val_mae: 0.0203\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.9886e-04 - val_mae: 0.0208\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.8058e-04 - val_mae: 0.0206\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 7.3790e-04 - val_mae: 0.0195\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0254 - val_loss: 7.4034e-04 - val_mae: 0.0199\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.2474e-04 - val_mae: 0.0195\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0247 - val_loss: 7.8823e-04 - val_mae: 0.0202\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 7.4711e-04 - val_mae: 0.0202\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0243 - val_loss: 6.8027e-04 - val_mae: 0.0186\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 7.4919e-04 - val_mae: 0.0201\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0242 - val_loss: 7.8344e-04 - val_mae: 0.0210\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 7.9717e-04 - val_mae: 0.0214\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.0696e-04 - val_mae: 0.0192\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 6.8987e-04 - val_mae: 0.0190\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 6.5796e-04 - val_mae: 0.0185\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 6.8658e-04 - val_mae: 0.0189\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 8.0791e-04 - val_mae: 0.0211\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.4875e-04 - val_mae: 0.0203\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0231 - val_loss: 6.8356e-04 - val_mae: 0.0191\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.4327e-04 - val_mae: 0.0182\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 7.0123e-04 - val_mae: 0.0197\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 7.1814e-04 - val_mae: 0.0199\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0226 - val_loss: 6.4863e-04 - val_mae: 0.0185\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 6.6119e-04 - val_mae: 0.0190\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0011 - mae: 0.0225 - val_loss: 6.2495e-04 - val_mae: 0.0181\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0223 - val_loss: 7.1048e-04 - val_mae: 0.0200\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 7.4653e-04 - val_mae: 0.0212\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0010 - mae: 0.0219 - val_loss: 6.4316e-04 - val_mae: 0.0190\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 5.8857e-04 - val_mae: 0.0179\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0010 - mae: 0.0217 - val_loss: 5.7056e-04 - val_mae: 0.0176\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.9576e-04 - mae: 0.0216 - val_loss: 5.6395e-04 - val_mae: 0.0173\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.7050e-04 - mae: 0.0212 - val_loss: 6.2019e-04 - val_mae: 0.0189\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.6174e-04 - mae: 0.0212 - val_loss: 6.2695e-04 - val_mae: 0.0194\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.7295e-04 - mae: 0.0214 - val_loss: 5.7016e-04 - val_mae: 0.0176\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.4690e-04 - mae: 0.0210 - val_loss: 5.6547e-04 - val_mae: 0.0178\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.5009e-04 - mae: 0.0211 - val_loss: 5.5138e-04 - val_mae: 0.0174\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.3246e-04 - mae: 0.0209 - val_loss: 6.2335e-04 - val_mae: 0.0193\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.5876e-04 - mae: 0.0213 - val_loss: 5.1214e-04 - val_mae: 0.0167\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.3985e-04 - mae: 0.0209 - val_loss: 5.4548e-04 - val_mae: 0.0171\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.2274e-04 - mae: 0.0207 - val_loss: 5.9834e-04 - val_mae: 0.0188\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.1612e-04 - mae: 0.0206 - val_loss: 5.1277e-04 - val_mae: 0.0169\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.1972e-04 - mae: 0.0208 - val_loss: 6.2238e-04 - val_mae: 0.0196\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.1423e-04 - mae: 0.0206 - val_loss: 5.0992e-04 - val_mae: 0.0167\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.1163e-04 - mae: 0.0207 - val_loss: 5.5310e-04 - val_mae: 0.0177\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.0030e-04 - mae: 0.0205 - val_loss: 5.6597e-04 - val_mae: 0.0176\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.9678e-04 - mae: 0.0205 - val_loss: 5.1631e-04 - val_mae: 0.0173\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.9461e-04 - mae: 0.0204 - val_loss: 5.0820e-04 - val_mae: 0.0168\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.9154e-04 - mae: 0.0204 - val_loss: 5.1355e-04 - val_mae: 0.0172\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.9524e-04 - mae: 0.0204 - val_loss: 6.1367e-04 - val_mae: 0.0189\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.7655e-04 - mae: 0.0201 - val_loss: 5.0846e-04 - val_mae: 0.0171\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.9022e-04 - mae: 0.0204 - val_loss: 5.2058e-04 - val_mae: 0.0171\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.7558e-04 - mae: 0.0202 - val_loss: 5.5942e-04 - val_mae: 0.0182\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.8203e-04 - mae: 0.0203 - val_loss: 5.2677e-04 - val_mae: 0.0173\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.6094e-04 - mae: 0.0199 - val_loss: 6.4451e-04 - val_mae: 0.0201\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.8556e-04 - mae: 0.0204 - val_loss: 6.3512e-04 - val_mae: 0.0196\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.8646e-04 - mae: 0.0204 - val_loss: 4.7260e-04 - val_mae: 0.0162\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.5541e-04 - mae: 0.0200 - val_loss: 5.0978e-04 - val_mae: 0.0173\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.5470e-04 - mae: 0.0200 - val_loss: 5.8910e-04 - val_mae: 0.0187\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.5107e-04 - mae: 0.0199 - val_loss: 4.7848e-04 - val_mae: 0.0164\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.4543e-04 - mae: 0.0199 - val_loss: 5.2728e-04 - val_mae: 0.0175\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.3979e-04 - mae: 0.0198 - val_loss: 4.8832e-04 - val_mae: 0.0166\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.3262e-04 - mae: 0.0196 - val_loss: 4.7346e-04 - val_mae: 0.0162\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.3288e-04 - mae: 0.0198 - val_loss: 4.7008e-04 - val_mae: 0.0161\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.3718e-04 - mae: 0.0199 - val_loss: 5.4381e-04 - val_mae: 0.0180\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.3668e-04 - mae: 0.0199 - val_loss: 4.7131e-04 - val_mae: 0.0161\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 8.1525e-04 - mae: 0.0195 - val_loss: 4.5094e-04 - val_mae: 0.0156\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.3642e-04 - mae: 0.0199 - val_loss: 5.5711e-04 - val_mae: 0.0185\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.1262e-04 - mae: 0.0195 - val_loss: 4.8830e-04 - val_mae: 0.0166\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.0868e-04 - mae: 0.0194 - val_loss: 5.3268e-04 - val_mae: 0.0178\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.0421e-04 - mae: 0.0194 - val_loss: 5.2086e-04 - val_mae: 0.0173\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.0823e-04 - mae: 0.0195 - val_loss: 5.2599e-04 - val_mae: 0.0177\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.9730e-04 - mae: 0.0193 - val_loss: 5.6248e-04 - val_mae: 0.0180\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.9420e-04 - mae: 0.0193 - val_loss: 5.2387e-04 - val_mae: 0.0170\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.0213e-04 - mae: 0.0194 - val_loss: 4.4051e-04 - val_mae: 0.0155\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.9372e-04 - mae: 0.0193 - val_loss: 5.2250e-04 - val_mae: 0.0174\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 7.7905e-04 - mae: 0.0191 - val_loss: 4.7251e-04 - val_mae: 0.0161\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 7.9006e-04 - mae: 0.0193 - val_loss: 4.8167e-04 - val_mae: 0.0163\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.9080e-04 - mae: 0.0193 - val_loss: 4.9932e-04 - val_mae: 0.0170\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.7494e-04 - mae: 0.0191 - val_loss: 4.7662e-04 - val_mae: 0.0164\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.7681e-04 - mae: 0.0192 - val_loss: 5.0065e-04 - val_mae: 0.0170\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.5264e-04 - mae: 0.0188 - val_loss: 4.9321e-04 - val_mae: 0.0164\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.6744e-04 - mae: 0.0190 - val_loss: 4.7278e-04 - val_mae: 0.0165\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.5707e-04 - mae: 0.0189 - val_loss: 4.9451e-04 - val_mae: 0.0169\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.5455e-04 - mae: 0.0189 - val_loss: 5.1536e-04 - val_mae: 0.0170\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.4853e-04 - mae: 0.0187 - val_loss: 4.5463e-04 - val_mae: 0.0159\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 6s 26ms/step - loss: 7.4697e-04 - mae: 0.0187 - val_loss: 4.7457e-04 - val_mae: 0.0162\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.4423e-04 - mae: 0.0188 - val_loss: 4.8742e-04 - val_mae: 0.0167\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.2822e-04 - mae: 0.0184 - val_loss: 5.0125e-04 - val_mae: 0.0171\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.4187e-04 - mae: 0.0187 - val_loss: 4.6274e-04 - val_mae: 0.0159\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.1486e-04 - mae: 0.0182 - val_loss: 5.1415e-04 - val_mae: 0.0175\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.1060e-04 - mae: 0.0183 - val_loss: 4.4506e-04 - val_mae: 0.0157\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.2081e-04 - mae: 0.0184 - val_loss: 5.6579e-04 - val_mae: 0.0183\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.3078e-04 - mae: 0.0186 - val_loss: 4.7345e-04 - val_mae: 0.0161\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.2263e-04 - mae: 0.0184 - val_loss: 4.5284e-04 - val_mae: 0.0159\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.0222e-04 - mae: 0.0182 - val_loss: 4.3397e-04 - val_mae: 0.0155\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.9286e-04 - mae: 0.0180 - val_loss: 4.7946e-04 - val_mae: 0.0162\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.1663e-04 - mae: 0.0184 - val_loss: 4.5690e-04 - val_mae: 0.0160\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.8565e-04 - mae: 0.0179 - val_loss: 4.5092e-04 - val_mae: 0.0159\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.9759e-04 - mae: 0.0181 - val_loss: 4.6759e-04 - val_mae: 0.0163\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.9053e-04 - mae: 0.0180 - val_loss: 4.9909e-04 - val_mae: 0.0168\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.8155e-04 - mae: 0.0179 - val_loss: 4.6146e-04 - val_mae: 0.0158\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.7368e-04 - mae: 0.0178 - val_loss: 4.8487e-04 - val_mae: 0.0166\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.6432e-04 - mae: 0.0176 - val_loss: 4.4663e-04 - val_mae: 0.0156\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.0497e-04 - mae: 0.0184 - val_loss: 4.9574e-04 - val_mae: 0.0169\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.6189e-04 - mae: 0.0177 - val_loss: 4.5384e-04 - val_mae: 0.0159\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.6697e-04 - mae: 0.0178 - val_loss: 5.4247e-04 - val_mae: 0.0179\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 6.5597e-04 - mae: 0.0176 - val_loss: 4.4187e-04 - val_mae: 0.0155\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.4548e-04 - mae: 0.0175 - val_loss: 6.0588e-04 - val_mae: 0.0191\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.6376e-04 - mae: 0.0177 - val_loss: 5.0056e-04 - val_mae: 0.0164\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.5224e-04 - mae: 0.0176 - val_loss: 4.4429e-04 - val_mae: 0.0155\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.3800e-04 - mae: 0.0173 - val_loss: 4.7800e-04 - val_mae: 0.0166\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.4938e-04 - mae: 0.0176 - val_loss: 4.4700e-04 - val_mae: 0.0156\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.3730e-04 - mae: 0.0175 - val_loss: 5.0003e-04 - val_mae: 0.0169\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2631e-04 - mae: 0.0172 - val_loss: 5.3681e-04 - val_mae: 0.0178\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.1423e-04 - mae: 0.0171 - val_loss: 4.4513e-04 - val_mae: 0.0155\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2133e-04 - mae: 0.0172 - val_loss: 4.3176e-04 - val_mae: 0.0153\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2206e-04 - mae: 0.0172 - val_loss: 4.5517e-04 - val_mae: 0.0156\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.2000e-04 - mae: 0.0172 - val_loss: 4.9212e-04 - val_mae: 0.0169\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.0626e-04 - mae: 0.0170 - val_loss: 5.1948e-04 - val_mae: 0.0170\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.0799e-04 - mae: 0.0170 - val_loss: 6.3051e-04 - val_mae: 0.0199\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.1002e-04 - mae: 0.0170 - val_loss: 4.7263e-04 - val_mae: 0.0164\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.0654e-04 - mae: 0.0170 - val_loss: 4.6998e-04 - val_mae: 0.0162\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.9320e-04 - mae: 0.0168 - val_loss: 4.9083e-04 - val_mae: 0.0168\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.0072e-04 - mae: 0.0169 - val_loss: 4.7911e-04 - val_mae: 0.0164\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.8685e-04 - mae: 0.0168 - val_loss: 4.7240e-04 - val_mae: 0.0160\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.7934e-04 - mae: 0.0166 - val_loss: 4.8703e-04 - val_mae: 0.0163\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.8349e-04 - mae: 0.0167 - val_loss: 4.3594e-04 - val_mae: 0.0155\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.7796e-04 - mae: 0.0167 - val_loss: 4.5358e-04 - val_mae: 0.0157\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6913e-04 - mae: 0.0165 - val_loss: 5.1768e-04 - val_mae: 0.0174\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.7059e-04 - mae: 0.0165 - val_loss: 4.5667e-04 - val_mae: 0.0159\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6990e-04 - mae: 0.0166 - val_loss: 4.3687e-04 - val_mae: 0.0154\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6371e-04 - mae: 0.0164 - val_loss: 5.3658e-04 - val_mae: 0.0179\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6671e-04 - mae: 0.0165 - val_loss: 4.6206e-04 - val_mae: 0.0160\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6568e-04 - mae: 0.0166 - val_loss: 4.9720e-04 - val_mae: 0.0167\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4895e-04 - mae: 0.0164 - val_loss: 4.5042e-04 - val_mae: 0.0158\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4821e-04 - mae: 0.0162 - val_loss: 4.8937e-04 - val_mae: 0.0162\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4672e-04 - mae: 0.0163 - val_loss: 4.5134e-04 - val_mae: 0.0157\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4967e-04 - mae: 0.0162 - val_loss: 4.6137e-04 - val_mae: 0.0158\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4039e-04 - mae: 0.0163 - val_loss: 5.0745e-04 - val_mae: 0.0174\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2673e-04 - mae: 0.0159 - val_loss: 4.3502e-04 - val_mae: 0.0154\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2874e-04 - mae: 0.0160 - val_loss: 4.6466e-04 - val_mae: 0.0163\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2619e-04 - mae: 0.0160 - val_loss: 4.6828e-04 - val_mae: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2792e-04 - mae: 0.0160 - val_loss: 4.8338e-04 - val_mae: 0.0165\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1806e-04 - mae: 0.0159 - val_loss: 5.7835e-04 - val_mae: 0.0184\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1508e-04 - mae: 0.0159 - val_loss: 4.6533e-04 - val_mae: 0.0159\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.0047e-04 - mae: 0.0156 - val_loss: 5.3472e-04 - val_mae: 0.0174\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.9805e-04 - mae: 0.0157 - val_loss: 5.1514e-04 - val_mae: 0.0170\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1483e-04 - mae: 0.0159 - val_loss: 5.7880e-04 - val_mae: 0.0188\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.9777e-04 - mae: 0.0156 - val_loss: 4.8466e-04 - val_mae: 0.0160\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8861e-04 - mae: 0.0155 - val_loss: 4.5854e-04 - val_mae: 0.0158\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8756e-04 - mae: 0.0155 - val_loss: 4.9151e-04 - val_mae: 0.0164\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8079e-04 - mae: 0.0153 - val_loss: 4.8830e-04 - val_mae: 0.0164\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8441e-04 - mae: 0.0154 - val_loss: 4.9412e-04 - val_mae: 0.0170\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8211e-04 - mae: 0.0154 - val_loss: 5.1818e-04 - val_mae: 0.0171\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.8096e-04 - mae: 0.0154 - val_loss: 4.5703e-04 - val_mae: 0.0157\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.6536e-04 - mae: 0.0152 - val_loss: 4.9508e-04 - val_mae: 0.0167\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7365e-04 - mae: 0.0153 - val_loss: 4.9914e-04 - val_mae: 0.0160\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7992e-04 - mae: 0.0155 - val_loss: 4.4913e-04 - val_mae: 0.0158\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.6782e-04 - mae: 0.0152 - val_loss: 4.9380e-04 - val_mae: 0.0167\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5908e-04 - mae: 0.0150 - val_loss: 4.8577e-04 - val_mae: 0.0161\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4985e-04 - mae: 0.0149 - val_loss: 5.0691e-04 - val_mae: 0.0163\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.6468e-04 - mae: 0.0153 - val_loss: 4.7638e-04 - val_mae: 0.0160\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5213e-04 - mae: 0.0150 - val_loss: 4.9790e-04 - val_mae: 0.0169\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4543e-04 - mae: 0.0148 - val_loss: 5.1177e-04 - val_mae: 0.0165\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4354e-04 - mae: 0.0149 - val_loss: 4.7645e-04 - val_mae: 0.0161\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5615e-04 - mae: 0.0151 - val_loss: 4.8747e-04 - val_mae: 0.0163\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5342e-04 - mae: 0.0151 - val_loss: 6.0849e-04 - val_mae: 0.0187\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.3414e-04 - mae: 0.0146 - val_loss: 4.6479e-04 - val_mae: 0.0160\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2332e-04 - mae: 0.0145 - val_loss: 5.1963e-04 - val_mae: 0.0170\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 6.56104040864042\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('ConvLSTM')\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_convlstm.fit(x_train_conv,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_convlstm.load_weights(filepath_simple)\n",
    "preds = simple_convlstm.predict(x_test_conv)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "atten_convlstm = keras.Sequential()\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True, \n",
    "                                            input_shape=(x_train_conv.shape[1], x_train_conv.shape[2], \n",
    "                                                         x_train_conv.shape[3], x_train_conv.shape[4])))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.ConvLSTM2D(64, kernel_size=(1,3),return_sequences=True))\n",
    "atten_convlstm.add(attention(return_sequences=True))\n",
    "atten_convlstm.add(keras.layers.Flatten())\n",
    "atten_convlstm.add(keras.layers.Dense(512, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(64, activation='relu'))\n",
    "atten_convlstm.add(keras.layers.Dense(32))\n",
    "atten_convlstm.add(keras.layers.Dense(6))\n",
    "\n",
    "atten_convlstm.compile(loss='mse', optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0326 - mae: 0.1290 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0080 - mae: 0.0666 - val_loss: 0.0034 - val_mae: 0.0441\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0055 - mae: 0.0541 - val_loss: 0.0027 - val_mae: 0.0398\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0048 - mae: 0.0507 - val_loss: 0.0025 - val_mae: 0.0382\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0044 - mae: 0.0482 - val_loss: 0.0025 - val_mae: 0.0391\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0041 - mae: 0.0466 - val_loss: 0.0022 - val_mae: 0.0360\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0038 - mae: 0.0446 - val_loss: 0.0021 - val_mae: 0.0348\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0034 - mae: 0.0418 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0031 - mae: 0.0393 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0029 - mae: 0.0384 - val_loss: 0.0015 - val_mae: 0.0292\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0027 - mae: 0.0363 - val_loss: 0.0015 - val_mae: 0.0298\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0025 - mae: 0.0353 - val_loss: 0.0013 - val_mae: 0.0265\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0024 - mae: 0.0337 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0022 - mae: 0.0324 - val_loss: 0.0012 - val_mae: 0.0253\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0021 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0020 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0257\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0019 - mae: 0.0304 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0018 - mae: 0.0297 - val_loss: 9.2023e-04 - val_mae: 0.0223\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0018 - mae: 0.0288 - val_loss: 9.3742e-04 - val_mae: 0.0227\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0017 - mae: 0.0285 - val_loss: 9.2923e-04 - val_mae: 0.0224\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0016 - mae: 0.0278 - val_loss: 0.0012 - val_mae: 0.0274\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0016 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0016 - mae: 0.0271 - val_loss: 8.6178e-04 - val_mae: 0.0219\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0269 - val_loss: 8.3456e-04 - val_mae: 0.0214\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0015 - mae: 0.0266 - val_loss: 8.3588e-04 - val_mae: 0.0215\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0015 - mae: 0.0267 - val_loss: 8.7432e-04 - val_mae: 0.0222\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 7.7831e-04 - val_mae: 0.0205\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0258 - val_loss: 7.7611e-04 - val_mae: 0.0202\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0014 - mae: 0.0257 - val_loss: 7.4115e-04 - val_mae: 0.0199\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.2289e-04 - val_mae: 0.0195\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0253 - val_loss: 7.9618e-04 - val_mae: 0.0205\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0014 - mae: 0.0252 - val_loss: 7.6315e-04 - val_mae: 0.0203\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0013 - mae: 0.0251 - val_loss: 8.5045e-04 - val_mae: 0.0210\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0013 - mae: 0.0248 - val_loss: 9.3731e-04 - val_mae: 0.0238\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0013 - mae: 0.0245 - val_loss: 6.9105e-04 - val_mae: 0.0186\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 9.2279e-04 - val_mae: 0.0238\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 7.9748e-04 - val_mae: 0.0211\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0013 - mae: 0.0244 - val_loss: 6.7852e-04 - val_mae: 0.0188\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 6.9967e-04 - val_mae: 0.0195\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0237 - val_loss: 7.0938e-04 - val_mae: 0.0189\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 0.0012 - mae: 0.0241 - val_loss: 7.1428e-04 - val_mae: 0.0193\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0234 - val_loss: 7.8385e-04 - val_mae: 0.0213\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0233 - val_loss: 7.8647e-04 - val_mae: 0.0214\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0012 - mae: 0.0232 - val_loss: 7.5919e-04 - val_mae: 0.0212\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 6.1827e-04 - val_mae: 0.0181\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.0419e-04 - val_mae: 0.0180\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 6.4481e-04 - val_mae: 0.0189\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.0011 - mae: 0.0224 - val_loss: 5.6812e-04 - val_mae: 0.0175\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 5.7399e-04 - val_mae: 0.0176\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 0.0010 - mae: 0.0216 - val_loss: 5.6685e-04 - val_mae: 0.0174\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 6s 27ms/step - loss: 0.0010 - mae: 0.0218 - val_loss: 5.5875e-04 - val_mae: 0.0176\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.8644e-04 - mae: 0.0214 - val_loss: 5.5667e-04 - val_mae: 0.0175\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 9.9877e-04 - mae: 0.0217 - val_loss: 5.2630e-04 - val_mae: 0.0167\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.7127e-04 - mae: 0.0211 - val_loss: 6.7033e-04 - val_mae: 0.0201\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.7702e-04 - mae: 0.0214 - val_loss: 5.4348e-04 - val_mae: 0.0173\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.7554e-04 - mae: 0.0214 - val_loss: 6.4742e-04 - val_mae: 0.0195\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.7651e-04 - mae: 0.0215 - val_loss: 5.4867e-04 - val_mae: 0.0175\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.4458e-04 - mae: 0.0210 - val_loss: 5.2263e-04 - val_mae: 0.0168\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.5222e-04 - mae: 0.0211 - val_loss: 5.3474e-04 - val_mae: 0.0170\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.3121e-04 - mae: 0.0208 - val_loss: 5.3627e-04 - val_mae: 0.0170\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.6253e-04 - mae: 0.0212 - val_loss: 5.3754e-04 - val_mae: 0.0174\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.3095e-04 - mae: 0.0208 - val_loss: 5.6163e-04 - val_mae: 0.0179\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.5181e-04 - mae: 0.0212 - val_loss: 5.0969e-04 - val_mae: 0.0166\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.2790e-04 - mae: 0.0208 - val_loss: 6.1294e-04 - val_mae: 0.0192\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.1785e-04 - mae: 0.0206 - val_loss: 4.7495e-04 - val_mae: 0.0160\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.2471e-04 - mae: 0.0208 - val_loss: 5.1171e-04 - val_mae: 0.0167\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.1832e-04 - mae: 0.0207 - val_loss: 6.0397e-04 - val_mae: 0.0189\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.2349e-04 - mae: 0.0209 - val_loss: 5.3581e-04 - val_mae: 0.0174\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 9.0997e-04 - mae: 0.0207 - val_loss: 5.2309e-04 - val_mae: 0.0172\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.9545e-04 - mae: 0.0204 - val_loss: 5.2494e-04 - val_mae: 0.0173\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.9830e-04 - mae: 0.0204 - val_loss: 5.8302e-04 - val_mae: 0.0183\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.1508e-04 - mae: 0.0207 - val_loss: 4.8888e-04 - val_mae: 0.0163\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 9.1314e-04 - mae: 0.0208 - val_loss: 5.3052e-04 - val_mae: 0.0171\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.9680e-04 - mae: 0.0205 - val_loss: 5.2408e-04 - val_mae: 0.0173\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.8458e-04 - mae: 0.0203 - val_loss: 5.2376e-04 - val_mae: 0.0172\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.6762e-04 - mae: 0.0200 - val_loss: 5.0125e-04 - val_mae: 0.0168\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.8985e-04 - mae: 0.0205 - val_loss: 4.7956e-04 - val_mae: 0.0159\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.7576e-04 - mae: 0.0202 - val_loss: 4.9114e-04 - val_mae: 0.0163\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.5898e-04 - mae: 0.0200 - val_loss: 5.0927e-04 - val_mae: 0.0168\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.6614e-04 - mae: 0.0202 - val_loss: 5.9557e-04 - val_mae: 0.0190\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.4387e-04 - mae: 0.0197 - val_loss: 4.8304e-04 - val_mae: 0.0160\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.6229e-04 - mae: 0.0202 - val_loss: 4.9969e-04 - val_mae: 0.0165\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.3867e-04 - mae: 0.0198 - val_loss: 4.7708e-04 - val_mae: 0.0160\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.4267e-04 - mae: 0.0199 - val_loss: 5.9122e-04 - val_mae: 0.0187\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.5597e-04 - mae: 0.0200 - val_loss: 5.8695e-04 - val_mae: 0.0182\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.2338e-04 - mae: 0.0196 - val_loss: 4.7023e-04 - val_mae: 0.0160\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 8.4020e-04 - mae: 0.0199 - val_loss: 5.6510e-04 - val_mae: 0.0181\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.1774e-04 - mae: 0.0195 - val_loss: 4.6679e-04 - val_mae: 0.0159\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.3471e-04 - mae: 0.0199 - val_loss: 4.4768e-04 - val_mae: 0.0156\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 8.0986e-04 - mae: 0.0194 - val_loss: 4.8927e-04 - val_mae: 0.0163\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.3741e-04 - mae: 0.0199 - val_loss: 5.1366e-04 - val_mae: 0.0172\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.9524e-04 - mae: 0.0192 - val_loss: 4.9514e-04 - val_mae: 0.0167\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.1219e-04 - mae: 0.0196 - val_loss: 6.7556e-04 - val_mae: 0.0204\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 8.0291e-04 - mae: 0.0194 - val_loss: 4.5048e-04 - val_mae: 0.0156\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.1540e-04 - mae: 0.0196 - val_loss: 4.4543e-04 - val_mae: 0.0157\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.7609e-04 - mae: 0.0191 - val_loss: 4.7947e-04 - val_mae: 0.0162\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.8933e-04 - mae: 0.0192 - val_loss: 5.5730e-04 - val_mae: 0.0179\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.8144e-04 - mae: 0.0192 - val_loss: 6.3247e-04 - val_mae: 0.0195\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 8.0241e-04 - mae: 0.0195 - val_loss: 5.0135e-04 - val_mae: 0.0166\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.6401e-04 - mae: 0.0189 - val_loss: 5.2500e-04 - val_mae: 0.0176\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.6125e-04 - mae: 0.0189 - val_loss: 6.2419e-04 - val_mae: 0.0193\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.5954e-04 - mae: 0.0188 - val_loss: 4.7168e-04 - val_mae: 0.0159\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.6422e-04 - mae: 0.0190 - val_loss: 4.6647e-04 - val_mae: 0.0164\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.3792e-04 - mae: 0.0185 - val_loss: 4.5935e-04 - val_mae: 0.0159\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 7.2384e-04 - mae: 0.0183 - val_loss: 4.6811e-04 - val_mae: 0.0161\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.3115e-04 - mae: 0.0185 - val_loss: 4.7011e-04 - val_mae: 0.0161\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.2123e-04 - mae: 0.0183 - val_loss: 4.5706e-04 - val_mae: 0.0160\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.2124e-04 - mae: 0.0185 - val_loss: 5.1957e-04 - val_mae: 0.0173\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 7.2637e-04 - mae: 0.0185 - val_loss: 4.5893e-04 - val_mae: 0.0160\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.1421e-04 - mae: 0.0183 - val_loss: 5.4698e-04 - val_mae: 0.0183\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.2117e-04 - mae: 0.0185 - val_loss: 4.9232e-04 - val_mae: 0.0167\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.9850e-04 - mae: 0.0181 - val_loss: 4.2435e-04 - val_mae: 0.0153\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.0343e-04 - mae: 0.0182 - val_loss: 4.6111e-04 - val_mae: 0.0160\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.8551e-04 - mae: 0.0179 - val_loss: 4.7087e-04 - val_mae: 0.0163\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 7.0051e-04 - mae: 0.0182 - val_loss: 5.9973e-04 - val_mae: 0.0192\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 6s 25ms/step - loss: 6.8980e-04 - mae: 0.0181 - val_loss: 4.7038e-04 - val_mae: 0.0161\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.8534e-04 - mae: 0.0180 - val_loss: 6.3841e-04 - val_mae: 0.0204\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 6.8823e-04 - mae: 0.0181 - val_loss: 4.8989e-04 - val_mae: 0.0166\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 6.6431e-04 - mae: 0.0176 - val_loss: 4.6032e-04 - val_mae: 0.0157\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.7272e-04 - mae: 0.0178 - val_loss: 4.5018e-04 - val_mae: 0.0160\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.6272e-04 - mae: 0.0176 - val_loss: 4.8111e-04 - val_mae: 0.0162\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.5517e-04 - mae: 0.0175 - val_loss: 5.1477e-04 - val_mae: 0.0173\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.4802e-04 - mae: 0.0174 - val_loss: 5.4740e-04 - val_mae: 0.0178\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.5170e-04 - mae: 0.0175 - val_loss: 4.9788e-04 - val_mae: 0.0168\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.5163e-04 - mae: 0.0176 - val_loss: 5.0530e-04 - val_mae: 0.0170\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.4331e-04 - mae: 0.0175 - val_loss: 5.0460e-04 - val_mae: 0.0173\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.4052e-04 - mae: 0.0174 - val_loss: 4.4542e-04 - val_mae: 0.0154\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.3514e-04 - mae: 0.0173 - val_loss: 5.4792e-04 - val_mae: 0.0181\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.3211e-04 - mae: 0.0173 - val_loss: 4.8996e-04 - val_mae: 0.0166\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2384e-04 - mae: 0.0173 - val_loss: 5.4448e-04 - val_mae: 0.0176\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2691e-04 - mae: 0.0173 - val_loss: 4.5307e-04 - val_mae: 0.0158\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.2857e-04 - mae: 0.0174 - val_loss: 5.0259e-04 - val_mae: 0.0171\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 6.1132e-04 - mae: 0.0170 - val_loss: 4.4367e-04 - val_mae: 0.0154\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.9686e-04 - mae: 0.0168 - val_loss: 4.7009e-04 - val_mae: 0.0161\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.9794e-04 - mae: 0.0168 - val_loss: 4.5136e-04 - val_mae: 0.0158\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 6.0582e-04 - mae: 0.0170 - val_loss: 4.4494e-04 - val_mae: 0.0156\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 7s 28ms/step - loss: 5.8960e-04 - mae: 0.0167 - val_loss: 5.4372e-04 - val_mae: 0.0177\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 5.9071e-04 - mae: 0.0167 - val_loss: 5.0590e-04 - val_mae: 0.0173\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.8920e-04 - mae: 0.0167 - val_loss: 4.9398e-04 - val_mae: 0.0167\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.8971e-04 - mae: 0.0169 - val_loss: 5.2227e-04 - val_mae: 0.0174\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.9060e-04 - mae: 0.0168 - val_loss: 4.8195e-04 - val_mae: 0.0166\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6374e-04 - mae: 0.0164 - val_loss: 4.5033e-04 - val_mae: 0.0156\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.7135e-04 - mae: 0.0165 - val_loss: 5.1166e-04 - val_mae: 0.0170\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.6377e-04 - mae: 0.0164 - val_loss: 4.3332e-04 - val_mae: 0.0153\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.7037e-04 - mae: 0.0166 - val_loss: 5.3184e-04 - val_mae: 0.0178\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.5679e-04 - mae: 0.0163 - val_loss: 5.2609e-04 - val_mae: 0.0172\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.5139e-04 - mae: 0.0162 - val_loss: 5.1860e-04 - val_mae: 0.0168\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.5298e-04 - mae: 0.0163 - val_loss: 4.4807e-04 - val_mae: 0.0156\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4594e-04 - mae: 0.0162 - val_loss: 4.5089e-04 - val_mae: 0.0156\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.4853e-04 - mae: 0.0163 - val_loss: 4.4000e-04 - val_mae: 0.0154\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.3373e-04 - mae: 0.0160 - val_loss: 4.3353e-04 - val_mae: 0.0152\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.3606e-04 - mae: 0.0161 - val_loss: 4.8721e-04 - val_mae: 0.0167\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2458e-04 - mae: 0.0160 - val_loss: 4.9092e-04 - val_mae: 0.0166\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.2455e-04 - mae: 0.0159 - val_loss: 4.5276e-04 - val_mae: 0.0155\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1835e-04 - mae: 0.0159 - val_loss: 6.0008e-04 - val_mae: 0.0189\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1357e-04 - mae: 0.0157 - val_loss: 4.6837e-04 - val_mae: 0.0162\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.1190e-04 - mae: 0.0157 - val_loss: 4.5089e-04 - val_mae: 0.0157\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.0393e-04 - mae: 0.0156 - val_loss: 4.5667e-04 - val_mae: 0.0160\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 4.9758e-04 - mae: 0.0155 - val_loss: 5.1892e-04 - val_mae: 0.0169\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 5.0930e-04 - mae: 0.0157 - val_loss: 4.9819e-04 - val_mae: 0.0169\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 5.0228e-04 - mae: 0.0157 - val_loss: 4.5625e-04 - val_mae: 0.0156\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.9981e-04 - mae: 0.0156 - val_loss: 4.7436e-04 - val_mae: 0.0165\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.9315e-04 - mae: 0.0155 - val_loss: 4.5190e-04 - val_mae: 0.0157\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7621e-04 - mae: 0.0152 - val_loss: 4.8775e-04 - val_mae: 0.0168\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7801e-04 - mae: 0.0153 - val_loss: 4.4530e-04 - val_mae: 0.0155\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 4.9349e-04 - mae: 0.0156 - val_loss: 4.7671e-04 - val_mae: 0.0164\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7105e-04 - mae: 0.0152 - val_loss: 4.6859e-04 - val_mae: 0.0158\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.7605e-04 - mae: 0.0153 - val_loss: 4.4399e-04 - val_mae: 0.0155\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.6899e-04 - mae: 0.0151 - val_loss: 4.8576e-04 - val_mae: 0.0164\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.6514e-04 - mae: 0.0151 - val_loss: 5.3312e-04 - val_mae: 0.0178\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5030e-04 - mae: 0.0148 - val_loss: 4.7934e-04 - val_mae: 0.0162\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5177e-04 - mae: 0.0148 - val_loss: 4.9128e-04 - val_mae: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4509e-04 - mae: 0.0148 - val_loss: 5.5367e-04 - val_mae: 0.0172\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4877e-04 - mae: 0.0149 - val_loss: 4.7291e-04 - val_mae: 0.0159\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.5330e-04 - mae: 0.0150 - val_loss: 4.8631e-04 - val_mae: 0.0163\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4204e-04 - mae: 0.0148 - val_loss: 4.6683e-04 - val_mae: 0.0160\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4076e-04 - mae: 0.0147 - val_loss: 5.6421e-04 - val_mae: 0.0178\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.3785e-04 - mae: 0.0147 - val_loss: 4.6669e-04 - val_mae: 0.0161\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.4167e-04 - mae: 0.0148 - val_loss: 4.9162e-04 - val_mae: 0.0163\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2712e-04 - mae: 0.0146 - val_loss: 4.8756e-04 - val_mae: 0.0163\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2367e-04 - mae: 0.0144 - val_loss: 4.3667e-04 - val_mae: 0.0152\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2280e-04 - mae: 0.0145 - val_loss: 4.4143e-04 - val_mae: 0.0153\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.3815e-04 - mae: 0.0148 - val_loss: 5.3328e-04 - val_mae: 0.0171\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2594e-04 - mae: 0.0146 - val_loss: 4.5149e-04 - val_mae: 0.0157\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.1636e-04 - mae: 0.0144 - val_loss: 4.6795e-04 - val_mae: 0.0157\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.2011e-04 - mae: 0.0145 - val_loss: 5.9474e-04 - val_mae: 0.0182\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.1457e-04 - mae: 0.0144 - val_loss: 4.5272e-04 - val_mae: 0.0156\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 4.0473e-04 - mae: 0.0142 - val_loss: 5.6018e-04 - val_mae: 0.0174\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.0350e-04 - mae: 0.0143 - val_loss: 5.6511e-04 - val_mae: 0.0179\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.0205e-04 - mae: 0.0142 - val_loss: 4.7271e-04 - val_mae: 0.0160\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.1097e-04 - mae: 0.0143 - val_loss: 7.0376e-04 - val_mae: 0.0206\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.0127e-04 - mae: 0.0142 - val_loss: 4.6802e-04 - val_mae: 0.0160\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 4.0199e-04 - mae: 0.0142 - val_loss: 5.3394e-04 - val_mae: 0.0168\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 6s 26ms/step - loss: 4.0075e-04 - mae: 0.0142 - val_loss: 5.0773e-04 - val_mae: 0.0166\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 3.8882e-04 - mae: 0.0139 - val_loss: 4.6688e-04 - val_mae: 0.0157\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 3.8991e-04 - mae: 0.0140 - val_loss: 5.5410e-04 - val_mae: 0.0169\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 3.8345e-04 - mae: 0.0139 - val_loss: 4.9449e-04 - val_mae: 0.0166\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 3.7536e-04 - mae: 0.0137 - val_loss: 4.6486e-04 - val_mae: 0.0157\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 6s 25ms/step - loss: 3.7578e-04 - mae: 0.0137 - val_loss: 5.4052e-04 - val_mae: 0.0172\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean Squared Error is: 6.031831646131014\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('ConvLSTM')\n",
    "    os.chdir(os.path.join(dest,'ConvLSTM'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_convlstm.fit(x_train_conv,y_train,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_convlstm.load_weights(filepath_attention)\n",
    "preds = atten_convlstm.predict(x_test_conv)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('ConvLSTM Results.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the prelimaries \n",
    "\n",
    "filepath_simple = 'simple_seq2seq.hdf5'\n",
    "filepath_attention = 'attention_seq2seq.hdf5'\n",
    "\n",
    "checkpoint_simple = keras.callbacks.ModelCheckpoint(filepath_simple,monitor='val_loss',save_best_only=True)\n",
    "checkpoint_attention = keras.callbacks.ModelCheckpoint(filepath_attention, monitor='val_loss',save_best_only=True)\n",
    "\n",
    "wk=Workbook()\n",
    "sheet1 = wk.add_sheet('Simple', cell_overwrite_ok=True)\n",
    "sheet2 = wk.add_sheet('Attention', cell_overwrite_ok=True)\n",
    "sheet3 = wk.add_sheet('Predictions', cell_overwrite_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_seq = y_train.reshape(y_train.shape[0], y_train.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_7/PartitionedCall:1\", shape=(None, 6, 128), dtype=float32)\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 24, 128)      67072       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 24, 128)      131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 24, 128)      131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 128), (None, 131584      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 6, 128)       0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 6, 128)       131584      repeat_vector[0][0]              \n",
      "                                                                 lstm_3[0][0]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 6, 128)       131584      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 6, 128)       131584      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 6, 128)       131584      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 1)         129         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 988,289\n",
      "Trainable params: 988,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "input_train = keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "output_train = keras.layers.Input(shape=(y_train_seq.shape[1], y_train_seq.shape[2]))\n",
    "\n",
    "## Encoder Section##\n",
    "encoder_first = keras.layers.LSTM(128, return_sequences=True, return_state=False)(input_train)\n",
    "encoder_second = keras.layers.LSTM(128, return_sequences=True)(encoder_first)\n",
    "encoder_third = keras.layers.LSTM(128, return_sequences=True)(encoder_second)\n",
    "encoder_fourth, encoder_fourth_s1, encoder_fourth_s2 = keras.layers.LSTM(128,return_sequences=False, return_state=True)(encoder_third)\n",
    "\n",
    "##Decorder Section##\n",
    "decoder_first = keras.layers.RepeatVector(output_train.shape[1])(encoder_fourth)\n",
    "decoder_second = keras.layers.LSTM(128, return_state=False, return_sequences=True)(decoder_first,initial_state=[encoder_fourth,encoder_fourth_s2])\n",
    "decoder_third = keras.layers.LSTM(128,return_sequences=True)(decoder_second)\n",
    "decoder_fourth = keras.layers.LSTM(128,return_sequences=True)(decoder_third)\n",
    "decoder_fifth = keras.layers.LSTM(128,return_sequences=True)(decoder_fourth)\n",
    "print(decoder_fifth)\n",
    "\n",
    "##Output Section##\n",
    "output = keras.layers.TimeDistributed(keras.layers.Dense(output_train.shape[2]))(decoder_fifth)\n",
    "\n",
    "simple_seq = keras.Model(inputs=input_train, outputs=output)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "simple_seq.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "simple_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 0.0185 - mae: 0.0956 - val_loss: 0.0034 - val_mae: 0.0451\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0054 - mae: 0.0551 - val_loss: 0.0022 - val_mae: 0.0363\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0042 - mae: 0.0475 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0032 - mae: 0.0410 - val_loss: 0.0017 - val_mae: 0.0318\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0023 - mae: 0.0339 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0019 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0015 - mae: 0.0274 - val_loss: 8.3606e-04 - val_mae: 0.0229\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0014 - mae: 0.0266 - val_loss: 9.2053e-04 - val_mae: 0.0246\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 5.8331e-04 - val_mae: 0.0184\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 6.8756e-04 - val_mae: 0.0203\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0013 - mae: 0.0256 - val_loss: 5.9555e-04 - val_mae: 0.0191\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0012 - mae: 0.0245 - val_loss: 5.1672e-04 - val_mae: 0.0173\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 7.8918e-04 - val_mae: 0.0215\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0012 - mae: 0.0240 - val_loss: 5.2046e-04 - val_mae: 0.0172\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0012 - mae: 0.0239 - val_loss: 5.0479e-04 - val_mae: 0.0171\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 5.4622e-04 - val_mae: 0.0180\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 5.6262e-04 - val_mae: 0.0177\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 5.5627e-04 - val_mae: 0.0180\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0011 - mae: 0.0228 - val_loss: 5.4203e-04 - val_mae: 0.0177\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0010 - mae: 0.0225 - val_loss: 6.3101e-04 - val_mae: 0.0196\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 6.2492e-04 - val_mae: 0.0192\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.6101e-04 - mae: 0.0215 - val_loss: 7.5976e-04 - val_mae: 0.0219\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 9.0469e-04 - val_mae: 0.0247\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 4.8871e-04 - val_mae: 0.0165\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.4628e-04 - mae: 0.0212 - val_loss: 6.7123e-04 - val_mae: 0.0194\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.7793e-04 - mae: 0.0218 - val_loss: 4.4549e-04 - val_mae: 0.0157\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.3659e-04 - mae: 0.0212 - val_loss: 5.8597e-04 - val_mae: 0.0190\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.3338e-04 - mae: 0.0211 - val_loss: 8.7977e-04 - val_mae: 0.0237\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.5269e-04 - mae: 0.0215 - val_loss: 4.0919e-04 - val_mae: 0.0150\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.1531e-04 - mae: 0.0210 - val_loss: 4.9532e-04 - val_mae: 0.0166\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.0088e-04 - mae: 0.0208 - val_loss: 6.5724e-04 - val_mae: 0.0200\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.9022e-04 - mae: 0.0206 - val_loss: 3.8658e-04 - val_mae: 0.0146\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.5964e-04 - mae: 0.0201 - val_loss: 4.0800e-04 - val_mae: 0.0151\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.2084e-04 - mae: 0.0197 - val_loss: 6.5068e-04 - val_mae: 0.0181\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.4339e-04 - mae: 0.0200 - val_loss: 4.3018e-04 - val_mae: 0.0153\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.1298e-04 - mae: 0.0196 - val_loss: 3.9958e-04 - val_mae: 0.0146\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.0296e-04 - mae: 0.0195 - val_loss: 3.7895e-04 - val_mae: 0.0143\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.0470e-04 - mae: 0.0195 - val_loss: 4.2401e-04 - val_mae: 0.0156\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.7338e-04 - mae: 0.0192 - val_loss: 3.7579e-04 - val_mae: 0.0143\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.6513e-04 - mae: 0.0191 - val_loss: 4.7091e-04 - val_mae: 0.0169\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.4852e-04 - mae: 0.0191 - val_loss: 4.3249e-04 - val_mae: 0.0158\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.2437e-04 - mae: 0.0187 - val_loss: 4.6633e-04 - val_mae: 0.0156\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 6.9388e-04 - mae: 0.0182 - val_loss: 3.9536e-04 - val_mae: 0.0144\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.9738e-04 - mae: 0.0184 - val_loss: 5.1782e-04 - val_mae: 0.0166\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.9298e-04 - mae: 0.0183 - val_loss: 5.2212e-04 - val_mae: 0.0168\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.5738e-04 - mae: 0.0177 - val_loss: 4.5920e-04 - val_mae: 0.0162\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2880e-04 - mae: 0.0176 - val_loss: 4.1775e-04 - val_mae: 0.0155\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2180e-04 - mae: 0.0173 - val_loss: 5.2801e-04 - val_mae: 0.0174\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 6.0735e-04 - mae: 0.0173 - val_loss: 5.2678e-04 - val_mae: 0.0165\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 6.0388e-04 - mae: 0.0173 - val_loss: 5.6009e-04 - val_mae: 0.0171\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 6.2927e-04 - mae: 0.0179 - val_loss: 4.6417e-04 - val_mae: 0.0165\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.5097e-04 - mae: 0.0166 - val_loss: 5.5201e-04 - val_mae: 0.0175\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.7414e-04 - mae: 0.0169 - val_loss: 4.1237e-04 - val_mae: 0.0143\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.5298e-04 - mae: 0.0167 - val_loss: 5.5924e-04 - val_mae: 0.0175\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.1276e-04 - mae: 0.0162 - val_loss: 5.8278e-04 - val_mae: 0.0157\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.9691e-04 - mae: 0.0159 - val_loss: 4.8017e-04 - val_mae: 0.0153\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.9282e-04 - mae: 0.0158 - val_loss: 5.4533e-04 - val_mae: 0.0166\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.7586e-04 - mae: 0.0156 - val_loss: 7.3020e-04 - val_mae: 0.0205\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 3s 12ms/step - loss: 4.3701e-04 - mae: 0.0150 - val_loss: 5.1946e-04 - val_mae: 0.0149\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.9720e-04 - mae: 0.0159 - val_loss: 6.5243e-04 - val_mae: 0.0181\n",
      "Epoch 61/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.4816e-04 - mae: 0.0152 - val_loss: 5.6467e-04 - val_mae: 0.0163\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.0192e-04 - mae: 0.0145 - val_loss: 5.0426e-04 - val_mae: 0.0161\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.9935e-04 - mae: 0.0146 - val_loss: 5.1572e-04 - val_mae: 0.0160\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.6859e-04 - mae: 0.0139 - val_loss: 5.9075e-04 - val_mae: 0.0174\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.7967e-04 - mae: 0.0142 - val_loss: 5.3719e-04 - val_mae: 0.0157\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.8320e-04 - mae: 0.0143 - val_loss: 5.2046e-04 - val_mae: 0.0148\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.6521e-04 - mae: 0.0140 - val_loss: 4.5521e-04 - val_mae: 0.0151\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.1363e-04 - mae: 0.0130 - val_loss: 5.2087e-04 - val_mae: 0.0153\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.2689e-04 - mae: 0.0132 - val_loss: 6.1229e-04 - val_mae: 0.0183\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.5471e-04 - mae: 0.0139 - val_loss: 6.5136e-04 - val_mae: 0.0183\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.0591e-04 - mae: 0.0128 - val_loss: 5.6349e-04 - val_mae: 0.0170\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.7757e-04 - mae: 0.0123 - val_loss: 5.0564e-04 - val_mae: 0.0160\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.7680e-04 - mae: 0.0123 - val_loss: 6.1788e-04 - val_mae: 0.0177\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.8852e-04 - mae: 0.0142 - val_loss: 5.3903e-04 - val_mae: 0.0159\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.4338e-04 - mae: 0.0116 - val_loss: 5.8114e-04 - val_mae: 0.0172\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.3168e-04 - mae: 0.0113 - val_loss: 5.0282e-04 - val_mae: 0.0160\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.3196e-04 - mae: 0.0113 - val_loss: 5.1694e-04 - val_mae: 0.0163\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.2242e-04 - mae: 0.0112 - val_loss: 5.4378e-04 - val_mae: 0.0167\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.0713e-04 - mae: 0.0107 - val_loss: 5.2614e-04 - val_mae: 0.0165\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.2621e-04 - mae: 0.0113 - val_loss: 5.6170e-04 - val_mae: 0.0165\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.0663e-04 - mae: 0.0108 - val_loss: 5.1570e-04 - val_mae: 0.0160\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.9330e-04 - mae: 0.0104 - val_loss: 5.3220e-04 - val_mae: 0.0159\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.9144e-04 - mae: 0.0104 - val_loss: 5.1894e-04 - val_mae: 0.0164\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.6622e-04 - mae: 0.0097 - val_loss: 5.4062e-04 - val_mae: 0.0165\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.7920e-04 - mae: 0.0100 - val_loss: 5.6923e-04 - val_mae: 0.0168\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.7785e-04 - mae: 0.0100 - val_loss: 5.8790e-04 - val_mae: 0.0170\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.6560e-04 - mae: 0.0097 - val_loss: 5.4178e-04 - val_mae: 0.0168\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.6906e-04 - mae: 0.0097 - val_loss: 5.0326e-04 - val_mae: 0.0165\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.6858e-04 - mae: 0.0098 - val_loss: 6.0014e-04 - val_mae: 0.0183\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.5168e-04 - mae: 0.0092 - val_loss: 5.5014e-04 - val_mae: 0.0171\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.5512e-04 - mae: 0.0094 - val_loss: 7.0880e-04 - val_mae: 0.0212\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.4416e-04 - mae: 0.0090 - val_loss: 5.3891e-04 - val_mae: 0.0170\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.3519e-04 - mae: 0.0087 - val_loss: 6.0288e-04 - val_mae: 0.0176\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.4057e-04 - mae: 0.0090 - val_loss: 5.7767e-04 - val_mae: 0.0174\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.3086e-04 - mae: 0.0086 - val_loss: 5.5913e-04 - val_mae: 0.0179\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.3381e-04 - mae: 0.0087 - val_loss: 5.5974e-04 - val_mae: 0.0180\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.2733e-04 - mae: 0.0085 - val_loss: 5.3845e-04 - val_mae: 0.0174\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.1115e-04 - mae: 0.0079 - val_loss: 5.0825e-04 - val_mae: 0.0163\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.2092e-04 - mae: 0.0083 - val_loss: 5.6501e-04 - val_mae: 0.0176\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.1053e-04 - mae: 0.0079 - val_loss: 5.1785e-04 - val_mae: 0.0165\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.2741e-04 - mae: 0.0085 - val_loss: 5.2941e-04 - val_mae: 0.0168\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.0618e-04 - mae: 0.0077 - val_loss: 5.0912e-04 - val_mae: 0.0168\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.0064e-04 - mae: 0.0075 - val_loss: 5.2668e-04 - val_mae: 0.0170\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 1.1515e-04 - mae: 0.0081 - val_loss: 5.4241e-04 - val_mae: 0.0173\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.0326e-04 - mae: 0.0077 - val_loss: 5.4455e-04 - val_mae: 0.0172\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.0271e-04 - mae: 0.0076 - val_loss: 6.1544e-04 - val_mae: 0.0184\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.3571e-05 - mae: 0.0072 - val_loss: 5.6082e-04 - val_mae: 0.0173\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.4715e-05 - mae: 0.0073 - val_loss: 5.3184e-04 - val_mae: 0.0172\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.6115e-05 - mae: 0.0073 - val_loss: 5.3787e-04 - val_mae: 0.0173\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.9785e-05 - mae: 0.0071 - val_loss: 5.4173e-04 - val_mae: 0.0174\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.0760e-05 - mae: 0.0072 - val_loss: 5.2966e-04 - val_mae: 0.0170\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.6453e-05 - mae: 0.0070 - val_loss: 5.1432e-04 - val_mae: 0.0169\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.7028e-05 - mae: 0.0066 - val_loss: 5.5442e-04 - val_mae: 0.0181\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 8.0862e-05 - mae: 0.0068 - val_loss: 5.1989e-04 - val_mae: 0.0170\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.0376e-05 - mae: 0.0071 - val_loss: 5.2493e-04 - val_mae: 0.0172\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 3s 12ms/step - loss: 8.5487e-05 - mae: 0.0069 - val_loss: 5.0802e-04 - val_mae: 0.0167\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.7789e-05 - mae: 0.0066 - val_loss: 5.3820e-04 - val_mae: 0.0170\n",
      "Epoch 118/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.1959e-05 - mae: 0.0072 - val_loss: 5.6422e-04 - val_mae: 0.0183\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.5257e-05 - mae: 0.0065 - val_loss: 5.6467e-04 - val_mae: 0.0176\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.9153e-05 - mae: 0.0067 - val_loss: 5.3154e-04 - val_mae: 0.0174\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.0918e-05 - mae: 0.0063 - val_loss: 5.4040e-04 - val_mae: 0.0175\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.3533e-05 - mae: 0.0064 - val_loss: 6.4768e-04 - val_mae: 0.0200\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 8.5241e-05 - mae: 0.0069 - val_loss: 5.3291e-04 - val_mae: 0.0172\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.1342e-05 - mae: 0.0063 - val_loss: 5.5503e-04 - val_mae: 0.0175\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.7968e-05 - mae: 0.0062 - val_loss: 5.1802e-04 - val_mae: 0.0170\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2210e-05 - mae: 0.0059 - val_loss: 5.3962e-04 - val_mae: 0.0180\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.0438e-04 - mae: 0.0076 - val_loss: 5.1846e-04 - val_mae: 0.0170\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 7.4560e-05 - mae: 0.0064 - val_loss: 5.3188e-04 - val_mae: 0.0174\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.8616e-05 - mae: 0.0058 - val_loss: 5.5548e-04 - val_mae: 0.0181\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.6954e-05 - mae: 0.0057 - val_loss: 5.5172e-04 - val_mae: 0.0178\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.7547e-05 - mae: 0.0057 - val_loss: 5.2942e-04 - val_mae: 0.0171\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.9504e-05 - mae: 0.0058 - val_loss: 5.4831e-04 - val_mae: 0.0177\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2318e-05 - mae: 0.0059 - val_loss: 5.7667e-04 - val_mae: 0.0181\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.8161e-05 - mae: 0.0057 - val_loss: 5.3617e-04 - val_mae: 0.0174\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2256e-05 - mae: 0.0059 - val_loss: 5.5384e-04 - val_mae: 0.0178\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.3428e-05 - mae: 0.0060 - val_loss: 5.4715e-04 - val_mae: 0.0175\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.2620e-05 - mae: 0.0059 - val_loss: 5.8296e-04 - val_mae: 0.0186\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.1963e-05 - mae: 0.0059 - val_loss: 6.4671e-04 - val_mae: 0.0199\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 9.0606e-05 - mae: 0.0072 - val_loss: 5.5414e-04 - val_mae: 0.0178\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.9281e-05 - mae: 0.0057 - val_loss: 5.6259e-04 - val_mae: 0.0179\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.2234e-05 - mae: 0.0054 - val_loss: 5.7218e-04 - val_mae: 0.0180\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.9390e-05 - mae: 0.0053 - val_loss: 5.4356e-04 - val_mae: 0.0174\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.3807e-05 - mae: 0.0050 - val_loss: 5.5437e-04 - val_mae: 0.0177\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.7056e-05 - mae: 0.0052 - val_loss: 5.8488e-04 - val_mae: 0.0185\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 6.6965e-05 - mae: 0.0062 - val_loss: 5.5097e-04 - val_mae: 0.0175\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.7850e-05 - mae: 0.0057 - val_loss: 5.5468e-04 - val_mae: 0.0176\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.9115e-05 - mae: 0.0053 - val_loss: 5.8462e-04 - val_mae: 0.0185\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.0984e-05 - mae: 0.0053 - val_loss: 5.9359e-04 - val_mae: 0.0186\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.6133e-05 - mae: 0.0051 - val_loss: 5.4346e-04 - val_mae: 0.0176\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.6851e-05 - mae: 0.0051 - val_loss: 5.3860e-04 - val_mae: 0.0174\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.5763e-05 - mae: 0.0051 - val_loss: 5.7603e-04 - val_mae: 0.0180\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.7889e-05 - mae: 0.0052 - val_loss: 5.8177e-04 - val_mae: 0.0181\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - ETA: 0s - loss: 5.2304e-05 - mae: 0.005 - 3s 13ms/step - loss: 5.2114e-05 - mae: 0.0054 - val_loss: 5.9616e-04 - val_mae: 0.0185\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.1452e-05 - mae: 0.0053 - val_loss: 5.5118e-04 - val_mae: 0.0175\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.3833e-05 - mae: 0.0056 - val_loss: 5.7682e-04 - val_mae: 0.0183\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.4491e-05 - mae: 0.0055 - val_loss: 5.3059e-04 - val_mae: 0.0173\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.3371e-05 - mae: 0.0049 - val_loss: 5.5991e-04 - val_mae: 0.0175\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.9025e-05 - mae: 0.0053 - val_loss: 5.6561e-04 - val_mae: 0.0175\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.4827e-05 - mae: 0.0056 - val_loss: 5.7894e-04 - val_mae: 0.0186\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.1341e-05 - mae: 0.0049 - val_loss: 5.5715e-04 - val_mae: 0.0180\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.6799e-05 - mae: 0.0046 - val_loss: 5.4169e-04 - val_mae: 0.0175\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.7005e-05 - mae: 0.0046 - val_loss: 5.5659e-04 - val_mae: 0.0178\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.6662e-05 - mae: 0.0046 - val_loss: 5.6633e-04 - val_mae: 0.0181\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.0658e-05 - mae: 0.0048 - val_loss: 5.4639e-04 - val_mae: 0.0177\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.0158e-05 - mae: 0.0053 - val_loss: 5.9022e-04 - val_mae: 0.0183\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.8167e-05 - mae: 0.0052 - val_loss: 5.6885e-04 - val_mae: 0.0180\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 5.4399e-05 - mae: 0.0055 - val_loss: 5.8285e-04 - val_mae: 0.0184\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.3825e-04 - mae: 0.0123 - val_loss: 5.4214e-04 - val_mae: 0.0170\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 1.2842e-04 - mae: 0.0080 - val_loss: 4.8935e-04 - val_mae: 0.0166\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.2712e-05 - mae: 0.0049 - val_loss: 5.0450e-04 - val_mae: 0.0170\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.0279e-05 - mae: 0.0042 - val_loss: 5.1343e-04 - val_mae: 0.0171\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 2.4826e-05 - mae: 0.0038 - val_loss: 5.0980e-04 - val_mae: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.1689e-05 - mae: 0.0035 - val_loss: 5.2503e-04 - val_mae: 0.0172\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.1052e-05 - mae: 0.0035 - val_loss: 5.4177e-04 - val_mae: 0.0176\n",
      "Epoch 175/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.3308e-05 - mae: 0.0037 - val_loss: 5.3399e-04 - val_mae: 0.0175\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.1480e-05 - mae: 0.0035 - val_loss: 5.3928e-04 - val_mae: 0.0174\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.3360e-05 - mae: 0.0037 - val_loss: 5.3273e-04 - val_mae: 0.0175\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.0272e-05 - mae: 0.0042 - val_loss: 5.4243e-04 - val_mae: 0.0176\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.6582e-05 - mae: 0.0046 - val_loss: 5.9539e-04 - val_mae: 0.0190\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.8772e-05 - mae: 0.0047 - val_loss: 5.4972e-04 - val_mae: 0.0177\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.7601e-05 - mae: 0.0046 - val_loss: 5.1953e-04 - val_mae: 0.0173\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.4868e-05 - mae: 0.0044 - val_loss: 6.0031e-04 - val_mae: 0.0189\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.7769e-05 - mae: 0.0046 - val_loss: 5.7446e-04 - val_mae: 0.0184\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 4.0496e-05 - mae: 0.0048 - val_loss: 5.6470e-04 - val_mae: 0.0182\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.3453e-05 - mae: 0.0044 - val_loss: 5.5508e-04 - val_mae: 0.0178\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.1375e-05 - mae: 0.0042 - val_loss: 5.4866e-04 - val_mae: 0.0180\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.2485e-05 - mae: 0.0043 - val_loss: 5.4391e-04 - val_mae: 0.0176\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.0948e-05 - mae: 0.0042 - val_loss: 5.5955e-04 - val_mae: 0.0179\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.8521e-05 - mae: 0.0047 - val_loss: 5.8385e-04 - val_mae: 0.0187\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.4363e-05 - mae: 0.0044 - val_loss: 5.4994e-04 - val_mae: 0.0180\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.8151e-05 - mae: 0.0046 - val_loss: 6.4157e-04 - val_mae: 0.0199\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 5.4833e-05 - mae: 0.0055 - val_loss: 5.3383e-04 - val_mae: 0.0172\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.3129e-05 - mae: 0.0043 - val_loss: 5.2317e-04 - val_mae: 0.0172\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.7930e-05 - mae: 0.0040 - val_loss: 5.4648e-04 - val_mae: 0.0178\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.7002e-05 - mae: 0.0039 - val_loss: 5.7490e-04 - val_mae: 0.0183\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 2.7384e-05 - mae: 0.0040 - val_loss: 5.5913e-04 - val_mae: 0.0179\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.7480e-05 - mae: 0.0047 - val_loss: 5.5821e-04 - val_mae: 0.0180\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.5295e-05 - mae: 0.0045 - val_loss: 5.3818e-04 - val_mae: 0.0176\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.0763e-05 - mae: 0.0042 - val_loss: 5.7362e-04 - val_mae: 0.0183\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 3s 12ms/step - loss: 3.3295e-05 - mae: 0.0043 - val_loss: 5.3954e-04 - val_mae: 0.0175\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2150, 6)\n",
      "The Mean Squared Error is: 6.052561843251212\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Seq2Seq')\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = simple_seq.fit(x_train,y_train_seq,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_simple])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "simple_seq.load_weights(filepath_simple)\n",
    "preds = simple_seq.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet1.write(0, 0, 'MSE')\n",
    "        sheet1.write(0, 1, 'Hours Ahead')\n",
    "        sheet1.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet1.write(i + 1, 1, i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 2)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 24, 128)      67072       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 24, 128)      131584      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 24, 128)      131584      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 24, 128), (N 131584      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 6, 128)       0           lstm_3[0][1]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 6, 128)       131584      repeat_vector[0][0]              \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 6, 24)        0           lstm_4[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 6, 24)        0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 6, 128)       0           activation[0][0]                 \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 256)       0           dot_1[0][0]                      \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 6, 128)       197120      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 6, 128)       131584      lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 6, 128)       131584      lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 6, 1)         129         lstm_7[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,053,825\n",
      "Trainable params: 1,053,825\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " K.clear_session()\n",
    "\n",
    "input_train = keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "output_train = keras.layers.Input(shape=(y_train_seq.shape[1], y_train_seq.shape[2]))\n",
    "\n",
    "## Encoder Section##\n",
    "encoder_first = keras.layers.LSTM(128, return_sequences=True, return_state=False)(input_train)\n",
    "encoder_second = keras.layers.LSTM(128, return_sequences=True)(encoder_first)\n",
    "encoder_third = keras.layers.LSTM(128, return_sequences=True)(encoder_second)\n",
    "encoder_fourth, encoder_fourth_s1, encoder_fourth_s2 = keras.layers.LSTM(128,return_sequences=True,return_state=True)(encoder_third)\n",
    "\n",
    "##Decoder Section##\n",
    "decoder_first = keras.layers.RepeatVector(output_train.shape[1])(encoder_fourth_s1)\n",
    "decoder_second = keras.layers.LSTM(128, return_state=False, return_sequences=True)(decoder_first, initial_state=[encoder_fourth_s1, encoder_fourth_s2])\n",
    "\n",
    "attention = keras.layers.dot([decoder_second, encoder_fourth], axes=[2, 2])\n",
    "attention = keras.layers.Activation('softmax')(attention)\n",
    "context = keras.layers.dot([attention, encoder_fourth], axes=[2, 1])\n",
    "\n",
    "decoder_third = keras.layers.concatenate([context, decoder_second])\n",
    "\n",
    "decoder_fourth = keras.layers.LSTM(128, return_sequences=True)(decoder_third)\n",
    "decoder_fifth = keras.layers.LSTM(128, return_sequences=True)(decoder_fourth)\n",
    "decoder_sixth = keras.layers.LSTM(128, return_sequences=True)(decoder_fifth)\n",
    "\n",
    "##Output Section##\n",
    "output = keras.layers.TimeDistributed(keras.layers.Dense(output_train.shape[2]))(decoder_sixth)\n",
    "\n",
    "atten_seq = keras.Model(inputs=input_train, outputs=output)\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "atten_seq.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "atten_seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory present\n",
      "Epoch 1/200\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 0.0349 - mae: 0.1353 - val_loss: 0.0052 - val_mae: 0.0571\n",
      "Epoch 2/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0078 - mae: 0.0662 - val_loss: 0.0047 - val_mae: 0.0534\n",
      "Epoch 3/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0073 - mae: 0.0647 - val_loss: 0.0053 - val_mae: 0.0566\n",
      "Epoch 4/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0066 - mae: 0.0614 - val_loss: 0.0045 - val_mae: 0.0518\n",
      "Epoch 5/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0058 - mae: 0.0575 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 6/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0055 - mae: 0.0553 - val_loss: 0.0034 - val_mae: 0.0460\n",
      "Epoch 7/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0052 - mae: 0.0534 - val_loss: 0.0028 - val_mae: 0.0420\n",
      "Epoch 8/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0049 - mae: 0.0518 - val_loss: 0.0026 - val_mae: 0.0397\n",
      "Epoch 9/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0045 - mae: 0.0496 - val_loss: 0.0025 - val_mae: 0.0391\n",
      "Epoch 10/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0045 - mae: 0.0494 - val_loss: 0.0022 - val_mae: 0.0370\n",
      "Epoch 11/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0043 - mae: 0.0480 - val_loss: 0.0022 - val_mae: 0.0371\n",
      "Epoch 12/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0469 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 13/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0040 - mae: 0.0467 - val_loss: 0.0019 - val_mae: 0.0339\n",
      "Epoch 14/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0037 - mae: 0.0445 - val_loss: 0.0021 - val_mae: 0.0355\n",
      "Epoch 15/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0038 - mae: 0.0451 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 16/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 17/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0035 - mae: 0.0431 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 18/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0034 - mae: 0.0420 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 19/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0033 - mae: 0.0417 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 20/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0033 - mae: 0.0410 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 21/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0031 - mae: 0.0401 - val_loss: 0.0017 - val_mae: 0.0317\n",
      "Epoch 22/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0031 - mae: 0.0398 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 23/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 24/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 25/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0027 - mae: 0.0372 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 26/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0025 - mae: 0.0360 - val_loss: 0.0012 - val_mae: 0.0267\n",
      "Epoch 27/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0024 - mae: 0.0347 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 28/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0022 - mae: 0.0336 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 29/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0022 - mae: 0.0332 - val_loss: 0.0010 - val_mae: 0.0246\n",
      "Epoch 30/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0021 - mae: 0.0324 - val_loss: 9.2883e-04 - val_mae: 0.0234\n",
      "Epoch 31/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0020 - mae: 0.0320 - val_loss: 9.8122e-04 - val_mae: 0.0247\n",
      "Epoch 32/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0019 - mae: 0.0305 - val_loss: 8.7356e-04 - val_mae: 0.0229\n",
      "Epoch 33/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 9.9567e-04 - val_mae: 0.0246\n",
      "Epoch 34/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 0.0015 - val_mae: 0.0326\n",
      "Epoch 35/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0017 - mae: 0.0289 - val_loss: 9.2871e-04 - val_mae: 0.0242\n",
      "Epoch 36/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0016 - mae: 0.0286 - val_loss: 0.0012 - val_mae: 0.0281\n",
      "Epoch 37/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0016 - mae: 0.0282 - val_loss: 7.3885e-04 - val_mae: 0.0210\n",
      "Epoch 38/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0015 - mae: 0.0271 - val_loss: 7.7781e-04 - val_mae: 0.0215\n",
      "Epoch 39/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0015 - mae: 0.0272 - val_loss: 7.0251e-04 - val_mae: 0.0205\n",
      "Epoch 40/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0015 - mae: 0.0268 - val_loss: 8.1403e-04 - val_mae: 0.0225\n",
      "Epoch 41/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0014 - mae: 0.0260 - val_loss: 6.8524e-04 - val_mae: 0.0200\n",
      "Epoch 42/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0014 - mae: 0.0269 - val_loss: 7.3980e-04 - val_mae: 0.0212\n",
      "Epoch 43/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0014 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0247\n",
      "Epoch 44/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0013 - mae: 0.0255 - val_loss: 8.5133e-04 - val_mae: 0.0234\n",
      "Epoch 45/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0013 - mae: 0.0250 - val_loss: 7.2684e-04 - val_mae: 0.0208\n",
      "Epoch 46/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0013 - mae: 0.0253 - val_loss: 7.5082e-04 - val_mae: 0.0219\n",
      "Epoch 47/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0013 - mae: 0.0252 - val_loss: 6.4831e-04 - val_mae: 0.0200\n",
      "Epoch 48/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0248 - val_loss: 7.1834e-04 - val_mae: 0.0209\n",
      "Epoch 49/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0013 - mae: 0.0254 - val_loss: 7.8118e-04 - val_mae: 0.0225\n",
      "Epoch 50/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0247 - val_loss: 7.6753e-04 - val_mae: 0.0221\n",
      "Epoch 51/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0246 - val_loss: 5.7934e-04 - val_mae: 0.0187\n",
      "Epoch 52/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 9.6332e-04 - val_mae: 0.0254\n",
      "Epoch 53/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0244 - val_loss: 5.8119e-04 - val_mae: 0.0188\n",
      "Epoch 54/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0238 - val_loss: 6.8659e-04 - val_mae: 0.0208\n",
      "Epoch 55/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0236 - val_loss: 6.8256e-04 - val_mae: 0.0201\n",
      "Epoch 56/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0012 - mae: 0.0242 - val_loss: 6.3702e-04 - val_mae: 0.0195\n",
      "Epoch 57/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 6.0570e-04 - val_mae: 0.0191\n",
      "Epoch 58/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0232 - val_loss: 5.9646e-04 - val_mae: 0.0191\n",
      "Epoch 59/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0237 - val_loss: 7.3531e-04 - val_mae: 0.0205\n",
      "Epoch 60/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0239 - val_loss: 5.4060e-04 - val_mae: 0.0181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 6.0682e-04 - val_mae: 0.0190\n",
      "Epoch 62/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0240 - val_loss: 6.6558e-04 - val_mae: 0.0205\n",
      "Epoch 63/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 5.4215e-04 - val_mae: 0.0179\n",
      "Epoch 64/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0234 - val_loss: 5.4641e-04 - val_mae: 0.0179\n",
      "Epoch 65/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 5.8700e-04 - val_mae: 0.0187\n",
      "Epoch 66/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0011 - mae: 0.0235 - val_loss: 6.2075e-04 - val_mae: 0.0194\n",
      "Epoch 67/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0233 - val_loss: 5.1451e-04 - val_mae: 0.0176\n",
      "Epoch 68/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0227 - val_loss: 5.4161e-04 - val_mae: 0.0180\n",
      "Epoch 69/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 5.3618e-04 - val_mae: 0.0177\n",
      "Epoch 70/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 6.2052e-04 - val_mae: 0.0199\n",
      "Epoch 71/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0226 - val_loss: 5.4897e-04 - val_mae: 0.0180\n",
      "Epoch 72/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0221 - val_loss: 5.0850e-04 - val_mae: 0.0173\n",
      "Epoch 73/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0010 - mae: 0.0225 - val_loss: 6.6195e-04 - val_mae: 0.0200\n",
      "Epoch 74/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.9256e-04 - mae: 0.0220 - val_loss: 5.5755e-04 - val_mae: 0.0183\n",
      "Epoch 75/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 0.0011 - mae: 0.0230 - val_loss: 5.7854e-04 - val_mae: 0.0185\n",
      "Epoch 76/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 0.0010 - mae: 0.0224 - val_loss: 5.4998e-04 - val_mae: 0.0182\n",
      "Epoch 77/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.9628e-04 - mae: 0.0221 - val_loss: 6.3110e-04 - val_mae: 0.0197\n",
      "Epoch 78/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.6235e-04 - mae: 0.0217 - val_loss: 6.6699e-04 - val_mae: 0.0202\n",
      "Epoch 79/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.7348e-04 - mae: 0.0220 - val_loss: 5.2592e-04 - val_mae: 0.0175\n",
      "Epoch 80/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.7526e-04 - mae: 0.0219 - val_loss: 5.3013e-04 - val_mae: 0.0179\n",
      "Epoch 81/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.5649e-04 - mae: 0.0217 - val_loss: 6.1705e-04 - val_mae: 0.0191\n",
      "Epoch 82/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.7320e-04 - mae: 0.0220 - val_loss: 6.4494e-04 - val_mae: 0.0197\n",
      "Epoch 83/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.7273e-04 - mae: 0.0218 - val_loss: 6.1947e-04 - val_mae: 0.0190\n",
      "Epoch 84/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.8627e-04 - mae: 0.0221 - val_loss: 5.8095e-04 - val_mae: 0.0186\n",
      "Epoch 85/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.3627e-04 - mae: 0.0213 - val_loss: 5.5899e-04 - val_mae: 0.0180\n",
      "Epoch 86/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.1458e-04 - mae: 0.0212 - val_loss: 5.8958e-04 - val_mae: 0.0183\n",
      "Epoch 87/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.3597e-04 - mae: 0.0214 - val_loss: 0.0010 - val_mae: 0.0258\n",
      "Epoch 88/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.2443e-04 - mae: 0.0212 - val_loss: 5.1817e-04 - val_mae: 0.0177\n",
      "Epoch 89/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.1209e-04 - mae: 0.0211 - val_loss: 6.2612e-04 - val_mae: 0.0200\n",
      "Epoch 90/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.5526e-04 - mae: 0.0218 - val_loss: 5.0447e-04 - val_mae: 0.0173\n",
      "Epoch 91/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.9503e-04 - mae: 0.0209 - val_loss: 5.8863e-04 - val_mae: 0.0188\n",
      "Epoch 92/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.1106e-04 - mae: 0.0212 - val_loss: 6.0325e-04 - val_mae: 0.0187\n",
      "Epoch 93/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.3538e-04 - mae: 0.0215 - val_loss: 5.5270e-04 - val_mae: 0.0178\n",
      "Epoch 94/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.8677e-04 - mae: 0.0208 - val_loss: 5.8415e-04 - val_mae: 0.0182\n",
      "Epoch 95/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.6086e-04 - mae: 0.0204 - val_loss: 5.0780e-04 - val_mae: 0.0172\n",
      "Epoch 96/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 9.0143e-04 - mae: 0.0210 - val_loss: 5.1390e-04 - val_mae: 0.0175\n",
      "Epoch 97/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.7240e-04 - mae: 0.0206 - val_loss: 4.9986e-04 - val_mae: 0.0173\n",
      "Epoch 98/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 9.0260e-04 - mae: 0.0211 - val_loss: 6.3811e-04 - val_mae: 0.0203\n",
      "Epoch 99/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.9157e-04 - mae: 0.0210 - val_loss: 0.0010 - val_mae: 0.0268\n",
      "Epoch 100/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.7198e-04 - mae: 0.0206 - val_loss: 6.2673e-04 - val_mae: 0.0199\n",
      "Epoch 101/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.9230e-04 - mae: 0.0210 - val_loss: 4.9828e-04 - val_mae: 0.0168\n",
      "Epoch 102/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.6452e-04 - mae: 0.0206 - val_loss: 5.0381e-04 - val_mae: 0.0171\n",
      "Epoch 103/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.5926e-04 - mae: 0.0205 - val_loss: 5.7103e-04 - val_mae: 0.0185\n",
      "Epoch 104/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.6510e-04 - mae: 0.0205 - val_loss: 6.4422e-04 - val_mae: 0.0201\n",
      "Epoch 105/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.5818e-04 - mae: 0.0206 - val_loss: 5.7003e-04 - val_mae: 0.0187\n",
      "Epoch 106/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.5379e-04 - mae: 0.0204 - val_loss: 6.4237e-04 - val_mae: 0.0199\n",
      "Epoch 107/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.5289e-04 - mae: 0.0205 - val_loss: 6.6454e-04 - val_mae: 0.0208\n",
      "Epoch 108/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.3359e-04 - mae: 0.0202 - val_loss: 5.8109e-04 - val_mae: 0.0189\n",
      "Epoch 109/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.1186e-04 - mae: 0.0200 - val_loss: 5.1015e-04 - val_mae: 0.0171\n",
      "Epoch 110/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.3913e-04 - mae: 0.0203 - val_loss: 5.3273e-04 - val_mae: 0.0180\n",
      "Epoch 111/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 8.1408e-04 - mae: 0.0200 - val_loss: 5.6498e-04 - val_mae: 0.0180\n",
      "Epoch 112/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.8467e-04 - mae: 0.0195 - val_loss: 8.3862e-04 - val_mae: 0.0239\n",
      "Epoch 113/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.9779e-04 - mae: 0.0198 - val_loss: 5.3643e-04 - val_mae: 0.0178\n",
      "Epoch 114/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.8772e-04 - mae: 0.0196 - val_loss: 4.7817e-04 - val_mae: 0.0167\n",
      "Epoch 115/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.9547e-04 - mae: 0.0198 - val_loss: 4.8357e-04 - val_mae: 0.0165\n",
      "Epoch 116/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.7748e-04 - mae: 0.0196 - val_loss: 5.6294e-04 - val_mae: 0.0176\n",
      "Epoch 117/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.6799e-04 - mae: 0.0194 - val_loss: 6.1154e-04 - val_mae: 0.0193\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 3s 13ms/step - loss: 7.7684e-04 - mae: 0.0196 - val_loss: 5.0594e-04 - val_mae: 0.0172\n",
      "Epoch 119/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.6841e-04 - mae: 0.0195 - val_loss: 5.5537e-04 - val_mae: 0.0186\n",
      "Epoch 120/200\n",
      "245/245 [==============================] - 4s 15ms/step - loss: 7.5459e-04 - mae: 0.0192 - val_loss: 5.6982e-04 - val_mae: 0.0187\n",
      "Epoch 121/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.5413e-04 - mae: 0.0193 - val_loss: 4.8179e-04 - val_mae: 0.0166\n",
      "Epoch 122/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.5010e-04 - mae: 0.0193 - val_loss: 5.6137e-04 - val_mae: 0.0181\n",
      "Epoch 123/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.5387e-04 - mae: 0.0194 - val_loss: 5.3752e-04 - val_mae: 0.0174\n",
      "Epoch 124/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.2673e-04 - mae: 0.0190 - val_loss: 6.6394e-04 - val_mae: 0.0204\n",
      "Epoch 125/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 7.5062e-04 - mae: 0.0192 - val_loss: 5.5458e-04 - val_mae: 0.0173\n",
      "Epoch 126/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.9658e-04 - mae: 0.0199 - val_loss: 5.8408e-04 - val_mae: 0.0181\n",
      "Epoch 127/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.3274e-04 - mae: 0.0192 - val_loss: 5.4444e-04 - val_mae: 0.0175\n",
      "Epoch 128/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9788e-04 - mae: 0.0187 - val_loss: 6.4483e-04 - val_mae: 0.0201\n",
      "Epoch 129/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9815e-04 - mae: 0.0187 - val_loss: 5.2437e-04 - val_mae: 0.0174\n",
      "Epoch 130/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9291e-04 - mae: 0.0185 - val_loss: 4.7993e-04 - val_mae: 0.0165\n",
      "Epoch 131/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.7910e-04 - mae: 0.0184 - val_loss: 6.0440e-04 - val_mae: 0.0183\n",
      "Epoch 132/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9118e-04 - mae: 0.0186 - val_loss: 5.6753e-04 - val_mae: 0.0186\n",
      "Epoch 133/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9516e-04 - mae: 0.0187 - val_loss: 6.5983e-04 - val_mae: 0.0195\n",
      "Epoch 134/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.7538e-04 - mae: 0.0185 - val_loss: 5.3332e-04 - val_mae: 0.0178\n",
      "Epoch 135/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.5024e-04 - mae: 0.0182 - val_loss: 6.5335e-04 - val_mae: 0.0196\n",
      "Epoch 136/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 7.0102e-04 - mae: 0.0190 - val_loss: 6.7678e-04 - val_mae: 0.0204\n",
      "Epoch 137/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.6038e-04 - mae: 0.0183 - val_loss: 5.3021e-04 - val_mae: 0.0176\n",
      "Epoch 138/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.2737e-04 - mae: 0.0179 - val_loss: 6.0968e-04 - val_mae: 0.0191\n",
      "Epoch 139/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.3460e-04 - mae: 0.0179 - val_loss: 5.6948e-04 - val_mae: 0.0184\n",
      "Epoch 140/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.5798e-04 - mae: 0.0182 - val_loss: 5.7041e-04 - val_mae: 0.0184\n",
      "Epoch 141/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.1304e-04 - mae: 0.0177 - val_loss: 5.6179e-04 - val_mae: 0.0181\n",
      "Epoch 142/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.9400e-04 - mae: 0.0185 - val_loss: 5.1105e-04 - val_mae: 0.0172\n",
      "Epoch 143/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.5612e-04 - mae: 0.0183 - val_loss: 5.4688e-04 - val_mae: 0.0182\n",
      "Epoch 144/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.0295e-04 - mae: 0.0176 - val_loss: 5.2790e-04 - val_mae: 0.0172\n",
      "Epoch 145/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.2327e-04 - mae: 0.0180 - val_loss: 5.3741e-04 - val_mae: 0.0176\n",
      "Epoch 146/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.9962e-04 - mae: 0.0177 - val_loss: 5.1439e-04 - val_mae: 0.0172\n",
      "Epoch 147/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.0784e-04 - mae: 0.0175 - val_loss: 5.6762e-04 - val_mae: 0.0181\n",
      "Epoch 148/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.5589e-04 - mae: 0.0170 - val_loss: 6.9482e-04 - val_mae: 0.0202\n",
      "Epoch 149/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 6.0396e-04 - mae: 0.0178 - val_loss: 6.2258e-04 - val_mae: 0.0196\n",
      "Epoch 150/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.6859e-04 - mae: 0.0172 - val_loss: 7.5499e-04 - val_mae: 0.0221\n",
      "Epoch 151/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.7479e-04 - mae: 0.0172 - val_loss: 5.7391e-04 - val_mae: 0.0180\n",
      "Epoch 152/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.5769e-04 - mae: 0.0169 - val_loss: 6.8147e-04 - val_mae: 0.0194\n",
      "Epoch 153/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.3158e-04 - mae: 0.0167 - val_loss: 5.3851e-04 - val_mae: 0.0177\n",
      "Epoch 154/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.3836e-04 - mae: 0.0168 - val_loss: 5.8685e-04 - val_mae: 0.0178\n",
      "Epoch 155/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.3455e-04 - mae: 0.0168 - val_loss: 5.2663e-04 - val_mae: 0.0176\n",
      "Epoch 156/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.4214e-04 - mae: 0.0168 - val_loss: 5.2558e-04 - val_mae: 0.0171\n",
      "Epoch 157/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.3203e-04 - mae: 0.0167 - val_loss: 5.5150e-04 - val_mae: 0.0177\n",
      "Epoch 158/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.4079e-04 - mae: 0.0170 - val_loss: 5.3951e-04 - val_mae: 0.0177\n",
      "Epoch 159/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.9108e-04 - mae: 0.0161 - val_loss: 5.5300e-04 - val_mae: 0.0182\n",
      "Epoch 160/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.0994e-04 - mae: 0.0164 - val_loss: 6.6365e-04 - val_mae: 0.0199\n",
      "Epoch 161/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.9650e-04 - mae: 0.0163 - val_loss: 6.0585e-04 - val_mae: 0.0183\n",
      "Epoch 162/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.0065e-04 - mae: 0.0162 - val_loss: 5.3272e-04 - val_mae: 0.0174\n",
      "Epoch 163/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.8183e-04 - mae: 0.0160 - val_loss: 8.2841e-04 - val_mae: 0.0238\n",
      "Epoch 164/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.9766e-04 - mae: 0.0163 - val_loss: 6.0225e-04 - val_mae: 0.0188\n",
      "Epoch 165/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.6955e-04 - mae: 0.0158 - val_loss: 7.3268e-04 - val_mae: 0.0221\n",
      "Epoch 166/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.7596e-04 - mae: 0.0171 - val_loss: 5.8456e-04 - val_mae: 0.0190\n",
      "Epoch 167/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.5594e-04 - mae: 0.0157 - val_loss: 5.7308e-04 - val_mae: 0.0180\n",
      "Epoch 168/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.4508e-04 - mae: 0.0155 - val_loss: 5.6345e-04 - val_mae: 0.0180\n",
      "Epoch 169/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.5389e-04 - mae: 0.0156 - val_loss: 5.6275e-04 - val_mae: 0.0181\n",
      "Epoch 170/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.3441e-04 - mae: 0.0153 - val_loss: 6.0390e-04 - val_mae: 0.0190\n",
      "Epoch 171/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.6224e-04 - mae: 0.0157 - val_loss: 5.9541e-04 - val_mae: 0.0187\n",
      "Epoch 172/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.1503e-04 - mae: 0.0151 - val_loss: 5.8869e-04 - val_mae: 0.0189\n",
      "Epoch 173/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.1377e-04 - mae: 0.0150 - val_loss: 5.6635e-04 - val_mae: 0.0182\n",
      "Epoch 174/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 4.2614e-04 - mae: 0.0152 - val_loss: 7.4467e-04 - val_mae: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.3371e-04 - mae: 0.0153 - val_loss: 5.7832e-04 - val_mae: 0.0186\n",
      "Epoch 176/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 4.0369e-04 - mae: 0.0149 - val_loss: 6.4544e-04 - val_mae: 0.0191\n",
      "Epoch 177/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.9991e-04 - mae: 0.0148 - val_loss: 5.8908e-04 - val_mae: 0.0181\n",
      "Epoch 178/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.9669e-04 - mae: 0.0147 - val_loss: 6.0617e-04 - val_mae: 0.0184\n",
      "Epoch 179/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.7622e-04 - mae: 0.0168 - val_loss: 7.4963e-04 - val_mae: 0.0212\n",
      "Epoch 180/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 5.5666e-04 - mae: 0.0167 - val_loss: 6.2749e-04 - val_mae: 0.0190\n",
      "Epoch 181/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.7827e-04 - mae: 0.0144 - val_loss: 7.4978e-04 - val_mae: 0.0214\n",
      "Epoch 182/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.5722e-04 - mae: 0.0140 - val_loss: 5.7066e-04 - val_mae: 0.0183\n",
      "Epoch 183/200\n",
      "245/245 [==============================] - 3s 13ms/step - loss: 3.5728e-04 - mae: 0.0140 - val_loss: 8.4657e-04 - val_mae: 0.0232\n",
      "Epoch 184/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.6858e-04 - mae: 0.0142 - val_loss: 6.1736e-04 - val_mae: 0.0190\n",
      "Epoch 185/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.6377e-04 - mae: 0.0141 - val_loss: 6.1351e-04 - val_mae: 0.0191\n",
      "Epoch 186/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.9496e-04 - mae: 0.0146 - val_loss: 5.7416e-04 - val_mae: 0.0180\n",
      "Epoch 187/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.5939e-04 - mae: 0.0141 - val_loss: 6.3916e-04 - val_mae: 0.0194\n",
      "Epoch 188/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.5336e-04 - mae: 0.0139 - val_loss: 6.1205e-04 - val_mae: 0.0189\n",
      "Epoch 189/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.5283e-04 - mae: 0.0140 - val_loss: 5.8144e-04 - val_mae: 0.0184\n",
      "Epoch 190/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.3967e-04 - mae: 0.0137 - val_loss: 6.6175e-04 - val_mae: 0.0199\n",
      "Epoch 191/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.3310e-04 - mae: 0.0136 - val_loss: 6.8280e-04 - val_mae: 0.0206\n",
      "Epoch 192/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.2577e-04 - mae: 0.0135 - val_loss: 7.4787e-04 - val_mae: 0.0213\n",
      "Epoch 193/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.3586e-04 - mae: 0.0137 - val_loss: 6.9058e-04 - val_mae: 0.0205\n",
      "Epoch 194/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.1785e-04 - mae: 0.0133 - val_loss: 6.9103e-04 - val_mae: 0.0204\n",
      "Epoch 195/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.2869e-04 - mae: 0.0136 - val_loss: 6.9552e-04 - val_mae: 0.0201\n",
      "Epoch 196/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.2738e-04 - mae: 0.0135 - val_loss: 6.2880e-04 - val_mae: 0.0192\n",
      "Epoch 197/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.7504e-04 - mae: 0.0142 - val_loss: 7.8159e-04 - val_mae: 0.0222\n",
      "Epoch 198/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 3.0315e-04 - mae: 0.0130 - val_loss: 8.6230e-04 - val_mae: 0.0235\n",
      "Epoch 199/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 2.9526e-04 - mae: 0.0129 - val_loss: 6.8042e-04 - val_mae: 0.0202\n",
      "Epoch 200/200\n",
      "245/245 [==============================] - 3s 14ms/step - loss: 2.9423e-04 - mae: 0.0129 - val_loss: 6.6157e-04 - val_mae: 0.0198\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvHElEQVR4nO3deXwV5dn/8c+VBIKyE0CRIIssyqIsEay4oVVxqYhChdoq1bpV9NH+Wksf6/Lz0Z+1j0/rY6u1Wq3WqmhtVawoikutG7IIAgoaECWgCEEDkQSyXL8/7gmck5yQE0hyAuf7fr3OK3Nm7plzz5yTuea6Z+Yec3dERCT9ZKS6AiIikhoKACIiaUoBQEQkTSkAiIikKQUAEZE0lZXqCtRH586dvVevXqmuhojIHmX+/Pkb3L1L9fF7VADo1asX8+bNS3U1RET2KGb2aaLxagISEUlTCgAiImlKAUBEJE3tUecARKRplJWVUVBQQGlpaaqrIvXQqlUrcnNzadGiRVLlFQBEpIaCggLatm1Lr169MLNUV0eS4O4UFhZSUFBA7969k5onqSYgMxtrZsvNLN/MpiWYnm1mj0fT55hZr2j8SDNbGL0Wmdn4mHlWmdniaJou7RFpRkpLS8nJydHOfw9iZuTk5NQra6szAzCzTOAu4ESgAJhrZjPc/YOYYhcCX7l7XzObBNwGnAMsAfLcvdzMugGLzOxZdy+P5hvj7huSrq2INBnt/Pc89f3OkskARgL57r7S3bcB04Fx1cqMAx6Khp8ETjAzc/ctMTv7VkBq+p7+3e9g+vSUfLSISHOVTADoDqyOeV8QjUtYJtrhFwE5AGY2ysyWAouBS2MCggMvmtl8M7u4tg83s4vNbJ6ZzVu/fn0y61TTPffA3/++a/OKSJMrLCxk6NChDB06lP3335/u3btvf79t27adzjtv3jyuvPLKOj/jyCOPbJC6vvbaa5x++ukNsqym1ugngd19DjDIzA4BHjKz5929FDjK3deYWVfgJTNb5u6vJ5j/XuBegLy8vF3LIDIyoKJi11dCRJpUTk4OCxcuBODGG2+kTZs2/PSnP90+vby8nKysxLuvvLw88vLy6vyMt956q0HquidLJgNYA/SIeZ8bjUtYxsyygPZAYWwBd/8QKAYGR+/XRH+/BJ4iNDU1jsxMqKxstMWLSOObMmUKl156KaNGjeKaa67h3Xff5Vvf+hbDhg3jyCOPZPny5UD8EfmNN97IBRdcwHHHHUefPn248847ty+vTZs228sfd9xxTJgwgYMPPphzzz2Xqiclzpw5k4MPPpgRI0Zw5ZVX1utI/7HHHmPIkCEMHjyYn//85wBUVFQwZcoUBg8ezJAhQ/jtb38LwJ133snAgQM59NBDmTRp0u5vrCQlkwHMBfqZWW/Cjn4S8L1qZWYA5wNvAxOAV9zdo3lWRyeBewIHA6vMrDWQ4e6bo+GTgJsaZpUSUAYgsuuuugqio/EGM3Qo3HFHvWcrKCjgrbfeIjMzk02bNvHvf/+brKwsZs+ezX/+53/y9wRNvcuWLePVV19l8+bNDBgwgMsuu6zGdfLvvfceS5cu5YADDmD06NG8+eab5OXlcckll/D666/Tu3dvJk+enHQ9165dy89//nPmz59Px44dOemkk3j66afp0aMHa9asYcmSJQB8/fXXAPzqV7/ik08+ITs7e/u4plBnBhC12U8FZgEfAk+4+1Izu8nMzoiK3Q/kmFk+8BOg6lLRowhX/iwkHOX/OLrqZz/gDTNbBLwLPOfuLzTgesVTBiCyV5g4cSKZmZkAFBUVMXHiRAYPHszVV1/N0qVLE85z2mmnkZ2dTefOnenatSvr1q2rUWbkyJHk5uaSkZHB0KFDWbVqFcuWLaNPnz7br6mvTwCYO3cuxx13HF26dCErK4tzzz2X119/nT59+rBy5UquuOIKXnjhBdq1awfAoYceyrnnnstf//rXWpu2GkNSn+TuM4GZ1cZdHzNcCkxMMN/DwMMJxq8EDqtvZXeZMgCRXbcLR+qNpXXr1tuHr7vuOsaMGcNTTz3FqlWrOO644xLOk52dvX04MzOT8vLyXSrTEDp27MiiRYuYNWsW99xzD0888QQPPPAAzz33HK+//jrPPvsst9xyC4sXL26SQJAefQEpAxDZ6xQVFdG9e7gg8cEHH2zw5Q8YMICVK1eyatUqAB5//PGk5x05ciT/+te/2LBhAxUVFTz22GMce+yxbNiwgcrKSs4++2xuvvlmFixYQGVlJatXr2bMmDHcdtttFBUVUVxc3ODrk0h6dAWhDEBkr3PNNddw/vnnc/PNN3Paaac1+PL32Wcf7r77bsaOHUvr1q05/PDDay378ssvk5ubu/393/72N371q18xZswY3J3TTjuNcePGsWjRIn74wx9SGR2Q3nrrrVRUVPD973+foqIi3J0rr7ySDh06NPj6JGJVZ7v3BHl5eb5LD4Q59lgwg9dea/A6ieyNPvzwQw455JBUVyPliouLadOmDe7O5ZdfTr9+/bj66qtTXa2dSvTdmdl8d69xbayagEREanHfffcxdOhQBg0aRFFREZdcckmqq9Sg1AQkIlKLq6++utkf8e8OZQAiImkqPQKAMgARkRrSIwAoAxARqSE9AoAyABGRGtIjACgDENmjjBkzhlmzZsWNu+OOO7jssstqnee4446j6jLxU089NWGfOjfeeCO33377Tj/76aef5oMPdjzv6vrrr2f27Nn1qH1izbHb6PQIAMoARPYokydPZnq1hzhNnz496f54Zs6cucs3U1UPADfddBPf/va3d2lZzV16BABlACJ7lAkTJvDcc89tf/jLqlWrWLt2LUcffTSXXXYZeXl5DBo0iBtuuCHh/L169WLDhvC02VtuuYX+/ftz1FFHbe8yGsI1/ocffjiHHXYYZ599Nlu2bOGtt95ixowZ/OxnP2Po0KGsWLGCKVOm8OSTTwLhjt9hw4YxZMgQLrjgArZu3br982644QaGDx/OkCFDWLZsWdLrmspuo3UfgIjsVCp6g+7UqRMjR47k+eefZ9y4cUyfPp3vfve7mBm33HILnTp1oqKighNOOIH333+fQw89NOFy5s+fz/Tp01m4cCHl5eUMHz6cESNGAHDWWWdx0UUXAfDLX/6S+++/nyuuuIIzzjiD008/nQkTJsQtq7S0lClTpvDyyy/Tv39/zjvvPP7whz9w1VVXAdC5c2cWLFjA3Xffze23386f/vSnOrdDqruNVgYgIs1SbDNQbPPPE088wfDhwxk2bBhLly6Na66p7t///jfjx49n3333pV27dpxxxhnbpy1ZsoSjjz6aIUOG8Mgjj9TanXSV5cuX07t3b/r37w/A+eefz+uv73iI4VlnnQXAiBEjtncgV5dUdxutDEBEdipVvUGPGzeOq6++mgULFrBlyxZGjBjBJ598wu23387cuXPp2LEjU6ZMobS0dJeWP2XKFJ5++mkOO+wwHnzwQV7bzb7CqrqUbojupJuq22hlACLSLLVp04YxY8ZwwQUXbD/637RpE61bt6Z9+/asW7eO559/fqfLOOaYY3j66acpKSlh8+bNPPvss9unbd68mW7dulFWVsYjjzyyfXzbtm3ZvHlzjWUNGDCAVatWkZ+fD8DDDz/Mscceu1vrmOpuo5UBiEizNXnyZMaPH7+9Keiwww5j2LBhHHzwwfTo0YPRo0fvdP7hw4dzzjnncNhhh9G1a9e4Lp3/67/+i1GjRtGlSxdGjRq1fac/adIkLrroIu68887tJ38BWrVqxZ///GcmTpxIeXk5hx9+OJdeemm91qe5dRudHt1BX3QRzJwJa6o/y15EElF30HsudQddnTIAEZEakgoAZjbWzJabWb6ZTUswPdvMHo+mzzGzXtH4kWa2MHotMrPxyS6zQekcgIhIDXUGADPLBO4CTgEGApPNbGC1YhcCX7l7X+C3wG3R+CVAnrsPBcYCfzSzrCSX2XCUAYjU257UPCxBfb+zZDKAkUC+u690923AdGBctTLjgIei4SeBE8zM3H2Lu1ddD9UKqKpdMstsOJmZCgAi9dCqVSsKCwsVBPYg7k5hYSGtWrVKep5krgLqDqyOeV8AjKqtjLuXm1kRkANsMLNRwANAT+AH0fRklgmAmV0MXAxw4IEHJlHdBNQEJFIvubm5FBQUsH79+lRXReqhVatWcVcZ1aXRLwN19znAIDM7BHjIzHZ+4W7N+e8F7oVwFdAuVUJNQCL10qJFC3r37p3qakgjS6YJaA3QI+Z9bjQuYRkzywLaA4WxBdz9Q6AYGJzkMhuOMgARkRqSCQBzgX5m1tvMWgKTgBnVyswAzo+GJwCvuLtH82QBmFlP4GBgVZLLbDjKAEREaqizCShqs58KzAIygQfcfamZ3QTMc/cZwP3Aw2aWD2wk7NABjgKmmVkZUAn82N03ACRaZgOv2w7KAEREakjqHIC7zwRmVht3fcxwKTAxwXwPAw8nu8xGowxARKSG9LgTODMz/NUlbSIi26VHAMiIVlNZgIjIdukRAKoyAJ0HEBHZLj0CgDIAEZEa0iMAKAMQEakhPQKAMgARkRrSIwAoAxARqSE9AoAyABGRGtIjACgDEBGpIT0CgDIAEZEa0iMAKAMQEakhvQKAMgARke3SIwBUNQEpAxAR2S49AoAyABGRGtIjAOgksIhIDekRAHQSWESkhvQIAMoARERqSI8AoAxARKSG9AgAygBERGpIjwCgDEBEpIakAoCZjTWz5WaWb2bTEkzPNrPHo+lzzKxXNP5EM5tvZoujv8fHzPNatMyF0atrg61VdcoARERqyKqrgJllAncBJwIFwFwzm+HuH8QUuxD4yt37mtkk4DbgHGAD8B13X2tmg4FZQPeY+c5193kNtC61UwYgIlJDMhnASCDf3Ve6+zZgOjCuWplxwEPR8JPACWZm7v6eu6+Nxi8F9jGz7IaoeL0oAxARqSGZANAdWB3zvoD4o/i4Mu5eDhQBOdXKnA0scPetMeP+HDX/XGdmlujDzexiM5tnZvPWr1+fRHUTUAYgIlJDk5wENrNBhGahS2JGn+vuQ4Cjo9cPEs3r7ve6e56753Xp0mXXKqAMQESkhmQCwBqgR8z73GhcwjJmlgW0Bwqj97nAU8B57r6iagZ3XxP93Qw8SmhqahzKAEREakgmAMwF+plZbzNrCUwCZlQrMwM4PxqeALzi7m5mHYDngGnu/mZVYTPLMrPO0XAL4HRgyW6tyc4oAxARqaHOABC16U8lXMHzIfCEuy81s5vM7Iyo2P1AjpnlAz8Bqi4VnQr0Ba6vdrlnNjDLzN4HFhIyiPsacL3iKQMQEamhzstAAdx9JjCz2rjrY4ZLgYkJ5rsZuLmWxY5Ivpq7Sd1Bi4jUkB53AuuBMCIiNaRHAFAGICJSQ3oEAGUAIiI1pEcAUAYgIlJDegQAXQYqIlJDegQAXQYqIlJDegQAZQAiIjWkRwBQBiAiUkN6BABlACIiNaRHAFAGICJSQ3oEAGUAIiI1pEcAUAYgIlJDegQAZQAiIjWkRwBQBiAiUkN6BABlACIiNaRHAFAGICJSQ3oEAGUAIiI1pEcAUAYgIlJDegUAZQAiItslFQDMbKyZLTezfDOblmB6tpk9Hk2fY2a9ovEnmtl8M1sc/T0+Zp4R0fh8M7vTzKzB1qo6PRBGRKSGOgOAmWUCdwGnAAOByWY2sFqxC4Gv3L0v8Fvgtmj8BuA77j4EOB94OGaePwAXAf2i19jdWI+dUwYgIlJDMhnASCDf3Ve6+zZgOjCuWplxwEPR8JPACWZm7v6eu6+Nxi8F9omyhW5AO3d/x90d+Atw5u6uTK2UAYiI1JBMAOgOrI55XxCNS1jG3cuBIiCnWpmzgQXuvjUqX1DHMgEws4vNbJ6ZzVu/fn0S1U24kPBSBiAisl2TnAQ2s0GEZqFL6juvu9/r7nnuntelS5ddr0RGhjIAEZEYyQSANUCPmPe50biEZcwsC2gPFEbvc4GngPPcfUVM+dw6ltmwMjOVAYiIxEgmAMwF+plZbzNrCUwCZlQrM4NwkhdgAvCKu7uZdQCeA6a5+5tVhd39c2CTmR0RXf1zHvDM7q1KHTIyFABERGLUGQCiNv2pwCzgQ+AJd19qZjeZ2RlRsfuBHDPLB34CVF0qOhXoC1xvZgujV9do2o+BPwH5wArg+YZaqYQyM9UEJCISIyuZQu4+E5hZbdz1McOlwMQE890M3FzLMucBg+tT2d2iDEBEJE563AkMygBERKpJnwCgDEBEJE76BABlACIicdInACgDEBGJkz4BQBmAiEic9AkAygBEROKkTwBQBiAiEie9AoAyABGR7dInAKgzOBGROOkTAJQBiIjESZ8AoAxARCRO+gQAZQAiInHSJwAoAxARiZM+AUAZgIhInPQJAMoARETipE8AUAYgIhInfQKAuoIQEYmTPgFAXUGIiMRJnwCgDEBEJE76BABlACIicZIKAGY21syWm1m+mU1LMD3bzB6Pps8xs17R+Bwze9XMis3s99XmeS1a5sLo1bVB1qg2ygBEROJk1VXAzDKBu4ATgQJgrpnNcPcPYopdCHzl7n3NbBJwG3AOUApcBwyOXtWd6+7zdnMdkqMMQEQkTjIZwEgg391Xuvs2YDowrlqZccBD0fCTwAlmZu7+jbu/QQgEqaUMQEQkTjIBoDuwOuZ9QTQuYRl3LweKgJwklv3nqPnnOjOzRAXM7GIzm2dm89avX5/EImuhDEBEJE4qTwKf6+5DgKOj1w8SFXL3e909z93zunTpsuufphvBRETiJBMA1gA9Yt7nRuMSljGzLKA9ULizhbr7mujvZuBRQlNT41FXECIicZIJAHOBfmbW28xaApOAGdXKzADOj4YnAK+4u9e2QDPLMrPO0XAL4HRgSX0rXy/KAERE4tR5FZC7l5vZVGAWkAk84O5LzewmYJ67zwDuBx42s3xgIyFIAGBmq4B2QEszOxM4CfgUmBXt/DOB2cB9DbliNSgDEBGJU2cAAHD3mcDMauOujxkuBSbWMm+vWhY7IrkqNhBlACIicdLnTmBlACIicdInACgDEBGJkz4BQBmAiEic9AkAygBEROKkTwBQBiAiEid9AoAyABGROOkTAJQBiIjESZ8AoAxARCRO+gQAdQctIhInfQKAuoMWEYmTPgFAGYCISJz0CQDKAERE4qRPAFAGICISJ30CgDIAEZE46RUAlAGIiGyXPgEgIwPcw0tERNIoAGRmhr9qBhIRAdIpAGREq6oAICICpFMAqMoAdB5ARARIMgCY2VgzW25m+WY2LcH0bDN7PJo+x8x6ReNzzOxVMys2s99Xm2eEmS2O5rnTzKxB1qg2ygBEROLUGQDMLBO4CzgFGAhMNrOB1YpdCHzl7n2B3wK3ReNLgeuAnyZY9B+Ai4B+0WvsrqxA0pQBiIjESSYDGAnku/tKd98GTAfGVSszDngoGn4SOMHMzN2/cfc3CIFgOzPrBrRz93fc3YG/AGfuxnrUTRmAiEicZAJAd2B1zPuCaFzCMu5eDhQBOXUss6COZQJgZheb2Twzm7d+/fokqlsLZQAiInGa/Ulgd7/X3fPcPa9Lly67viBlACIicZIJAGuAHjHvc6NxCcuYWRbQHiisY5m5dSyzYSkDEBGJk0wAmAv0M7PeZtYSmATMqFZmBnB+NDwBeCVq20/I3T8HNpnZEdHVP+cBz9S79vWhDEBEJE5WXQXcvdzMpgKzgEzgAXdfamY3AfPcfQZwP/CwmeUDGwlBAgAzWwW0A1qa2ZnASe7+AfBj4EFgH+D56NV4lAGIiMSpMwAAuPtMYGa1cdfHDJcCE2uZt1ct4+cBg5Ot6G6rygAUAEREgD3gJHCDUV9AIiJx0icAKAMQEYmTPgFAGYCISJz0CwDKAEREgHQKALoMVEQkTvoEAGUAIiJx0icAKAMQEYmTPgGgqh+h115LaTVERJqL9AkARx4JJ58M118Paxq32yERkT1B+gQAM7jrLti2DX7xi1TXRkQk5dInAAAcdBD86EfwxBPw9depro2ISEqlVwAA+MEPYOtWePLJVNdERCSl0i8AjBwJ/fvDww+nuiYiIimVfgHALGQBr78Oq1alujYiIimTfgEA4PvfD38feSS19RARSaH0DAC9esHRR4dmoNofXCYisldLzwAAoRlo+XKYNy/VNRERSYn0DQATJ0J2NvzlL6muiYhISqRvAOjQAc45B/74R3jnnVTXRkSkyaVvAAC44w7o3h2++11Yvz7VtRERaVJJBQAzG2tmy80s38ymJZiebWaPR9PnmFmvmGm/iMYvN7OTY8avMrPFZrbQzJqsIf7+++Gxx6I3HTuGG8LWr4fx46G0tKmqISKScnUGADPLBO4CTgEGApPNbGC1YhcCX7l7X+C3wG3RvAOBScAgYCxwd7S8KmPcfai75+32mtSivBxuuAHuvRc2boQrroCf/jTm4p8RI8J5gDffDCeGy8oaqyoiIs1KMhnASCDf3Ve6+zZgOjCuWplxwEPR8JPACWZm0fjp7r7V3T8B8qPlNZnMTHjjDbjmGrj1VigpgbVrYcGCmEITJ8L//E/IBsaPD4VERPZyyQSA7sDqmPcF0biEZdy9HCgCcuqY14EXzWy+mV1c24eb2cVmNs/M5q3fhXb6qk5At2yB22+HYcPCs2FmzKhW8Cc/gXvugZkzw7CIyF4ulSeBj3L34YSmpcvN7JhEhdz9XnfPc/e8LlUPdamngw+G//N/wvC118Lo0QkCAMAll+wIBC+8sEufJSKyp0gmAKwBesS8z43GJSxjZllAe6BwZ/O6e9XfL4GnaOSmof/7f+GZZ+Css+CMM2DhQvj00wQFb74ZDjkETjkF9tsPfv973S0sInulZALAXKCfmfU2s5aEk7rVj59nAOdHwxOAV9zdo/GToquEegP9gHfNrLWZtQUws9bAScCS3V+d2rVsGXb8ZnD22eHvAw8kKNiqFcyaFU4YDBkSzhpfckloQxIR2YvUGQCiNv2pwCzgQ+AJd19qZjeZ2RlRsfuBHDPLB34CTIvmXQo8AXwAvABc7u4VwH7AG2a2CHgXeM7dm6zNpXdvOPXUcA/Ytm0JCvToAdOmwYsvws9/DvfdB8OHw513wqJFTVVNEZFGZb4HNW/k5eX5vAbqu2fWLBg7Fv76Vzj33DoKv/xyyAJWrNhxBvm00xqkHiIijc3M5ie63D5t7wQ+8cTwXJjbbkvi0v8TToCPP4bVq2Ho0NCFxFFHwQEHqDM5EdljpW0AyMiAX/8aFi8Ozf11MoPcXPjnP0P3EcXF0KIFfPvboWlo1iyoqGj0eouINJS0bQKqcu654RnxCxfCoEH1nPnTT0Mq8fHH4f2hh8KVV8Ixx0DfviFoiIikmJqAavG//xt6hf71r3dh5p494cMPw63Fjz4K33wDP/pRaFs64AC4+mooKmrwOouINIS0DwCdO8MFF4QO4tau3YUFZGZCt24weTJ89BEsXRpuJDvmmBBd+vaFI4+Eyy+HgoIGr7+IyK5K+wAAcNVVodO43/9+NxeUkQEDB4Yrhh5/HObMCSeQ99knXErar18ICntQs5uI7L0UAIA+fWDChNAf3EsvNeCCDz8cpk8Pl5F+9FE4X3DVVXDEEaFPivz8BvwwEZH6UQCI/PGPoc+gM88M3UW/+24Df0CvXqEvirvvhsrKcNLh4IPDOYMNGxr4w0RE6qYAEOnYMdz4e8wx8LvfhWb7Rx5p4A8xg8sug7lzwz0FU6fCQw/BgAGhy9KEtyWLiDQOBYAY++0Hzz8PX34ZAsEPfhCa8H/zm/hm+23bGqAZf//9wyMpFy4MfQ5NnRr6qLjkEnj6adi8eTc/QERk5xQAEmjfHp57LnQhvXFj+HvDDWHa3/8e9t0nnQTr1oVxH30Ev/jFLu6zBw2CV18NHzhqVLgcafx4yMmB448PJ5N10lhEGkHa3whWF3e46KLwLOFOnUJAGDIk3PvVvn04l3vbbbBmTdhf33RT6C/uggtCx6L1tm0bvPVWSEWefjpEl8MPhx//OJypbtOmoVdRRPZytd0IpgCQhPJy+H//LzQNDRgAl14a7v/60Y9Cc37HjvAf/wE33rhjnpNPDh2JvvYafO97Yb5YhYUhoJjBO+/AYYeFq0XjVFSE5xXfemuIOG3ahB7stm6Ftm3DcwsOOSQ84Wb//Rt5K4jInkoBoBFUVsJTT4V98MCBYXjTptBN0NSpO8q1aBEeNPbLX4bnElx3XbgI6OabQ99yp58egkStJ53d4a23mPOrV7nmpRP5x0E/I6f4U/jssx0fMH58iCDZ2eFO5BNPhC5d4O23Q+UGDFDXFCJpSgGgiT3zTGguGjMmNAv9+c/hiL+0NDxbpk+f0JVQTk7oLWLr1nAV0oknJl6eezgx/cYbYXnXXQeVm4rJWPZB6NP68cfDzr+kJPFlpd27hzRjyJBwstksLLRly3An87p1IcU5/HA48MDQfrX//uHmNhHZoykApNjbb4ebgPffPzxtctSosD8uKAjngH/0oxAY/vSn0MpT3ezZITi0bx/289deGwLBCy9AXvWv9Ysv4NlnQ2Q58kgq3nufLa/Po+2yuaHtqs7+ryP77gutW4emqIEDw4Ny3MNzESoqQqbRv38IFp98Ej6vffuwgkuWhAh3zDE7ljFoUDinsXBhaM7q2TNkJp06hflatw4BLDs7ZDVVv02zcIZ98+ZmFZRKSsKqK7GS5k4BoBn6+GNYuTKcL5g/P3Qn9PHH4SD86KPDvnLgQBgxIhzxl5SEG9ZOPXXHMkaPhn//u/adUFlZaGJ6++3QG8U5Z5WFI30IM5WWhk6QOncOrzlzQgbxzTfc91RnurXYwOkHvh926OvWhZ1y796hD6SPPoJVq8K4Ll1COrN2bWgHM4N27XatM7yMjFCXoqIw3LVraO5yD8GhY8dwDqTq1apVmNamTXht3RrWq6QktMd17QqDB8P++/Pqsm5cNv0Y/jHlWQb2KYWsrB0P+hkxIpzwKSwMn92zZ7hZb7/94PPP4auvQgDatIkvPilh2H8czbjjN3PPf20I06qypqoA1rJl+NtMApbsOdzDq6F+OgoAe4CtW+Hee8OzihcvDl0HffxxOHju0SPswE86Kdyb0KZNCBxTp4aT0q1awciRYd/9z3+Gg/Djj4f//u/QQnTwwbBsWZhn8uTQcenhh4d93vvvw7/+BR98EA7Cx40L2cipp4blLlgQ6rJpU9i3tW4dU+nSUspLy3l5ThtGj4Y2LbaGs9r9+oWd4dKl4WRJZWVYqR49QtTaujXsePPz4euvww63uDicx/jmm7DD7dAhrPwXX4RMoXPnkGl8/XXIBoqLw9/S0hBwiovDKzs7VLxVq7Ch1qyBjz6ixLMZwmJW0JczeIZnODOsQ1W2UV6e9Hc1gb/xdyYAMJsTOIFXai+ckbEjGFT9jR1u2ZJlGQM555Nbubz381zc/bkwrWo9srPDq2XLHcs0C++rypnteFVNLy8PQbqiItzZOHBg+E4yM8OrRYuwfdzDNty6NXy5HTqEOm/diq/9HDugW/iM2mzcGDK4zMxaixQXh1WpqAi/z6rzZruroCCcP5s4MfwvvPtuaF7t0iX5ZZSU7PifSXSR3fvvh2R27NjwP7J2bRi+6aZwH+ejj4beXeriDuvXw5tvhov9hg8PP/fKyjA9Nzf81G+9Ff7xj/A/eMcd4X6k3Q0ECgB7mMrK8KWvXRt+dMceG/5fIfyQzMI/0xFHhIeSZWeH/18I+9jVq3cs64YbQpPRb34TXlUJAIQfYElJGM7JCT+6kpJwYJ2bG8q2bRv2s4WFoVznzqGT04MOCgf5s2eHQNWvH/zsZ+Ey2DffDPvxSy8Nj0nYvHnH/n7LlvBQtT59QsAyC+swd24ISN/6Vlj3G28Mnzlp0o6D/A4dQsbzzjvhn//UU+GKK8IyZs8O50jWrg3r1b17WIfu3aFjuwpemlnG9Kdbccbplcz4ZwbX/6SYj/KN089uRZ8eZbw0vZANxa3Yp2M2gw5rweZVG8hY/yXfzl1Gp17t8A4dsfVf8j8vDuHWJw7i+u+v5NHZXSmvgPuvXsoxfdeyYUURr36wH7OX5bLk806MPGANlRWVvLn6QD4vbkvHlt8wNncpp3Z7jwH7ruaL4jZ8uqkDVy36IV9s6wTAIz2v5butnyNzWwnFJZm8UjySeaWD2VjejolZT9HJvmJ5RV+KylvTy1cymjeZwygKyaGMFtzNjymmDd/nr2S22ZdKN/b/Jp9/cjob6cQl/JGTeJEv6cp9XIThlJPFc5xGfz7ixIxXeCjzhywpG0AlGVzJ7zio01e822I0uRlr6Vq2hqzyUjK7dqJr6WoO+ewFClseQPGBA+nQtzPl2yrJqCijw37ZrNjUhcc/PYK/fDSKfVuUsW/mVj7/pj0tMis4+7B8Zn90IAd2KeHq8Z+yYWtb9t0X8gZsZp+WFWzakkVhUSbZLRzatmW19eDPD2awZg2MHu0cfUwGv73D+PDD8Nuo+t23bV3BRcd+TNcj+pDdtiWtWoU4+cUXYfo+++xIFrOzQ+8sH30UfisnnxxaKPv0CctbsSKczwPo1GYrG4tDIDzkkNCa2rp1iLOnnRaGe/cOxxtLl4bEMzc3/HZfeikcgO2s9bVTp/A/XFYG3/lOqO+bb4a42rFjOPbZ1avAdysAmNlY4H+BTOBP7v6ratOzgb8AI4BC4Bx3XxVN+wVwIVABXOnus5JZZiLpFACSVVoaXm3bhmakli3DlUVvvx2al/Ly4i9BLS0N49u2DbcavP9+CCLHHht+8Fu2wDXXhD7sZs8OLS/f+1444jnqqBAcVq0KO/xPPgk79l694LzzwpVNa9aEf4Qjjgg/5jfeiK9vTk74WxVMYu23346b66rK9ugR/iFjtWkTmshycuDJJ8M6VRk0KNRny5ZQl4KCMFzliivCEVbfvuEfrH37Ha1UZuH9li1198oxaRI8/HAIWmedFZYVq0OHUJcFC8JyjzoqtChVnfOJrTOEncVzz4Wj2DlzwjZs2zZsp7KyEBBbtYpflypmjvuONsCeB1bSsb2zcHH8EXmHNmW0abmNgo2tMXMM334tAMDR/daxaHVHvi5pRf/2XzC27wo+pxt/m98HgPaZxRRV1H8P1IoSpvAgZbTgy8wDuKDiXh5jMjM4g1OZyQKGs4reSS2rDysYwmLeZDQb6EJLtvJ8u0m8suUIZlacxEVtp/PipiN4mvEJ5+/UcjPbKjIprth3x/ZqW8h/DnuBPyw5ipXFXRnRfR2ffN2RL7/Zl07Z3/CDb/7IyMq3eZTvMbzdCtqeeTzTnsxjwvFfcdvln3HZbT1Z/uk+bCrOoGBDNh32LePQ/qVs3NyCNetbsOmbTI4aXsKoYdvYr0slI0dUsG9rY9GybMoqM8lsYZRVZPLu/Ay8dBvXnr6Ig47rQUW3XB59FJYvD0nWXXft+vmmXQ4AZpYJfAScCBQAc4HJ7v5BTJkfA4e6+6VmNgkY7+7nmNlA4DFgJHAAMBvoH82202UmogDQdKqyjPrYtCmkyoccEprWIRwJbdwYdmh9+oQdY1lZOHldXByyicrKkE307Rt2kAsXhkBw1lnhyOezz3a0QHz5ZTjvXPV+7dodR0l5eeECpurrUVS0o/m+6l6LDz4I40eNCldfff11OPrr2DHUb+XKUNfNm8MOu6QkLKukJDwFNPbEe2lpuIG7oCDstEePDul9ZuaOQBLberNlS7g/ZM2a8NygAw4I2VObNmGbPPVUyIhKSsJR4UknhazIPRyNuofmk44dQ9B/550wvWfPsOxRo8L2X7VqxxHjZ5+FgJSVFQL/ggVhu190UQi8VQcRmzaFHc6IETuaHZYtC+sxZEio09dfh+yzrCxs/w8/DAGsXbswLSsrTC8sDME4b3gl7Ys+CytTVaisDMewki1s3fgN7y1w+nTYSNEm4/2VbSiryKD1PpV0ab+NbeUZeOFGOq5bxuCem8nYJxsvKeXD1W1oXbmZni2ilC8jI/xA8vIoP3gwW//0MFs/WcvWrc7WrDbkVHxJ25IvoWtXKr/eREn+GjZbO3JabqZFS4PsbPybLdhXG+N/RJMmwS23hI14+eXwwQdsowUtqXk4v5WWtKCMDHbsVyuxuPdJ69YtRP0WLcJGnT9/F+8u3b0A8C3gRnc/OXr/CwB3vzWmzKyozNtmlgV8AXQBpsWWrSoXzbbTZSaiACAija60NES8iopwFNShw45p27aFNs7168P0jIzwyswMUb579xAlCwpChKyoCG1E5eW1D1e9qi5k6N8/XHSxZEn89Ecf3dEOXE+1BYCsJObtDsS0KFMAjKqtjLuXm1kRkBONf6favN2j4bqWKSLS9KouIEikZctw9URdDj109+pw8sm7N3+Smv31aWZ2sZnNM7N569evT3V1RET2GskEgDVAj5j3udG4hGWiJqD2hJPBtc2bzDIBcPd73T3P3fO61OfaLhER2alkAsBcoJ+Z9TazlsAkYEa1MjOA86PhCcArHk4uzAAmmVm2mfUG+gHvJrlMERFpRHWeA4ja9KcCswiXbD7g7kvN7CZgnrvPAO4HHjazfGAjYYdOVO4J4AOgHLjc3SsAEi2z4VdPRERqoxvBRET2crVdBdTsTwKLiEjjUAAQEUlTCgAiImlqjzoHYGbrgU93cfbOQIInpaSc6lV/zbVuqlf9NNd6QfOt267Wq6e717iOfo8KALvDzOYlOgmSaqpX/TXXuqle9dNc6wXNt24NXS81AYmIpCkFABGRNJVOAeDeVFegFqpX/TXXuqle9dNc6wXNt24NWq+0OQcgIiLx0ikDEBGRGAoAIiJpaq8PAGY21syWm1m+mU1LcV16mNmrZvaBmS01s/+Ixt9oZmvMbGH0OjUFdVtlZoujz58XjetkZi+Z2cfR345NXKcBMdtkoZltMrOrUrW9zOwBM/vSzJbEjEu4jSy4M/rdvW9mw5u4Xv9tZsuiz37KzDpE43uZWUnMtrunietV63dnZr+IttdyM2u0J6LUUq/HY+q0yswWRuObcnvVtn9ovN+Yu++1L0JPoyuAPkBLYBEwMIX16QYMj4bbEp6LPJDwmMyfpnhbrQI6Vxv3a2BaNDwNuC3F3+UXQM9UbS/gGGA4sKSubQScCjwPGHAEMKeJ63USkBUN3xZTr16x5VKwvRJ+d9H/wSIgG+gd/d9mNlW9qk3/H+D6FGyv2vYPjfYb29szgJFAvruvdPdtwHRgXKoq4+6fu/uCaHgz8CE7HpHZHI0DHoqGHwLOTF1VOAFY4e67eif4bnP31wndnceqbRuNA/7iwTtABzPr1lT1cvcX3b08evsO4aFLTaqW7VWbccB0d9/q7p8A+YT/3yatl5kZ8F3gscb47J3Zyf6h0X5je3sASPQ842axwzWzXsAwYE40amqUxj3Q1E0tEQdeNLP5ZnZxNG4/d/88Gv4C2C8F9aoyifh/ylRvryq1baPm9Nu7gHCkWKW3mb1nZv8ys6NTUJ9E311z2V5HA+vc/eOYcU2+vartHxrtN7a3B4BmyczaAH8HrnL3TcAfgIOAocDnhBS0qR3l7sOBU4DLzeyY2Ikecs6UXDNs4alxZwB/i0Y1h+1VQyq3UW3M7FrCw5geiUZ9Dhzo7sOAnwCPmlm7JqxSs/zuYkwm/kCjybdXgv3Ddg39G9vbA0DSzx5uKmbWgvDlPuLu/wBw93XuXuHulcB9NFLquzPuvib6+yXwVFSHdVUpZfT3y6auV+QUYIG7r4vqmPLtFaO2bZTy356ZTQFOB86NdhxETSyF0fB8Qlt7/6aq006+u+awvbKAs4DHq8Y19fZKtH+gEX9je3sAaFbPHo7aF+8HPnT338SMj223Gw8sqT5vI9ertZm1rRomnEBcQvyzns8HnmnKesWIOypL9faqprZtNAM4L7pS4wigKCaNb3RmNha4BjjD3bfEjO9iZpnRcB/Cc7pXNmG9avvuant+eFP6NrDM3QuqRjTl9qpt/0Bj/saa4ux2Kl+EM+UfESL3tSmuy1GE9O19YGH0OhV4GFgcjZ8BdGvievUhXIGxCFhatZ2AHOBl4GNgNtApBdusNVAItI8Zl5LtRQhCnwNlhPbWC2vbRoQrM+6KfneLgbwmrlc+oX246nd2T1T27Og7XggsAL7TxPWq9bsDro2213LglKasVzT+QeDSamWbcnvVtn9otN+YuoIQEUlTe3sTkIiI1EIBQEQkTSkAiIikKQUAEZE0pQAgIpKmFABERNKUAoCISJr6/075WaHOsmt6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('Directory present')\n",
    "except FileNotFoundError:\n",
    "    print('Creating a new directory......')\n",
    "    os.chdir(os.path.join(dest))\n",
    "    os.mkdir('Seq2Seq')\n",
    "    os.chdir(os.path.join(dest,'Seq2Seq'))\n",
    "    print('New Directory Created')\n",
    "\n",
    "history = atten_seq.fit(x_train,y_train_seq,validation_split=0.1,batch_size=32,epochs=200,callbacks=[checkpoint_attention])\n",
    "\n",
    "plt.plot(history.history['loss'],'r',label='Training Loss')\n",
    "plt.plot(history.history['val_loss'],'b',label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "atten_seq.load_weights(filepath_attention)\n",
    "preds = atten_seq.predict(x_test)\n",
    "\n",
    "preds = preds.reshape(preds.shape[0],preds.shape[1])\n",
    "print(preds.shape)\n",
    "\n",
    "y_test_unscaled = scaler.inverse_transform(y_test)\n",
    "y_pred_unscaled = scaler.inverse_transform(preds)\n",
    "\n",
    "e_mse = mse(y_test_unscaled[:,5],y_pred_unscaled[:,5])\n",
    "print(f'The Mean Squared Error is: {e_mse}')\n",
    "\n",
    "for i in range(y_test.shape[1]):\n",
    "        sheet2.write(0, 0, 'MSE')\n",
    "        sheet2.write(0, 1, 'Hours Ahead')\n",
    "        sheet2.write(i + 1, 0, mse(y_test_unscaled[:,i],y_pred_unscaled[:,i]))\n",
    "        sheet2.write(i + 1, 1, i+1)\n",
    "wk.save('Seq2Seq Results.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
